{"v":1,"episode":265,"speakers":["Tim Pritlove","roddi","Ralf Stockmann","Björn Reimer"],"t":[250,300,303,305,306,309,310,319,321,330,337,340,341,386,387,413,415,417,422,426,439,447,453,456,472,493,495,501,509,517,520,524,538,541,544,552,556,558,562,563,567,567,570,664,681,707,780,817,870,871,873,893,902,904,907,910,926,1049,1051,1066,1086,1092,1105,1130,1134,1154,1198,1202,1237,1242,1246,1312,1340,1357,1359,1498,1530,1531,1713,1713,1714,1716,1725,1728,1734,1756,1782,1801,1802,1809,1812,1817,1821,1821,1845,1864,1884,1888,1925,1927,1930,1937,2015,2021,2132,2239,2296,2320,2346,2351,2358,2386,2423,2429,2438,2511,2615,2616,2729,2803,2834,2835,2879,2883,2886,2889,2912,2918,2923,2944,2949,2974,2978,2981,2983,3048,3050,3057,3067,3069,3082,3181,3207,3209,3266,3271,3304,3308,3309,3311,3314,3316,3376,3397,3400,3415,3429,3432,3457,3465,3467,3475,3477,3500,3509,3514,3712,3719,3779,3982,3994,4078,4083,4091,4093,4360,4629,4633,4634,4639,4753,4819,4829,4911,4932,4940,4944,5022,5023,5049,5257,5299,5308,5312,5343,5345,5358,5466,5467,5474,5475,5487,5488,5490,5491,5498,5508,5509,5510,5512,5515,5517,5521,5524,5525,5548,5554,5636,5669,5671,5997,6004,6027,6045,6072,6075,6082,6087,6147,6150,6151,6153,6243,6294,6378,6388,6479,6486,6514,6520,6523,6526,6531,6544,6547,6551,6560,6594,6638,6642,6668,6673,6675,6677,6679,6687,6694,7068,7078,7108,7115,7142,7144,7152,7153,7292,7303,7314,7316,7325,7392,7406,7408,7463,7476,7477,7535,7579,7619,7627,7636,7639,7646,7648,7658,7669,7672,7677,7680,7709,7755,7758,7759,7761,7882,7886,7888,7896,7898,8202,8203,8209,8213,8229,8234,8245,8248,8416,8645,8763,8774,8776,8790,8793,8850,8854,8863,8923,8928,9091,9094,9132,9137,9139,9141,9172,9263,9296,9316,9318,9320,9321,9342,9343,9347,9348,9357,9362,9364,9372,9378,9380,9387,9402,9418,9446,9447,9452,9476,9551,9553,9558,9559,9562,9583,9589,9596,9600,9616,9620,9648,9652,9667,9672,9678,9694,9697,9699,9709,9711,9723,9725,9732,9734,9736,9737,9755,9781,9811,9815,9830,9958,9967,9976,9983,9984,9987,9989,9990,9992,10007,10011,10017,10149,10151,10422,10527,10530,10570,10583,10596,10598,10604,10607,10623,10627,10648,10663,10667,10692,10693,10693,10694,10697,10699,10700,10709,10711,10715,10722,10727,10778,10846,10879,10881,10917,10933,10942,10949,10951,10959,10970,10979,11027,11033,11035,11045,11050,11078,11081,11116,11125,11131,11139,11144,11200,11311,11312,11384,11426,11438,11448,11465,11467,11486,11539,11542,11570,11578,11584,11595,11630,11636,11638,11650,11653,11686,11693,11894,11943,11944,11965,11968,12055,12056,12141,12149,12152,12278,12457,12459,12473,12475,12482,12497,12500,12501,12511,12653,12658,12669,12675,12892,12899,12901,12903,12981,12982,13021,13022,13032,13056,13061,13085,13094,13175,13179,13347,13350,13354,13375,13397,13477,13496,13514,13517,13547,13577,13580,13611,13645,13646,13669,13672,13748,13756,13824,13847,13883,13905,13912,13921,13926,13948,13962,13980,14018,14035,14038,14073,14111,14146,14147,14156,14158,14244,14245,14248,14250,14265,14267,14314,14315],"s":[0,1,0,1,0,1,0,2,0,2,0,1,0,3,0,2,0,3,0,3,2,3,0,2,3,0,2,3,2,0,2,0,2,0,2,0,1,0,2,0,2,3,0,2,0,2,1,2,1,2,0,1,0,2,1,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,3,0,1,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,2,0,2,0,2,0,2,3,2,0,2,0,2,0,2,0,2,0,2,0,1,0,2,0,2,0,2,0,2,3,2,3,0,2,3,1,2,0,3,0,2,0,2,1,3,1,3,1,0,2,0,1,0,3,0,3,0,3,1,3,0,3,0,1,0,3,1,3,0,3,0,3,0,3,0,3,0,1,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,1,2,3,0,2,3,0,2,0,2,3,2,0,2,0,2,1,2,0,2,1,2,1,2,0,2,0,2,0,2,0,2,0,2,0,2,0,1,0,2,0,2,0,1,0,2,0,1,2,0,2,0,2,0,3,2,3,0,3,0,3,0,3,0,3,2,0,2,0,3,0,2,3,0,1,3,0,3,0,3,1,0,2,0,2,0,1,0,1,0,2,0,2,0,2,1,2,0,2,0,2,0,2,3,2,3,2,3,2,0,2,0,2,0,2,0,2,0,3,2,0,2,0,2,0,2,0,2,0,2,1,0,2,0,2,0,3,0,1,2,0,2,0,2,1,0,1,0,1,2,0,2,0,2,0,1,2,0,2,0,1,0,2,0,1,2,1,2,0,2,3,1,0,1,0,1,0,1,0,1,2,1,3,0,2,1,2,0,2,0,2,0,3,0,2,0,1,0,2,0,2,3,2,0,1,2,3,2,0,3,2,0,2,0,2,0,2,0,1,2,0,2,0,1,0,3,0,2,3,2,1,2,0,1,3,1,3,2,0,2,0,2,3,2,0,1,2,0,2,0,2,0,2,0,2,0,1,0,1,0,3,1,3,1,3,1,3,0,3,1,3,0,3,0,3,1,0,1,0,3,1,3,1,3,0,1,3,0,1,0,1,0,1,3,1,0,3,0,3,2,1,3,0,3,1,3,0,3,1,3,1,3,0,3,0,3,1,3,1,3,1,0,1,0,3,0,3,0,1,2,1,3,0,3,0,1,0,1,0,2,0,1,0,3,0],"x":["Hallo und herzlich willkommen, hier ist die Freakshow Nummer 265.\nDie Zahlen schießen nach oben, durch die Decke geradezu. Hallo,\nwir sind's und wir schreiben den 4. Mai 2023.\nMay the 4th be with you. Den musste ich jetzt bringen, weil wenn ich den nicht\ngebracht, Dann würde es die ganze Zeit im Chat auftauchen und alle würden mich\nfragen, warum ich das nicht erwähnt hätte und so weiter und deswegen mache ich das jetzt.\nGenau, hallo ich bin's Tim, hier ist die Freak Show und da sind wir wieder.\nNach nur drei Wochen, möchte ich mal kurz feststellen, in ganz brauchbarer Besetzung, wie ich finde.\nNämlich mit Roddy. Hallo Roddy. Aloha. Aloha.","Schön, dass du mich als brauchbare Besetzung bezeichnest.","Ist doch okay, oder?","Ich fühle mich gebauchpinselt.","Das ist das, was der Brite not bad nennt.","Not too shabby.","Not too shabby, genau. Haben wir so ein bisschen Echo hier gerade irgendwo drin? Nee.\nRalf ist auch wieder da. Hallo Ralf.","Einen wunderschönen guten Abend.","Guck mal, wie der mit dem Mikrofon umgehen kann. Da ist so richtig schön mit\nso einer Elmar Gunsch Stimme.\nBerichtet er uns.","Trotz jahrelanger Abstinenz. Kennst du noch Elmar Gunsch? Wenn ich die Stimme\nhöre wahrscheinlich, ja jetzt vom Namen her.","Du hast keine Assoziation mit Elmar Gunsch?","Bayerische Rundfunk oder?","Das ist jetzt eine gute Frage, die ich ehrlich gesagt nur mit Wikipedia beantworten kann.\nElmar Gunsch war auf jeden Fall im Fernsehen, hier heißt es österreichischer\nModerator tatsächlich sogar auch und der hatte so eine ganz bassige Stimme und\nder hat so eine Sendung gemacht, die hieß Wiedersehen macht Freude.\nWo er dann über so alte Dinge berichtet hat und das Ganze halt mit so einer\nElmar Gunsch Stimme und zwar, ja.\nIrgendjemand hat mal so einen schönen Witz gemacht mit Elmar Gunsch.\nIrgendwie eine Atomwiederaufbereitungsanlage mit seiner Stimme als wieder,\nwie hättest du es genannt, Entsorgungspark bezeichnet, sind alle sehr beruhigt.\nSo und dann last but not least haben wir noch Björn mitgebracht.","Hallo Björn.","Björn Reimer, erstes mal in der Freak Show, herzlich willkommen.\nDankeschön. Genau, mit dir.\nDa freue ich mich sehr, dass es geklappt hat und das hat diverse Gründe,\nwarum du hier ganz richtig bist, wie ich finde. Jetzt muss ich erstmal kurz\nhier wieder meine Lesebrille, mein Gott, das ist auch echt ein Problem mit diesen\nganzen Behinderungen, erstmal klarkommen hier.","Zumindest sitzen wir auf Stühlen.","Bist du denn Star Wars Fan Björn?","Ja.","Das klingt total überzeugend.","Also früher war ich großer Star Wars Fan. Das was jetzt alles am Neuen rausgekommen\nist, hat mich jetzt nicht mehr so begeistert oder in wechselnden Maßen.\nDeswegen habe ich jetzt kurz nachgedacht.\nAber früher schon. Also das hat mich damals mitgenommen.","Wo setzt du denn neu an? Sind die Prequels schon neu oder erst die Sequels?","Also die Sequels haben mich ernüchtert. Das war nicht mehr so gut als es dann wieder kam.","Warte mal, was sind denn jetzt die Sequels und was sind die Prequels,\nda komme ich jetzt durcheinander.","Also die Prequels ist Episode 1, 2, 3, also Phantom Menace und Clone,\nAttack of the, doch Attack of the Clones, genau, Return of the Sith und dann\ndie Sequels ist dann halt mit Rey und Finn und genau 7, 8, 9.","Genau, dann so rum, genau. Also die, ja, da fand ich den ersten super und dann\nspäter hat das auch wieder ein bisschen abgebaut.\nDas wirkte alles sehr zu geschmeidig, fand ich. Also es war nicht mehr sehr\nunterhaltsam und auch nicht sehr viel Neues, wie ich fande.","Da hat jeder so seine Meinung.","Die ganzen Serien jetzt so, Mandalorian und Andor und.","Da hab ich nicht mehr so viel reingeguckt, da war ich dann auch nicht mehr so\nbegeistert von. Andor hab ich angefangen, hat mich aber auch nicht mitgerissen.","Da muss man auch mindestens bis Folge 3 durchhalten, damit der erste Pay-Off\nkommt, die ersten zwei Folgen sind wirklich schwierig.","Andor find ich einen ganz großen Wurf.","Wie viel Zeit haben wir?","Du weißt ja, hier ist das alles sehr flexibel, aber ganz ehrlich,\nich bin ja so alt, ich hab ja noch den Star Wars Film im Kino gesehen als er raus kam.","Den ersten.","Den vierten ersten wie auch immer, New Hope.","Das kann ja fast nicht sein. Wieso? Weil so viel älter als ich bist du doch\nauch nicht. Ich bin ja zehn. Ich hätte den dritten im Kino gucken können.","Ich war zehn oder elf.","Ich hatte nur das Panini Heft.","Wann kam der in Deutschland raus? 78 oder 77 schon noch?","Ich meine 78 kam der.","Ja, da war ich 11. Da kann man schon mal ins Kino gehen.","Fair enough.","Das ist alles weit vor meiner Zeit.","Ja ich weiß, ich bin ja auch alt. Aber da weiß ich noch genau wie es mir vorher\nging und wie es mir danach ging.\nUnd ich glaube alle die das gemacht haben damals, also es ist sehr schwer das\nsozusagen glaubhaft nachzuerzählen,\naber es war wirklich so man ging halt rein und vorher war halt die Welt so und\ndann gingst du halt rein, dann hast du diesen Film geguckt, dann kamst du wieder\nraus und die Welt war neu.\nAlles war anders. Also mit Star Wars hat irgendwie sozusagen die offizielle\nZeitrechnung neu begonnen,\nes war irgendwie das Jahr Null gefühlt so, du hast sofort gemerkt so,\nokay, nichts ist mehr so wie es war, alles ist jetzt neu definiert,\nirgendwie Star Wars hat uns alle komplett den Kopf verdreht und dieser ganze\nCraze war absolut nachvollziehbar, weil es war einfach diese Zauberwelt,\ndiese Märchenwelt, die sie da geschaffen haben, dieser Spaß und das war alles so neu.\nAber ich weiß noch, was hat sich der Film abgemüht mit Science Fiction?\nAlso da gab es wirklich ganz schlechte Phasen, es gab natürlich auch noch ein paar Hochphasen,\nda werden wir auch noch drauf kommen und so weiter, aber ganz zweifelsohne hat\nStar Wars halt so ein komplett neues Kapitel eingeläutert,\ndas kann lustig sein und das kann irgendwie Abenteuer sein und alles und dann\nnoch diese Effekte, die für die damaligen Verhältnisse einfach unfassbar waren,\nEs war einfach eine Illusion, die da abgezaubert wurde, wie auch immer.\nAuf jeden Fall, Star Wars war dann bam, bam, bam und nichts war mehr so wie vorher.","Das Design.\nDas Raumschiff Design alleine. Die allererste Szene, wenn sich der Sternzerstörer\nbrumm brumm, wer nach den zehn Sekunden noch weiß, ob er Männlein oder Weiblein ist.\nSowas war völlig neu einfach für Kino.","Ja, auch der Sound. Also das war auch die Zeit, wo Kinos überhaupt angefangen\nhaben ordentlichen Sound zu haben.\nVorher hat's da so kleine plerrende Boxen und dann kam halt so mit diesen Filmen\nkam halt so dieses Krachbumm irgendwie auf einmal rein und dass man das dann\nso im Bauch spürte und so weiter.\nAlso man wurde da an allen Sensoriken gezupft und ich weiß nicht ob der Sprung\ndanach jemals wieder so groß war, so im Gesamtgefühl.","Das absurde ist, ich bin zu Star Wars gekommen, weil man es mir erzählt hat.\nIch war damals irgendwo auf der Schule und wir hatten eine Busfahrt von 20 Minuten\nund mein bester Freund, der hatte die alle schon auf Video geguckt irgendwie, alle drei Teile.\nMan hat ja mir im Laufe einer Woche während der ganzen Busfahrten die komplette\nGeschichte erzählt von Teil 1 über Teil 2 über Teil 3. Das heißt also ich kenn\nStar Wars als mündliche Überlieferung, so hat's angefangen.\nUnd dann irgendwie erst ein paar Monate, es hat wirklich lange gedauert,\nein paar Monate später hat er dann wieder irgendwie den Videorekorder organisiert\nund dann gab's dann irgendwie eine Watchparty,\nwo wir dann relativ schnell auf so einem abgeranzten kleinen Mini Farbfernseher\nmit schlechten Tapes irgendwie kopiert haben,\ndas war noch so eine Raubkopie, das war noch niemals irgendwie aus der Videothek,\nweil ich glaub die gab's gar nicht in der Videothek zu dem Zeitpunkt,\ndie konnte man also auch am Anfang nur irgendwie aus Sonderbankquellen irgendwie beziehen.\nDas war so das denkbar schlechteste Star Wars Intronisation,\ndie man sich auch nicht vorstellen kann. Erst die ganze Story gespoilert und\ndann die schlechte Version auf dem Scheiß Fernseher geguckt und es war trotzdem fantastisch.\nUnd wenn ein Film trotzdem so funktioniert, obwohl er so massiv schlechte Startchancen\nhat, dann muss da was dran sein.","Ich erinnere mich nur, dass ich den, irgendwann haben wir mal die ersten drei\nTeile, also Episode 4 bis 6, von analoger Laserdisc angeguckt.\nUnd zwar waren das drei analoge Laserdiscs pro Film, aber mit Vor- und Rückseite.\nAlso irgendwie gefühlt alle Viertelstunde musste diese Disc umgedreht werden\noder eine neue eingelegt werden und dann natürlich mit dem weichen Mikrofasertuch\nnochmal vorsichtig abgewedelt.\nJa, das war nicht ganz so beeindruckend irgendwie dann, aber es war trotzdem schön.","Ja und Episode 1 dann, also Teil, der erste dann der Prequels,\nden habe ich in der Tat Raubmord kopiert, bei uns damals bei den Medienwissenschaftlern\ngesehen und den haben wir über 48 Stunden runtergeladen und ich glaube weite\nTeile davon habe ich dann da auch gewilltig campiert in meinem Arbeitsraum,\ndas war, ich weiß gar nicht was das für ein Protokoll war, da gab es ja noch\nkein Torrent zu dem Zeitpunkt und da musste es also irgendwie gefühlt alle 15\nMinuten dagegen treten damit irgendwie der Download nicht wieder zusammenbrach.\nUnd das waren also natürlich, in Denaver haben wir auch häppchenweise geguckt,\nalso so alle so in Chunks von zehn Minuten konntest du quasi dann schon wieder\nweitergucken, das setzte sich ja so fort diese gar nicht so gute Experience,\ndass ich also Episode 1 würde ich in zehn Minuten Fragmenten über 48 Stunden\ngeguckt habe, aber auch das war nicht so schlecht.\nAlso das Podrace, darauf lasse ich ja nach wie vor nichts kommen,\ndas sind perfekte 30 Filmminuten die man da drin hat.","Aber Jar Jar Binks.","Ja egal, der ist da ja, kommt zu sehen.","Portraits gebe ich dir. Also ich glaube sonst hätte man den Film auch einfach\nkomplett gleich aus den Kinos nehmen können.\nDas war noch so ein bisschen der Ansatz. Aber sorry, die ganzen Charaktere und\nso, das wäre fast komplett schief gegangen.\nUnd Jar Jar Binks, siehst du irgendeine Legitimation für Jar Jar Binks?","Ich glaube sie wollten unbedingt einen Jamaikanisch sprechenden Synchronsprecher\nin dem Film haben, weil sein Jamaikanisch ist wirklich gut.","Wie der hat auch noch.","Ja ja die haben eine ziemlich deftige Rassismus Debatte ja noch.","Ja ja der hat richtig krasses Jamaikanisch gesprochen.","Auch weil die von der Handelsföderation dann ja auch so asiatischen Select drin haben.\nDas war also schon alles nicht so ganz fein. Hat sich Lukas,\nglaube ich, sogar auch einigermaßen offiziell für entschuldigt,\nim Nachhinein, irgendwie etliche Jahre später.","Ja, zurecht.\nWeil er hat, ich finde er hat nicht schnell genug loslassen können und auch\nso seine Redos von 4,5,6 war ja auch totale Katastrophe.\nHier mit irgendwie Handshot first, also dass er wirklich auch noch in den Ablauf\neingreift und dann auch noch seine,\nich meine ich rechne es ihm ja hoch an, dass er immer nach Perfektion strebt so,\naber er ist dann halt wirklich in dieses Uncanny Valley der Special Effects\nreingefallen und hat irgendwie zu einem Zeitpunkt wo er dachte jetzt ist schon\nalles richtig geil und wenn ich das jetzt mache dann werden die Filme richtig toll,\nist aber genau, hat so richtig in den Scheißetopf von, ne ist noch nicht so\ngeil wirklich so reingegriffen und dadurch halt die Filme verunstaltet.\nWir hatten ja hier schon mal eine ausführliche Diskussion, du wirst sie sicherlich\nverfolgt haben, wie ich dich kenne\nRalf, zu dem Thema, mit irgendwelcher Reihenfolge muss man das hören.\nDie Machete Order natürlich. Genau die Machete Order auf der einen Seite,\naber auf der anderen Seite auch diese Special,\ndas weiß ich nicht mehr ganz genau wie die Ausgaben hießen, ich hab sie hier groß gepriesen,\njetzt weiß ich es grad nicht mehr, aber es gibt ja verschiedene,\nes gibt ja sozusagen eine Version aller Filme,\ndie zusammengesetzt sind aus sozusagen allem Material was es gibt,\nwo sozusagen die original, der original Szenenverlauf ist mit den besser gemachten\nVerbesserungen reingenommen,\nalles irgendwie in HD und so weiter und da kann man sich High Star Wars so richtig\ngeil angucken so, das ist halt einfach qualitativ das beste was man kriegen\nkann ohne dass es die Story verholt ist.\nUnd vor allem ist halt ganz viel Jar Jar Binks rausgeschnitten worden und ehrlich gesagt,\nJar Jar Binks kann ja noch ertragen, aber wo ich wirklich die Galle kriege,\nwas ich das Schlimmste finde überhaupt in diesem ganzen 1-2-3-Epos,\nganz schlimm in eins und auch ganz schlimm in zwei, Diese unsäglich langweiligen\nDiskussionen zwischen Obi-Wan und, äh, hier, äh, junger Skywalker, wie heißt er?","Anakin. Anakin.","Und überhaupt das ganze wie so deutsches Theater, also wo sie die ganze Zeit da so sitzen,\nimmer linkscard, rechtscard, linkscard, sie sitzen die ganze Zeit auf Sofas\nund reden miteinander, da kann ich auch in Berlin ins Theater gehen,\nwenn ich mir das anschauen will, also das ging überhaupt nicht.","Du hattest ja mal hier diese Crew da aus Amiland, die diese Rezensionen machen,\nwie heißen die noch? die auch so ein bisschen völlig neben der Spur sind,\ndie da wirklich sehr gut 40 Minuten lang oder sogar über eine Stunde durchanalysieren,\nwas alles schief gelaufen ist bei den Prequels. Du erinnerst dich was ich meine?","Du hast es selber gepriesen, völlig zu Recht. Ja, sorry ist zu lange her alles.","Weil da haben die genau das sehr gut mal wirklich so standbildmäßig so,\nwarum sind diese Einstellungen hier so langweilig, warum passiert hier nicht\nmehr Dynamik, warum Show, Down, Tell, also einfach so die Grundregeln von guten\noriginellen Filmen machen werden da einfach halt ignoriert.","Ich weiß nicht mehr wie es heißt aber jetzt weiß ich mal was du meinst. Genau. Ja,\nnaja, so aber dann und womit ich ja auch nie so richtig klar kam,\nwar diese ganze Zusatzwelt, die dann so zwischen diesen Filmen entsponnen wurde\nin Form von diesen Animationsfilmen.\nDafür war ich zu alt. Das hat mir nicht gefallen und das hat irgendwie ja irgendwie\nein junges Publikum gefunden.","Der hat also Clone Wars nicht gefallen, notier.","Ja ich hab das erst vor kurzem überhaupt das erste mal versucht nachzuschauen, aber...\nIch bonde nicht mit dem Animationsgenre, also das ist mir dann zu,\nalso dass das dieselbe Welt sein soll, das geht bei mir nicht zusammen,\ndas ist für mich wie das Fernsehen in Star Wars damals.","Also in Clown Wars muss man, kann man glaube ich so ein paar einfache Wahrheiten\nmal versuchen zusammen zu tragen, die haben ein bisschen einen kolprigen Start\nauch, so die erste Season ist also sicherlich nicht so das Glanzstück.\nEs sind aber so ein paar Story-Arcs drin, die so mit zum Besten gehören,\nwas du so lore-technisch an Star Wars kriegen kannst. Also weil da ja eben wirklich\nviel, wie wurde das Ganze vorbereitet und wie ist es dann hinterher mit Darth\nMaul weitergegangen, den holen sie ja wieder zurück.\nIst ein schöner Arc, wie verhält sich Sidious dann dazu? Also wenn man grundsätzlich\nso in dieses ganze Star Wars Lore-Thema eintauchen möchte, so wie hängt was\nwie zusammen, ist Clone Wars der absolute Honigtopf.\nDu findest also keine andere Quelle, wo du das so schön zusammenfassst.","In Chat wird gerade gesagt, es gibt Clone Wars und The Clone Wars.","Also ich meine die große lange Folge, also nicht die kurze erste.\nDas ist glaube ich Clone Wars und das was ich meine ist glaube ich The Clone Wars.\nAlso das wo es irgendwie fünf, sechs Seasons von gibt. Das das taugt richtig,\ndie haben ja noch eine nachgeschoben vor einem oder zwei Jahren,\nhaben sie quasi weil sie das Ende quasi der letzten offiziellen Season war so\nein bisschen halbgar und man wusste gar nicht was passiert mit Ahsoka jetzt\neigentlich irgendwie weiter,\ndas ist zum Beispiel würde ich sagen bester weiblicher Charakter im Star Wars\nUniversum, Ahsoka, der jetzt auch ihre eigene Show kriegt, noch knapp vor Rey,\nja total super, bester weiblicher Charakter, angucken.","Okay gut, aber ich sag ja nur ich konnte mit diesem Animationsgenre nicht bonden.","Also das war, kann ich nachvollziehen, auch der Zeichenstil muss einem gefallen.","Das kann toll sein und die Story mag toll sein, aber ich konnte da nicht,\nkeine Verbindung herstellen.\nDeswegen ist mir dieses ganze Star Wars Universum überhaupt eigentlich erst\nnäher gebracht worden, seitdem sie eben jetzt diese Zwischenfilme machen.\nSo und da fand ich den, oh Gott ich kann mir den scheiß Namen nicht merken,\nwie hieß der mit dem Angriff da, den fand ich super, den fand ich irgendwie\ntoll, der hat mich das erste mal so ein bisschen abgeholt für dieses,\nes gibt noch Geschichten dazwischen, okay so.\nDann fand ich diesen Solo, fand ich okay.\nUnd Obi-Wan als Serie war genauso langweilig wie die Obi-Wan Rolle in den Filmen.\nSorry, ich mag ja diesen Schauspieler. Ich liebe ihn.\nAber diese Rolle haben sie eben komplett zerpflückt oder die Regie,\nich weiß nicht, es ist so tranig, so langweilig, so zum Einschlafen,\nzum Gähnen, grauenhaft, furchtbar.","Obi-Wan hat einfach ein paar richtig fiese inszenatorische Macken,\nwenn also die kleine Leia irgendwie durch den Wald vor den super harten Kopfgeldjägern\nabhaut und die ständig über irgendwelche Wurzeln stolpern nur damit sie sie\nnoch nicht gefangen kriegen,\nAlso wenn du halt irgendwie so zwei badass Typen hast und die schaffen es zehn\nMinuten lang nicht irgendwie eine Sechsjährige oder Zehnjährige zu fangen,\ndas ist auch so wirklich plump inszeniert, also darüber kann man sich schon ein bisschen helfen.","Also Ewan McGregor finde ich ja einen geilen Schauspieler und ich bin sehr froh,\nich hab den ja irgendwie schon in seinem allerersten Film ist er mir ja schon\naufgefallen, damals als er noch in Schottland, Shallow Grave war der erste Film\nmit dem er bekannt geworden ist, ganz lustiger Superfilm.","Bin ich Trainspotting eingestiegen, ganz klassisch.","Trainspotting kam danach, also Shallow Grave war sozusagen wo er entdeckt wurde\nund danach kam irgendwie Trainspotting und aus diesem ganzen schottischen Kollektiv\nsind ja so einige Stars hervorgegangen,\njetzt wollen wir nicht so weit wegkommen von Star Wars, auf jeden Fall finde ich Ewan McGregor,\nalso es tut mir wirklich leid Ewan McGregor, ich mag dich sehr gerne,\naber sie haben dir eine kaputte Rolle gegeben, die ist einfach von der Regie\nzerstört worden und finde ich auch sehr wenig rausgeholt.\nUnd dann, deswegen fand ich dann Andor wieder so geil, weil Andor,\nwenn du sagst so die ersten drei Folgen geguckt und irgendwie hä,\nso ja, das ist wieder so etwas was sich ganz langsam aufbaut so und dann sehr\nschön den Anfang von allem zeichnet.\nAlso das ist ja das, was da drin steckt. Da steckt der Anfang dieser gesamten\nRebellion drin. Warum eigentlich? Wie? Wer? Und so.\nUnd das finde ich ganz toll. Und Mandalorian...\nIst ein gutes Beispiel dafür, dass man einen kriegen kann,\nalso erstmal Mandalorian, geilster Soundtrack der nicht von John Williams ist,\nalso dieser Schwede, Hammer Thema super umgesetzt trägt sich jetzt schon über\ndrei Serien wird immer evolviert ganz da haben sie wirklich einen super super\nsuper Komponisten gefunden,\nSchwede oder Finne oder sowas, ganz komischer Name, Langasör, irgendwie sowas.\nDas ist geil und ich meine klar mit Baby Yoda haben sie es natürlich alle gekriegt so.\nDas war einfach der Cuteness Faktor hoch 10, aber auch da ist es halt so,\nJa ok, ihr müsst also jetzt eine Folge in dieser Serie füllen und jetzt gibt\nes ja so ein Abenteuer, was soll der Name?\nDie Mission of the Week. Genau, die Mission of the Week,\nwo nichts übrig bleibt für den Rest der Geschichte und das finde ich dann wieder so schade,\ndass man da irgendwie so diese Zeit ein bisschen, das ist zwar irgendwie ganz\ngute Unterhaltung und so,\naber am Ende, ok, wir haben jetzt 30 Minuten eine Story gesehen,\ndie in keinem der Previously on Mandalorian auch nur eine Sekunde reingeschnitten\nwird, so wichtig war das jetzt.\nUnd das finde ich dann wiederum.","Ja, also ich hab mit Andor echt so meine Schwierigkeiten.\nIrgendjemand hat das in Masterdon mal auf die schöne prägnante Formel gebracht,\nich weiß ja nicht mehr wer jetzt spontan.\nDie haben die Stars aus Star Wars rausgenommen.\nAlso sprich all das was irgendwie was mit eben Märchen und Eskapismus und tolles\ninteressantes Design und sowas, das ist halt alles raus operiert und du hast nur noch den Krieg.\nJa also was macht dieses oppressive Imperiumsregime mit den ganzen Menschen?","In was ist nur noch der Krieg?","In Star Wars. Sie haben die Stars rausgenommen aus Star Wars. In Andor. So.\nAlso Star Wars, das war immer die Kombination, das ist eigentlich ein Actionfilm,\naber du hast eben dieses ja, Sky is the limit und es ist Eskapismus und tolles\nDesign und man hat auch Spaß und das ist alles raus und du bist nur noch im\nKrieg, nur noch die Wars sind übrig.\nSo und was macht der Krieg mit den ganzen Menschen, wie funktioniert dieses\nUnrechtsregime, wie funktioniert jetzt das Imperium von innen.\nDie Szenen finde ich natürlich fantastisch, wenn da also der Secret Service\nvom Imperium irgendwie gezeigt wird und was die wiederum alle für Binnenquerellen\nhaben. Aber Spaß ist das halt alles nicht.\nEs sind halt keine Stars mehr drin.\nAlso nicht Stars im Sinne von die Sterne da oben am Himmel halt und das finde\nich hängt dem schon so ein bisschen nach.\nPlus dieser Erzähl-Rhythmus, dass du immer diese Dreierblöcke hast.\nDu brauchst zwei Folgen Exposition bis du dann wieder irgendwie einen Höhepunkt\nbekommst. Die sind dann ziemlich gut, die dritte Folge ist gut,\ndie sechste ist gut und dann nach hinten raus ziehen sie die Taktung generell\nzum Glück ein bisschen hoch.\nAber diese Folgen zwischendurch die sind schon auch,\naber du hast dann da wirklich auch in Folge 1, 2 und ich glaube auch in 4 und\n5 hast du halt auch Szenen wo Leute irgendwie am Mittagstisch sitzen und Alltag\nbesprechen, das will ich in Star Wars nicht sehen, echt nicht.\nSo und das hat auch kein irgendwie, das kommt dann auch nicht im nächsten Previously.\nAlso ich hätte auch gesagt Andor kannst du gut auf die Hälfte runtercutten.\nDer ganze Mon Matma Plot fand ich total überflüssig, da passiert eigentlich gar nichts.\nEs gibt eine lange Besprechung mit den Kulturdeliktanten, da kann man sich das\nalles nochmal in Länge anhören, warum ich da so Schwierigkeiten mit habe und\nwas ich jetzt bei Mandalorian wirklich nicht verstehe ist halt so der Übergang\nvon zweiter Season zu dritter Season.\nGanz tolles Ende, zweite Season, Krogu, also Baby Yoda geht weg und Luke nimmt\nihn mit, fantastischer Auftritt, episch, alle geweint.\nSo und die erste Folge, Season 3, ach ja da ist er übrigens.\nWenn ihr euch fragt wieso, ja da müsste Boba Fett gucken. Und dann guckst du\nBoba Fett und siehst okay da sind halt zwei Folgen Mandalorian reingearbeitet\nund ich verstehe natürlich was der Gedanke dahinter ist,\ndie wollen halt jetzt so ein Mando-Verse aufziehen, so wie es halt irgendwie,\nansonsten Disney ja auch mit den ganzen, na wie heißt das andere große Franchise?\nNein, Guardians of the Galaxy und Marvel, das Marvel-Universe,\nwo alles mit allem verwoben ist und dann irgendwie wieder in großen Kulminationsfilmen\nzusammengetragen wird und sowas.\nGenau so eine Schiene wollen die da halt bringen.\nDu kannst doch nicht ernsthaft von Leuten erwarten, dass sie zwischen der zweiten\nund der dritten Season irgendwo oder erstmal woanders nachgucken müssen,\nwie jetzt der Hauptplot um den Hauptcharakter irgendwie weiterging.\nJa. Ich muss nochmal gucken, ich glaube sie bringt es noch nichtmals in irgendeine\nPreviously Sequenz, was jetzt eigentlich mit Luke los war und dass er sich entscheiden\nmusste, will er jetzt ein Lorianer werden oder will er jetzt ein Jedi werden\nund natürlich entscheidet er sich für sein Papa.","Das war in Boba Fett.","Das war in Boba Fett, ja.","Richtig, Boba Fett auch gesehen, das war auch langweilig.","Ja das hatte auch drei gute Folgen das waren halt die beiden Mando Folgen plus\neiner anderen und der Rest war halt auch irgendwie fies. Es ist schwierig.","Freuen wir uns auf Star Wars 10.","Ja es sind jetzt drei neue Filme angekündigt das wird in der Tat glaube ich ganz spannend.","Also auf jeden Fall, 4. Mai ist so ein bisschen der Tower-Day der Star Warsies,\nwie heißen die denn eigentlich?\nStar Warsies? Trekkies sind von Star Trek und wenn man bei Star Wars ein Fan\nist, gibt's da auch einen Namen für? Ist man dann irgendwas?","Jedi vielleicht? Nicht notwendigerweise natürlich. Das was ich jetzt gerade\nmal in den Chat gepostet habe ist das traurigste was man heute glaube ich sehen\nkann, nämlich Marco Buschmann von der FDP der Grogu hoch hält und behauptet es sei Yoda.\nTiefer werden wir heute nicht mehr fallen.\nYoda und ich werfen heute ein. Auch sehr schöner Tut dazu von Marco Bohnen sagt\ner. Nebenbei Grüße, hier ist Highlancer.","Und wieso schreibst du so wanst\nman sich nicht glaubhaft an Star Trek Fans ran. Ist ok, doppelter Witz.\nNaja. Alright. So. Und kommen wir mal zu dir Björn. Jetzt müssen wir erst mal hier, äh...","Was kommt jetzt?","Na, du hast heute Geburtstag.","May the 4th be with me. Genau.","Ich dachte ja, du hast einen besonderen Bezug zu Star Wars, deswegen.","Ja, daraus konnte ich auch sehr gut merken, wann dieses May the 4th überhaupt entstanden ist.","Ja, wann denn?","Weil ich würde sagen, das fing an so vielleicht vor acht bis zehn Jahren,\ndas müsste man nochmal recherchieren, wann das wirklich groß ist,\naber das ist so, wenn ich meine Erinnerungen nicht täusche, das wo das natürlich\nständig erwähnt wird, wenn man an diesem Tag Geburtstag hat.\nDas ist nicht neu mehr für mich. May the 4th be with you.\nAber ja, das gibt es noch nicht so lange wie Star Wars auf jeden Fall.\nZumindest in meiner Erfahrung.","Nee, nee, das kam irgendwann später. Ich weiß auch gar nicht warum.\nIch fand es auch nicht so wichtig.\nSo, aber das tut ja auch nichts zur Sache, aber vielleicht kannst du ja mal\nso ein bisschen erzählen, was du so für ein Nerd bist.\nDu hast ja unter anderem so ein Hackerspace gestartet, aber vielleicht kannst\ndu dich ja mal selber mal einführen.","Ja, ich fang mal vielleicht vorne an,\nalso der Kern von irgendwie, was mich viel beschäftigt ist Softwareentwicklung\nund genauer gesagt verdiene ich seit einiger Zeit mein Geld mit Elixier und zwar bei einer Firma,\ndie hier ja auch schon bekannt ist, VUGA, also Computerspiele,\nBackends, da ist das glaube ich auch sehr, sehr gut für geeignet.","Also bis jetzt sozusagen in der Abteilung, in der Huckel früher war.","Ja also in dem gleichen Gebiet da hat sich einiges einiges geändert,\nalso es ist ja auch eine Firma die gewachsen ist, wo sich auch jetzt ich sag\nmal mehr vom Startup zu einer kontinuierlichen Firma geworden,\nauf was wir machen und wie wir das da alles machen, aber genau in dem Bereich,\nwir sind da, früher Erlang, Ruby gab es da auch ganz ganz viele andere Sachen\nund ich war da einer derjenigen, der schon vor Jahren mitgeprägt hat,\nals wir ein neues zentrales Backend System gebaut haben, das halt komplett in LXC aufzubauen.\nUnd mittlerweile entwickeln wir, ich würde sagen seit mindestens fünf Jahren\nim Backend nichts mehr außer LXE. Also es gibt noch ein paar alte Sachen.","Backend heißt sozusagen die ganzen Gameserver.","Genau, alles was irgendwie auf dem Server passiert.","Wie groß muss man sich WUKA so vorstellen mittlerweile? Also hast du da irgendwelche\nZahlen oder Größenordnungen?","Also eine Zahl die man vielleicht nehmen kann, gerade haben wir so ungefähr\nzwei plus ein bisschen Millionen Spieler am Tag.\nDas ist so eine Zahl die man so nehmen kann. Mhm.\nGröße von Anzahl der Leute sind es 300, 350 würde ich sagen.\nDie Pandemie hat Spielfirmen sehr geholfen, würde ich mal sagen.\nWährend wir dann alle im Homeoffice waren, ist die Firma größer geworden als das Büro in dem wir sind.\nUnd ja, jetzt teilen wir uns das Büro und nehmen, weil wir in Schichten immer\nda reingehen, weil wir nicht mehr alle reinpassen.\nGenau, also es hat sich auch insofern erinnert, früher gab es sehr,\nsehr, sehr viele kleine Spiele, also die Spielebranche hat sich sehr verändert,\nweil früher ging es darum ein Spiel zu machen, das war ein Hit und dann ging\nes weg und das war auch, sag ich mal, relativ, relativ einfach ein erfolgreiches Spiel zu machen.\nHeutzutage ist das kein Geheimnis mehr, dass Computerspiele gerade auf dem Handy\nsehr sehr viel benutzt werden. Man hat halt einen weltweiten Markt mit sehr\nsehr vielen Leuten die da spielen und da ist es schwerer geworden.\nDas heißt an einem Spiel sitzen jetzt 100, 150 Leute.\nDas waren früher eher 10, 20.\nUnd das ist verteilt auf alle Gewerke.","150 Leute entwickeln an einem Spiel oder administrieren also alles, ne? Also Developer.","Genau, das fängt an von Leuten, die sich um Story erstmal kümmern,\nalso das ist so eine unserer Spezialitäten, dass wir Spiele bauen,\ndie sehr stark auf Geschichte basieren.\nAlso in den Spielen werden Geschichten erzählt, wir releasen auch immer neue\nGeschichten, also neue Kapitel zu den Spielen.\nDann die ganzen Game-Designer, die Artists, die Künstler, 2D, 3D, das alles rum.\nDann natürlich Software-Entwicklung, im Client-Unity, da haben wir eine Menge Leute.\nDann im Backend, LXC, dann aber auch hinten rum Data, Data-Science,\ndas ist eine riesen Preise-Palette und dann noch, das ist noch gar nicht Publishing\nund alles mit drin. Und das summiert sich.\nUnd heutzutage muss man extrem Aufwand betreiben, um sich um die Erwartungen des Marktes zu kümmern.\nJa, da verdiene ich mein Geld, aber das ist nicht alles. Neben zwei Kindern,\ndie mich sehr viel noch beschäftigen, mache ich in meiner Freizeit versuche\nich einen Hackspace zu organisieren.\nGenauer gesagt den X-Sign, hier im Nachbarbezirk, im schönen Friedrichshain.\nDas war auch eine interessante Reise. Das war gar nicht so geplant,\ndass das so groß wird. Wir haben damals angefangen in einem kleinen Ladenlokal\nin der Grünberger Straße und ja mittlerweile sind es… Wann ist damals?\nVor sieben Jahren, ziemlich genau jetzt.\nUnd jetzt sind es 130 Mitglieder, die da hinkommen und von Software,\naber auch Hardware, Making, also wir sind relativ breit aufgestellt, alles dort machen.\nAlso wir haben auch eine Nähecke, 3D-Drucken, Laserkarten, die üblichen Sachen.\nUnd ja, auch über Alex Hirwitt da geredet, unter anderem.","Die üblichen Sachen, du bist gut, also ich meine es gibt ja so eine und so eine\nHackerspaces, es gibt so welche, so was weiß ich, so wie CCCB,\nwo halt wirklich mehr so Developer und Polit orientiert ist,\nbisschen elektronik gemacht wird aber nicht so viel\nbastel kram so und\ndann gibt es welche die sich aber sehr viel mehr wiederum in diesem spielerischen\nmit so 3d druck festgesessen haben aber dann so an anderen stellen irgendwie\nnicht so präsent sind und ich finde das im x-heim ist es sehr ausgewogen also\ndas würde ich von allem was da auch so räumlich nimmt irgendwie alles mehr oder\nweniger gleich viel Platz ein,\nDunkelkammer, dann hast du irgendwie so einen Lasercutter,\ngibt eine valide Holzwerkstatt mit Drehbank, mit Bandsäge, mit CNC Fräse,\nalso es ist irgendwie alles da, Werkzeug ist irgendwie alles da und wenn man irgendwas machen will.\nSo dann kann man irgendwie sofort loslegen, egal worum es sich irgendwie handelt,\nselbst wenn man irgendwie Elektronikprobleme hat, gibt's dann irgendwie Labor\nund irgendwie sitzt auch.","Ganz anders, also eine ganz andere Spannbreite machen kann. Man kann halt irgendwie,\njemand baut was und dann macht man da LEDs rein und dann schreibt man dafür die Software,\ndas ist ja eine unglaubliche Spannbreite und das kann man halt alles,\nman hat halt dort die Leute, wo man von lernen kann und das gemeinsam machen\nkann und eine Sache, die uns auch glaube ich auszeichnet ist,\nwir haben halt ein riesengroßes, Also wir sind in einem Ladenlokal, sag ich mal.\nAlso wir haben große Schaufenster, das heißt man kann vorbeilaufen,\nda stehen auch einige Sachen drin in den Schaufenstern, was Eltern mit Kindern\nlieben, aber auch hassen, je nachdem wie schnell sie zur Kita kommen wollen\noder müssen, weil die ganzen Kids davor stehen.\nAber es erzeugt halt eine wahnsinnige Offenheit. Es kommen immer wieder Nachbarn\nrein, die sagen, hey, mich hat so interessiert, was ihr hier macht,\nwas macht ihr hier eigentlich?\nÜbrigens jeder der interessiert ist kann montags bei uns vorbeikommen.\nDas ist immer unsere offene Abend. Da sind meistens auch immer viele Leute da,\ndie erzählen was sie machen. Man kann da eine Tour bekommen,\nsich diese ganzen Bereiche zeigen lassen.","Und gefühlt findet die ganze Zeit irgendeine Tour statt. Wenn man da ist,\nimmer wenn ich mich da aufgehalten habe,\nstand immer gerade irgendjemand so im Eingang rum, der so ein bisschen so,\nwas ist das denn hier, so und dann dauert es auch keine 10 Sekunden und dann\nwird die Person schon von irgendjemand abgeholt und kriegt halt so die Rundtour.\nDas finde ich irgendwie ein echtes Feature so welcoming zu sein.","Das ist aber auch unglaublich interessant, was man da für Leute und Geschichten erfährt,\nwenn man so irgendwelche Leute, die erstmal so schüchtern da reinkommen,\nso ha ich hab gehört hier gibt's Touren und dann fängt man an mit denen zu reden\nund dann hört man plötzlich interessante Geschichten,\nwo die herkommen, was die für Zeug machen, das ist wahnsinnig interessant und\ndas ist auch echt cool, weil da muss man gar nicht mehr so viel rumgehen,\ndie Leute kommen jetzt alle her, das war auch nicht so erwartet,\nals wir damit angefangen haben, aber.","Das X-High ist auch erstaunlich international, finde ich.","Also, ja, ich kann das jetzt nicht so gut vergleichen, aber es sind schon viele\nLeute, es wird sehr häufig Englisch gesprochen, ja.","Ja ja viele Amerikaner, also aus verschiedensten Ländern aber halt so Englisch\nist da einfach wirklich second language,\ndas merkt man schon, dass da einfach und zwar jetzt nicht nur die als Gast mal reinschauen,\nsondern die auch dauerhaft da sind und dann halt auch die Touren dann gleich\nin Englisch machen, wenn der Bedarf da ist und das fand ich schon ganz geil,\nja das ist auf jeden Fall ein schönes Experiment und ein sehr brauchbarer Sozialraum.","Ja, das würde ich auch sagen. Das ist in erster Linie. Es ist auch mittlerweile,\ngerade auch Montage, sind für mich viel mehr hingehen, mit Leuten reden,\nLeute kennenlernen und für Projekte komme ich dann immer an anderen Tagen,\nweil ja, das in erster Linie für viele Leute ein Sozialraum geworden ist und\ndas war auch eine große Motivation für uns, als wir angefangen haben.\nWir wollten halt einen gemeinsamen Ort haben, wo wir an Zeug bauen können,\naber uns auch erstens treffen können. Wo man einfach hingehen kann und da ist\ndann meistens jemand und das ist es auch wirklich geworden.\nIch könnte jetzt nicht behaupten, es gab einen Masterplan, das ist so entstanden.","Ja, so Sachen kann man auch nicht planen. Das ergibt sich eigentlich immer so ein bisschen.","Ja, das ist ja mein Hobby, was manchmal sehr viel Zeit nimmt aber auch sehr viel Spaß macht.","Ja cool. Gut. So, jetzt wollen wir mal ein bisschen mehr Feedback machen,\ngab ja so das eine oder andere.\nAber vielleicht vorweg noch ne schlechte Nachricht,\ndie wir vielleicht ansprechen können, es gibt nicht so richtig viel was wir darüber wissen,\naber es ist jemand gestorben aus der großen deutschen Podcast Gemeinde,\nnämlich Nikolaus Seemak, den viele vielleicht von euch kennen,\nweil ihr ihn gehört habt, Oder zumindest so auch als umtriebige Person wahrgenommen habt.\nNikolas hat die Elementarfragen gemacht, das war glaube ich sein erster Podcast, damit ging es los.\nÄhnliches Format wie mein CAE, also auch so Interview, längere Gespräche mit Leuten,\nviele Promis dabei und dann hat er auch mit Freunden vor einigen Jahren dieses\nPodcast Label gegründet 4000 Hertz.\nDu kanntest ihn ja auch Ralf ne?","Genau, ich kannte ihn ein bisschen über die Subscribe eigentlich kennengelernt,\nalso unsere Podcast Tagung, die wir ja viele Jahre gemacht haben und da war\ner dann auch mal zu Gast genau und wir hatten dann ja auch so den einen oder\nanderen Disput über die Ausrichtung so wie das deutsche Podcast Wesen.\nUm diesen abgegrenzten Begriff mal zu nehmen, in welche Richtung sich das entwickeln sollte und.\nEr kam ja aus dem professionellen Medien, Und wir haben in der Tat mal eine\nNullnummer auf der Republika aufgenommen mit Nikolas und mir und Claudia so\nals halbe Moderation dazwischen.","Wurde das auch veröffentlicht?","Das wurde nicht veröffentlicht, das wird auch nie veröffentlicht.\nWeil es hat auch nur so semi gut funktioniert.\nAlso es war ein total zivilisiertes Gespräch, ich glaube und das hätte er vielleicht unterschrieben,\ndass wir am Ende glaube ich von unseren Positionen nicht wirklich irgendwo abgerückt\nsind und dann konterkarierte das etwas so die eigentliche Formateidee der ganzen Geschichte.\nJa also das ist schon finde ich ein harter Schlag,\nweil gerade einer der ersten, die halt sowas wie ein Label, ja so klar Meta-Ebene\ngab es natürlich auch schon,\nich weiß du hast damals etwas die Augenbraue gelupft,\nals es dann hieß so das erste deutsche Podcast Label geht an den Start mit 4000\nHerzen und die Meta-Ebene gab es zu dem Zeitpunkt schon wie viele Jahre,\naber das ist so die Medienerzählung und das deutsche Podcasttum,\ndas ist ja sowieso eine Geschichte voller Missverständnisse.\n47 ist er nur geworden. 47 Schlaganfall.\nDas gab es in einer der Berliner Zeitungen, suche ich gleich nochmal raus für\ndie Shownotes, da gab es eine kurze Würdigung nochmal und ich habe ihn in der\nTat viel lieber gehört, als dass ich mit ihm diskutiert habe.\nAlso absolut legendär, das würde ich auch gerne gleich in die Shownotes nochmal reinwerfen,\ndas finde ich sein Interview in den Elementarfragen mit Rainer Langhans,\nalso damals Kommune 1 und ich bin ja so ein verhinderter Alt-Hippie,\nich bin ja sauer, dass ich nicht bei 68 dabei sein konnte, Mangelsalter.\nUnd was er da mit dem ja doch völlig verschrobenen und schon irgendwie doch\nin seiner sehr sehr eigenen Welt lebenden Rainer Langehans, was sie trotzdem\nda für ein Gespräch, ich glaub zwei Stunden oder sowas geht das ungefähr,\nzusammen kriegen, ganz toll.\nDas kann man sich, finde ich, immer noch wunderbar anhören. Für mich eine ganz\npersönliche Sternstunde des deutschen Podcasts.","Ja was für ein Vogel, da fang ich jetzt nicht mit an,\nich hab auch so eine Story mit ihm, aber er hat noch beim Podcast Mikrodilettanten,\nda hat er so einen Laber Podcast gemacht, Zusammen mit Gero und Phil,\nda war ich einmal dabei mit Holgi, da haben wir das Intro gesquattet,\ndas war so ein gespielter Witz, das war ganz gut.\nUnd der hat ja mit Holgi auch sehr viel zusammen gemacht.\nJa Nikolas, das ist schade und insofern sagen wir liebe wohl und tschüss.\nSeine Stimme ist noch da und Podcasts werden auch in 500 Jahren noch gehört, auch Deine.\nSo kommen wir zu unserem Feedback, da gab es so einiges.\nJa, viele Kommentare, schön, dass ihr wieder da seid, das hat uns sehr gefreut.\nDu hast aber auch im Nachgang noch rund um die Mastodon Social Media Diskussion\nnoch das eine oder andere ausgefochten.","Ehrlich gesagt gar nicht so viel, also wir haben, ich hab eben mal gezählt 140\nKommentare im Blog, dazu noch ungefähr 50 auf Mastodon.\nNichts auf Twitter, was ich als persönlichen Erfolg verbuche,\nda haben wir die Publikation ja quasi auch totgeschwiegen.\nDas auf Mastodon, das war alles natürlich alles flauschig und friedevoller Eierkuchen,\nweil Preaching to the Choir, das war natürlich erwartbar, dass sie das gut fanden,\ndass wir das Thema da mal aufgreifen.","Endlich hört uns einer.","Es gab im Blog in der Tat einen schönen Hinweis von einem Björn,\nnämlich dass es durchaus einen Weg gibt, auf Mastodon in seinem Namenshändel\neine eigene Domain unterzubringen.\nOhne dass man eine eigene Instanz betreiben muss. Und das ist auch nicht irgendein\nkruder Hack, sondern das ist in der ganz offiziellen Doku von Mastodon,\nkann man sich das angucken.\nTechnologie dahinter ist Webfinger, man legt also eine JSON-Datei,\nsehr übersichtlich, sehr kurz, irgendwo auf einen Server, dessen Domain man\ngut findet und wo man halt entsprechend Zugriff hat auf dieses Well-Known-Verzeichnis.","Der RFC ist von 2013, das ist also schon abgehangen.","Gut abgehangen, genau. Und dann kann man in der Tat.","Lange ignoriert und jetzt endlich wieder ins Gespräch gekommen.","Kann man eine der Schwächen oder diese Derate von Mastodon damit eben ausgleichen,\nwenn du dann die Instanz wechselst und dann normalerweise deinen Namen dann\nauch wechseln müsstest?\nUnd mit der Methode kann man sich quasi dauerhaft einen konstanten,\nstabilen Namen besorgen.\nDas schmeißen wir mal in die Schaunotes rein. Danke Björn für den Hinweis dazu.","Jetzt gibt's ja auch Blue Sky, aber wir haben alle noch keinen Invite bekommen.","Ja wir sind nicht hip genug, eindeutig. Also ist das von einem der Twitter Gründer?","Ja von dem Jack Dorsey einst, der hatte mal so eine Phase wo er wirklich der\nMeinung war Twitter müsste ja eigentlich dezentralisiert und frei und open sein.\nIch werde aus dem Typen eh nicht schlau also er ist für mich ein totales Mysterium\nirgendwas dazwischen ich verstehe ihn überhaupt nicht und teilweise hatte ich\nso den Eindruck dass er doch noch alle beisammen hat aber ich bin mir nicht\nso ganz so sicher ob das überhaupt geht in dieser Szene.","Ist auch glaube ich hart in der Kryptoblase abgetaucht und unterwegs und auch\nnie wieder so richtig hoch gekommen.","Ja das ist halt das Problem, also die sind irgendwie alle so ein bisschen verspult so,\naber ab und zu kommt ja auch mal was interessantes bei raus und dieses Blue\nSky war ja dann so ein Proposal,\ndas hing da so ein bisschen in der Luft und ist ja dann durch diese Übernahme\nvon Twitter ohnehin so ein bisschen unter die Räder gekommen,\naber dann haben sie Ende letzten Jahres dann tatsächlich irgendwie eine Gruppe\nangefangen das wohl umzusetzen und jetzt gibt's das als App, ist das richtig sehr?","Nur als App derzeit, keine Webseite und Invite only.","Genau, invite only, das kennen wir ja schon.","Wir nennen uns Clubhouse.","Genau und das ist auch so ähnlich wie Clubhouse, also sie machen auch so invite graphs und so weiter,\nalso müssen wir mal gucken inwiefern sie dann sozusagen auch so Punishment machen\nfür du hast hier die ganzen Idioten reingeholt, du darfst jetzt hier gar nichts\nmehr und so, also das wird nochmal ganz interessant.\nKlar kann sein, dass das so yet another social media fail wird,\nkennen wir das Internet?\nWar das jemals schon mal anders? Leute probieren halt Dinge und dann gucken wir mal ob's passiert.\nAber ich würde auch noch nicht sagen, dass das Ding jetzt schon durch ist.\nWie, wer, wer sozusagen, also ob Twitter Relevanz behält?\nSeine Relevanz, also irgendeine Relevanz wird es behalten,\naber es hat natürlich seine, un, nicht das falsche Wort wählen,\nalso die die Relevanz die es hatte, hat es jetzt nicht mehr,\naber es ist noch keiner da der mehr Relevanz hat.","Es ist noch nicht MySpace.","Es ist noch nicht genau es ist noch nicht MySpace, es ist noch nicht von irgendwas\nkomplett überrollt worden, es ist halt nur scheiße.","Ich würde sagen es kommt ein bisschen auf die Domäne an, also wie wir in der\nletzten Sendung auch versucht haben hoffentlich ein bisschen rauszuarbeiten,\nwenn du beispielsweise den deutschen Wissenschaftsbetrieb anguckst.","Du wolltest sagen Blase.","Ja das nennt man so, kann man da ganz wertfrei, kann ich da auch von Blase sprechen,\nvöllig okay. Es sind trotzdem irgendwie ein paar tausend Hansel,\ndie jetzt irgendwie halt die deutschen Digital Humanities dort ganz gut zusammenbringen\nauf Art und Weise wie sie es auf Twitter nicht gemacht haben.","Ich rede aber jetzt schon von\nGlobal Appeal, nicht von irgendwo in Deutschland gibt es ein paar Leute,\ndie finden das geil, sondern halt, dass das sozusagen,\nweil ich meine das war so meine, mein Gefühl als ich auf Twitter gestoßen bin,\nwar, das wird der globale Chat, das ist der Ort, wo sich die Welt unterhält.\nVielleicht ein bisschen hyperbolisch, aber ich denke so ganz falsch habe ich\ndamit nicht gelegen. So, es war...\nTweets im Fernsehen.\nDonald Trump hat gesagt, Obama twitterte, oh mein Gott,\nhier ist irgendwas passiert, das sind die ersten Reaktionen auf Twitter,\nalso das ist nicht mit Facebook passiert, das ist nicht mit YouTube passiert,\nTwitter war schon der Ort und ist es auch noch gerade so.\nUnd jetzt müsste halt irgendwas kommen, was in der Lage ist,\nTwitter da so wirklich final die Eier abzuschneiden.\nUnd ob Mastodon dazu die Power hat, da habe ich noch meine Zweifel.\nEs ist eine super Lösung für viele Communities, es löst viele Probleme,\ndie andere Leute mit Twitter hatten und die gesehen haben, Twitter war nie das\nrichtige für mich, aber das ist das richtige für mich.\nWunderbar ja trotzdem ist es noch nicht der Kampf um diesen globalen Chatraum,\nder ist noch nicht, der hat noch nicht angefangen oder wenn dann liegen die,\nalso da ist die Armee noch nicht im Boot.","Bin mir nicht sicher ob es den\naber auch überhaupt nochmal geben wird so beziehungsweise auch geben muss,\nalso Blue Sky ist im Moment halt ne ziemlich US Geschichte so da machen sie\njetzt gerade richtig Hype, Also mit den Klammern muss man auch mal sagen derzeit\nglaube ich 50.000, 55.000 Accounts.\nAber die sind natürlich alle sehr laut, weil sie natürlich irgendwie halt,\nhast du auch schon gesagt, der Social Graph ist natürlich jetzt schon sehr Premium,\nden sie da jetzt gerade am Start haben.","Jetzt kommen wir erstmal ganz im Problem.","Genau, das zieht natürlich schon, aber das hatten wir wirklich ja eins zu eins\nbei Clubhouse, letztendlich kann man sich ja wirklich angucken wie sowas läuft\nund die entscheidende Frage für mich wird sein,\nschaffen sie irgendwann mal den Sprung, den Clubhouse nicht oder viel zu spät\ngeschafft hat, nämlich von diesem Invite-Oni da mal weg zu gehen und wirklich\nirgendwo in den Mainstream rein zu kommen.\nUnd zum anderen dieses Versprechen, naja wir sind ja auch dezentral,\nwir setzen ja auf dem AT-Protokoll auf, was grundsätzlich erstmal Dezentralität verspricht.\nDann guckt man sich aber an, okay, Anzahl der Server vom BlueSky exakt eins.\nSo das heißt also es gibt derzeit nur diese eine zentrale Instanz,\nwas alle als großen Gewinn feiern,\nweil hey, endlich ist man wieder alle beisammen und man hat diesen einen Kommunikationsraum\nund ich muss mich darum kümmern wem folge ich,\ndamit ich von der anderen Instanz was mitbekomme, ja gut und schön aber dezentral,\nderzeit ist es eine Blaupause, ein Versprechen, was erstmal eingelöst werden\nmuss und wie sie dann mit Trollen, Nazis, whatever umgehen und das ganze Moderationsgame\ndann anfangen irgendwie zu spielen ist halt auch noch völlig unklar.","Ist das dezentral im Sinne von Mastodon oder ist das nur so ein Rubberstamping?","Das ist so wie ich's verstanden habe quasi schon so ein Alternativprotokoll\nund grundsätzlich könnte man die beiden glaube ich sogar bridgen.\nAlso ist es nicht Fediverse, also Mastodon ist ja wiederum nur eine Implementierung\nvom Activity-Pup-Protokoll.\nUnd das AT-Protokoll ist schon was anderes, aber wäre nicht so,\ndass man das nicht durchaus auch über Apps zusammen integrieren könnte.\nSo jetzt mein Stand, ohne dass ich mich jetzt allzu tief damit beschäftigt hätte.\nAber derzeit haben die halt da null Interesse dran, weil sie wollen halt erstmal ihren Hype-Train.","Und haben die ein Business-Modell dann?","Nobody knows.","Crickets and tumbleweeds.","Das beantwortet ja wahrscheinlich schon mal viel.","Haben sie denn wenigstens Startup-Kapital?","Was sie auf jeden Fall wohl haben ist eine ganz gute Onboarding Experience.\nAlso wie fühlt sich die App an, wenn ich jetzt so im Zero State vorbeikomme\nund noch nichts ist eingerichtet.\nDas machen sie wohl ganz gut. Wobei ich auch da sagen muss, wenn man jetzt die\naktuelle offizielle Mastodon App installiert oder wenn man hier Ivory installiert,\nalso den Tweetbot Nachbau oder Ice Cubes, die haben auch schon echt gute Onboardings mittlerweile.\nAlso das Mastodon Onboarding jetzt im Mai 2023 ist nochmal ein ganz anderes\nals im Januar 2023 selbst war.\nAlso da würde ich dann auch nochmal gerne die beiden Systeme nebeneinander halten.\nViele, die jetzt das Onboarding von vor drei Jahren im Kopf haben von Mastodon\nund sagen so, oh das ist jetzt alles so viel besser hier bei Blue Sky,\nja macht euch nochmal einen neuen Account und macht das mal über die offizielle App.\nDa wirst du eigentlich schon genauso auch auf deinen zentralen Server erstmal\nhingeleitet und folgt mal folgenden Leuten, die sind hier hip unterwegs.\nSo viel anders ist das glaube ich nicht. Aber I may be wrong.","Ja wird sich zeigen. Also ist auf jeden Fall interessant, dass es da nochmal\neinen neuen Ansatz gibt.\nSie versprechen ja auch sowohl eine chronologische als auch eine algorithmische\nTimeline und sie versprechen auch komplette Portabilität einschließlich des\nContents. Was wir wiederum Masterdon nicht.","Also...","Kann gut sein, dass es auch auf so eine Art technologischen Wettbewerb hinausläuft\nund vielleicht ist am Ende die Lösung ja sozusagen the merge of all this,\nso who knows, also könnte könnte noch interessant werden.","Also der Schöpfer von Mastodon hat ja gerade jetzt vor zwei drei Tagen auch\nso ein bisschen die Roadmap jetzt für Mastodon rausgegeben und es wird eine\nSuche über alles geben und es wird Quoting geben von Toots, hell freezes over.","Das heißt Prost.","Also das sind natürlich schon Reaktionen darauf so okay da draußen die Welt\nbleibt nicht stehen und man wird vielleicht das ein oder andere Dogma dann doch mal über Bord werfen.\nIch hoffe sie machen das alles mit Opt Out. Also meine Wunschvorstellung wäre\ndas erstmal alles aktiviert ist und aber eben die Communities die sich davon\nabkoppeln wollen und die einfach einen Schutzraum brauchen,\ndass die also mit einem einfachen Klick sich aus den Sachen raus opten können.\nDas denke ich wäre schon sinnvoll.","Ich glaube, dass die Zukunft von Twitter eher im Twitter-Headquarter entschieden\nwird, als bei Mastodon oder Blue Sky, ehrlich gesagt.","Also es wird sterben.","Naja, sagen wir mal so, wenn sie den Kurs beibehalten, den sie jetzt haben und\nalles kurz und klein kloppen, dann wird es kurz und klein sein.","Das meinte ich damit.","Also ich glaube, solange es Mastodon jetzt gibt und wie wenig das Relevanz hatte,\nbis Elon da mit seinem Waschbecken eingeritten ist bei Twitter,\nzeigt halt auch ganz deutlich, warum Mastodon jetzt so groß ist,\nweil Twitter so scheiße geworden ist.","Definitiv. Alright, so dann gab's noch ganz viel Feedback zum Thema, Tim hat's ja nicht alle.","Wer würde ihm widersprechen?","Was erlaube Tim so und ja ich hab das mit Interesse gelesen,\nwas da alles so gemeint wurde zu meinen Auslassungen über das objektorientierte\nParadigma und so weiter und es gab ja da auch diverse längliche Kommentare,\ndie irgendwie ja versucht haben ein wenig diesen Case zu machen,\nwas man immer gerne so hört mit so ja aber in meiner Sprache kann ich das auch\nalles machen und so schlimm ist es ja nicht und das was ihr da macht in euren\nfunktionalen Programmiersprachen das ist ja am Ende auch nur OOP also gehabt\nalle möglichen Darstellungen,\nmuss aber zugeben, dass mich relativ wenig davon wirklich nennenswert überzeugt\nhat was da so kam und vor allem gab es ein paar interessante Missverständnisse und das Kern,\neins der auffälligsten Missverständnisse war und das habe ich glaube ich auch nicht so ausgeführt.\nEinmal nochmal vielleicht worum es mir ging und was das auch konkret bedeutet.\nAlso ich habe ja die ganze Einlassung in das Thema,\nOkay, poemieren und wo stehen wir denn sozusagen mit Poemiersprachen heutzutage\nund warum ich auch der Meinung bin warum Objektorientierung relativ wenig bietet\nfür das was wir heutzutage so benötigen?\nUnd es einfach nur deshalb gemacht wird, weil es da ist und weil alle davon\nreden, war ja das Problem mit der Nebenläufigkeit.\nUnd Nebenläufigkeit ist von vielen auch so ein bisschen unter diesem Aspekt\nvon Parallelität wahrgenommen worden.\nAlso man hat ja so dieses Ja-Multichor und da heizt dann alles parallel und\ndu meinst ja auch, Audio ist ja eine schlechte Anwendung, weil das kann man\nja nicht parallelisieren und so weiter.\nDas mag alles richtig sein, dass das in einzelnen Fällen nicht parallelisierbar\nist, aber Parallelisierbarkeit ist nochmal ein ganz anderes Thema.\nUnd ein schönes Gleichnis, was ich gefunden habe, ist, also der Unterschied\nzwischen Nebenläufigkeit und Parallelisierung ist in etwa der.\nParallelisierung ist, wenn fünf Leute parallel ein Ikea-Bett zusammenschrauben.\nJeder sein eigenes Bett. Das ist so volle Parallelisierung.\nNebenläufigkeit ist, wenn fünf Leute ein Ikea-Bett zusammenschrauben.\nUnd dann hängt es sehr viel damit zusammen,\nwer hat schon die Schrauben ausgepackt, ist die Tüte schon aufgemacht,\nwo liegen denn jetzt die Schrauben, wann brauchen wir denn die Schrauben ganz genau,\nin welcher Reihenfolge machen wir das, wo legen wir das Holz hin,\nwenn wir gerade nicht dran arbeiten müssen, wer jetzt da drüber gestolpert ist,\nist das jetzt das Richtige, hab ich das verwechselt, oh scheiße ich muss nochmal\nin den Nebenraum, wo sind denn jetzt nochmal die Schrauben, hab ich überhaupt das richtige Werkzeug.\nMan verliert so viel Zeit in diesen kleinen Übergängen,\nin diesen Kanten, wo die eine Arbeit in die andere Arbeit übergeht und wo vor\nallem verschiedenste Akteure sich unterschiedlichen Teilproblemen zuwenden müssen und die teilweise,\nJa jetzt könnte ich sagen parallel, nebenläufig sind, also ich kann die Schraubentüten öffnen.","Du musst parallel sagen, aber es ist klar du kannst die Schraube nicht reinschrauben\nbevor nicht die Tüte aufgemacht wurde wo die Schraube drin ist.","Genau, aber es ist nicht parallel die selbe Arbeit, sondern es sind Dinge die\nim besten Fall auch parallel laufen, aber nebenläufig sind in der Definition,\ndass sie erstmal so nichts miteinander zu tun haben.\nSie haben keine unmittelbaren Abhängigkeiten so lange bis das eine das andere\nanfordert oder bis das eine nicht mehr weitermachen kann bevor das andere nicht da ist.\nUnd diese ganzen kleinen Pausen, die sind so ein bisschen das Ärger des,\ndass einfach die Systeme heutzutage einem relativ wenig in die Hand geben,\num genau das zu optimieren.\nUnd das ist halt das Problem mit nahezu allen Programmiersprachen,\ndie alle in irgendeiner Form Single-Threaded sind,\ndie einfach nicht generell von sich aus Parallelität fördern oder Nebenläufigkeit\nfördern und das war sagen wir mal der Punkt den ich gemacht habe und warum ich\nauf das Erlang Ökosystem verwiesen habe,\nweil das so eine Grunderkenntnis war beim Design von Erlang.","Ich würde das vielleicht ein bisschen verfeinern, weil es geht da zwar auch\num das Funktionale, aber vielmehr noch um das, was in der Erlangenwelt OTP heißt.\nAlso das ist eine Art Framework, um aktorbasierte Programmierungen zu machen.\nAlso man denkt von Grund auf nur an Aktoren, die sich gegenseitig Nachrichten schicken.\nDas hat jetzt erstmal direkt nicht so viel mit funktional oder objektorientiert\nzu tun. Es gibt zum Beispiel auch in der JVM-Welt in Skala Acker,\ndie ein ähnliches Modell machen.\nMit Objekt orientiert und da das Enablen, das hat aus meiner Sicht,\ndas habe ich auch lange gemacht, auch Probleme, weil die JVM nicht darauf ausgelegt ist.\nUnd das ist der große Vorteil von Erlang aus meiner Sicht. Das ist,\ndas ganze System ist von Grund auf aufgebaut, um ein Aktoren-System und auch\nwenig anderes zu unterstützen.\nDas fängt vom Debugging an, aber auch wie das ganze System startet,\ndie Error-Trails und wie auch mit Messages und so weiter umgegangen wird.\nEs gibt auch Implementationen in anderen Sprachen, also ich bin jetzt neulich\nüber Ergo gestolpert, das ist quasi OTP in Go nachgebaut, auch eine interessante Entwicklung.\nAber das würde ich mal sagen ist auch aus meiner Erfahrung das,\nwas im Kern diese Nebenläufigkeit, aber jetzt kommt es auch die Parallelität sehr enabled,\nalso sehr viel möglich macht, weil man halt Den State, den man hat,\nder in einem Akto gehalten wird, automatisch, den Zugriff darauf automatisch\nserialisiert durch die Nachrichten, die reinkommen, die dann auch verarbeitet werden.\nDas erleichtert, wenn man es richtig baut, auch das Testen und so weiter.\nDas ist, glaube ich, der Kern und auch da die Sprache und das Ökosystem auf\nviel verzichtet, ist man sozusagen auch gezwungen, in bestimmten Arten und Weisen zu denken.\nMan denkt, wo hat man State, wo ist der in meiner Anwendung,\nApplikation verbaut? Und davon geht's los, weil das baut man in seine Aktoren\nrein oder Genserver, wie es in Erlang beziehungsweise Alexir genannt wird.\nUnd darauf aufbauend baut man dann halt seine Anwendung.\nDas hat auch sehr viele Vorteile, wenn man Ressourcen hat, die von verschiedenen\nStellen gebraucht werden, dann kümmert sich ein spezieller Prozess nur um diese eine Ressource.\nUnd Leute können anfragen, bekommen zweifelne Antwort, aber auch die Ressource,\ndie hat für sich immer eine Ordnung, in der das kommt.\nDas heißt, man geht einer bestimmten Art von Race Condition aus dem Weg,\nwenn man nicht aufpasst, schafft man sich andere Probleme, wenn man 15 Aktoren\nhat, die sich in komplizierten Art und Weise Nachrichten schicken,\nkann das auch zu unvorhersehbaren Konstellationen führen, das stimmt auch.\nAber erstmal grundsätzlich ist das ein Modell was auch für das was wir machen\nsehr sehr gut passt und eine ganze Klasse an Fehlern erstmal ausschließt.\nAuch so ganz einfache Sachen wie Memory Management. Also du hast halt da deine\nAktoren, alles was da drauf gebaut wird stirbt zusammen mit dem Aktor.\nDas heißt wenn du so ein Request hast der reinkommt, Da macht er was für den\nSpieler oder was auch immer die App macht und dann stirbt der Prozess,\nnimmt alles Memory und so mit sich mit und vorbei ist es. Das heißt dann ist\ndas alles vergessen. Wenn er crasht, ist nur das eine kaputt.\nDas sind einfach so Grundprinzipien, die da sehr, sehr helfen bei Systemen,\ndie sehr parallel und auch nebenläufig arbeiten.","Wie kam es denn zu dieser ganzen Orientierung auf Alyx hier bei VUGA für die\nGameserver? Also was war denn da so der treibende Faktor und was wurde denn da früher verwendet?","Also früher, als wir, da hatten wir auch noch sehr sehr, wo wir sehr viele Spiele\nhatten, sehr schnell und kurze Entwicklung,\nda hatten wir wirklich viele verschiedene Sprachen im Backend.\nTeile davon waren auch Erlang und damit haben wir für bestimmte Anwendungen\nauch gute Erfahrungen gemacht.\nDann gab es auch Ruby, es gab auch andere Sprachen, es gab auch Scala und anderes und es kam am Ende da,\nso die guten Erfahrungen mit Ruby und mit Erlang waren halt in LXIR vereint\nund das haben wir uns dann halt damals angeguckt, das hat also A zu dem gepasst,\nwas wir in der Firma konnten.\nEs hat aber auch unseren, so ein\npaar Schmerzen, die wir mit Erlang hatten befriedigt, aber auch mit Ruby.\nAlso es ist auch so, dass in der LXC-Welt sehr, sehr viele Leute von Ruby,\nvon Rails kommen, also auch sehr viel diesen Geist mitbringen,\nder auch teilweise sehr viel Gutes hat. Nicht alles, aber teilweise.\nUnd dann war es einfach, von da an hat sich das bewährt. Also wir haben nur\nnoch gewartet, bis LXC 1.0 draußen war.\nVorher haben wir da nichts mit wirklich gemacht, aber dann haben wir uns langsam\nran getestet und das war dann, hat von Anfang an gepasst.\nUnd nach wie vor gibt es bei uns seitdem wir das machen auch wenig Suche nach\nAlternativen in anderen Sprachen und sowas, was es ja auch immer gerne gibt,\ndass man dann nach was anderem guckt.","Und jetzt haben wir auch, also für… Also ihr sucht nicht, weil ihr keine Probleme damit habt?","Genau, mit der Sprache und dem Oexos System haben wir jetzt keine großen Schmerzen,\nalso das löst alle Probleme und noch mehr, die wir haben.","Ihr habt den richtigen Nagel für den Hammer.","Ja, so kann man das natürlich sagen, also wenn wir andere Sachen machen würden,\nda gibt es viele Anwendungsbereiche, wo das nicht das Perfekte wäre, das stimmt natürlich.\nAber ich, also vor allen Dingen auch der Bereich, der erweitert sich gerade\nmit Alex hier. Also eine Sache, die wir jetzt haben, also wir haben auch sehr\nviele, ich nenne es mal Admin Interfaces.\nAlso Interfaces, wo Leute, die irgendwas mit dem Spiel machen,\nmit den Backends interagieren, von uns intern, was mit den Servern machen wollen\nund dort, da benutzen wir seit einiger Zeit Liveview. Das ist so ein neues Paradigma\nder Webentwicklung, sage ich mal. Also so ein bisschen.\nEs hat ja angefangen mit Static Generated HTML, das war so das Klassik PHP wie\nwir es kennen, du hast auf eine Form geklickt oder einen Link und dann hat sich\nwas neu gerendert über Templates im Backend.\nDann war das natürlich nicht dynamisch genug, wir wollten sehr viele Dinge tun\nund da ging es halt bis hin zu diesem Single Page App mit JavaScript,\nwo man quasi nur noch einen riesen Application lädt und Live View ist so ein\nbisschen der Weg in der Mitte.\nMan muss dort, man rendert wieder Seiten im Backend und hat eine JavaScript-Komponente\nim Client, die quasi die Diffs nur ins Frontend rendert.\nDas heißt, man hat quasi wieder ein Template im Backend, was man rendert,\nwas man dynamisch updatet und dann hat man in diesem Framework ein Diff-System,\nwas sich das HTML-Diff ausrechnet und das über Websockets an den Client pusht.\nDas ist ein sehr, sehr guter Mittelweg für einige Anwendungsbereiche,\nwo man dynamische und auch sich ständig updatende HTML Seiten haben will.\nAlso man wird damit jetzt nicht Google Maps entwickeln oder sowas,\naber sehr viele dynamische Sachen kann man halt besonders auch sehr schnell entwickeln.\nDashboards zum Beispiel. Das haben wir massenweise und gerade halt auch schnell\nund auch dynamisch kann man da sehr viel und schnell machen und das ist auch so eine Sache,\ndie wir getestet haben und das hat uns halt einen ganz neuen Horizont erschlossen,\nweil wir auch gerade im Backend halt immer, wir haben halt irgendwelche Frontends\ngebaut, aber eigentlich wollten die Leute Backend machen und dann braucht man\ndiesen ganz anderen Mindset, da muss man erst eine Javascript Pipeline aufbauen,\ndas ist ja auch eine ganz andere Sache.\nDas hat ja auch seine Eigenheiten, das Ökosystem, ich sag's mal so.\nDann fängst du an da den State, also es gibt ja auch genug coole Anwendungen,\ndie damit geschrieben werden, aber es hat halt auch Probleme,\ngerade wenn man einfach nur ein bisschen dynamisches Dashboard schreiben will\nund dafür eignet sich das halt perfekt, weil du halt dann auch wieder im Backend\nhast du für jede Website oder jeder View, der aufgebaut wird, einen Aktor im Backend,\nDer hält das virtuelle DOM für\ndiesen einen User und da kannst du halt im Backend über Event und sowas,\nwie du das halt dann auch mal deine Applikation aufbaust, dieses virtuelle DOM\nupdaten und du hast dann halt das Live-Reframework, was dafür zuständig ist\noder was dann den kleinen Ansicht, was der Nutzer im Browser sieht, halt für dich updatet.\nUnd das ist halt auch wieder sehr gut widergespiegelt in LX hier und der ganzen,\nja man muss sagen in der Beam, also der Virtual Machine von Erlang mit diesem\nAktormodell und was das kann.\nDazu ist natürlich in der ganzen Architektur von Erlang dieses Aufrechterhalten\nvon tausenden, hunderttausende Millionen aktiven Netzwerkverbindungen so ein\nbisschen so ein Heimspiel. Also das ist das was es kann.\nUnd das heißt da kann man gerade diese Dinge auch mit abdecken und mittlerweile\nwird dieses Paradigme von Liveview auch von anderen Frameworks,\nalso von anderen Sprachen auch benutzt, also in der Ruby Welt wurde sowas nachgebaut,\nes gibt mit Livewire auch sogar was von PHP, da gibt's eine lange Liste, in Go gibt's auch was.\nUnd gerade bei Ruby, also sind die darüber gestolpert,\ndass halt zum Beispiel, dort kann nicht so mit Prozessen umgegangen werden,\ndas funktioniert einfach nicht, das war auch tatsächlich eine der Motivationen von Chris McCord,\nalso das ist der Gründer oder der Autor des großen Webframeworks Phoenix,\nder hat das probiert in Ruby zu bauen und ist dann gescheitert.\nUnd dann führte eins zu anderem und Jahre später gab es dann halt Phoenix.\nGab auch noch andere Gründe, aber das ist eine der Geschichten,\ndie er erzählt. um mal diese Idee von Live.io umzusetzen, weil die Idee gab\nes schon viel, aber das...\nMan braucht so ein bisschen die Foundations von Alexia, um das wirklich gut\nund auch in großen Skalen umsetzen zu können.","Also Live.io ist wirklich eine große Sache in dieser Alexia Welt.\nAlso generell wenn man so in die Alexia Welt reinschaut, da hast du halt erstmal\nso die Sprache so in unison mit dem Erlangen Ökosystem,\nDas ist das, was da so generell erstmal die Foundation ist für das Grundinteresse.\nDas ist so das, was alle primär dahin zieht. Dass du diese Stabilität hast und\ndass du eben dieses Betriebssystem quasi in deiner Sprache hast.\nDass du so eine konkrete Vorstellung hast von Prozessen und das sind alles so\nFirst Class Objekte in deiner ganzen Sprache sind.\nAber dann das zweite große Ding ist halt dieses Phoenix Web Framework,\nwas halt einfach das Entwickeln von Webseiten einfach super einfach macht.\nAlso das hab sogar ich hingekriegt.\nIch hab keine Ahnung von Webdevelopment, aber das ist einfach zu naheliegend\nund wenn man erstmal die anderen Prinzipien drin hat, dann ist das mehr oder\nweniger so ein Abfallprodukt.\nAlso man kriegt einfache Webseiten sehr sehr einfach hin.\nUnd dann dachte ich so, oh ja, dann gibt's ja noch dieses Liveview und das ist\njetzt bestimmt voll kompliziert und dann stellt man fest so,\nne, gar nicht,\ndas macht dann sogar noch komplexere Anwendungen sehr einfach,\nweil du auf einmal es nur noch quasi mit einem Aktionsort zu tun hast,\nalso alles befindet sich auf dem Server und der Server hat einfach eine klare\nVorstellung davon, was auf dem Bildschirm auf der Webseite ist.\nUnd ich weiß nicht, ich hab den Vergleich letztes mal schon gebracht,\naber ich sag's nochmal, das ist im Prinzip so ein bisschen die Wiedergeburt des Unix-Terminals.\nAlso so wie du früher unter Unix eine Anwendung gemacht hast,\ndie so im Unix Betriebssystem Multi-User lief und das beste Beispiel ist...\nSo wenn du immer guckst, okay, Programmiersprachen und Frameworks,\nwas ist so die Standard-App, die so als erstes Beispiel geliefert wird,\nda hast du dann so jahrelang Taschenrechner gehabt, so mit Force und so weiter,\nbis das dann irgendwann nicht mehr ging, dann war's irgendwie die To-Do-App,\ndas hält sich irgendwie auch noch bis in die Neuzeit.\nUnd bei Liveview ist dann so immer so dieses, ah jetzt machen wir mal ein Multi-User-Chat.\nSo ein Multi-User-Chat, das wirfst du so mal eben so aus der hohlen Hand.\nDu hast alles da, was du brauchst, diese ganze Kommunikation,\nmehrere User kommunizieren, jeder hat seinen eigenen View, alles updatet sich\nin Realtime, das ist so in Liveview ist das einfach, da musst du noch nicht\nmal groß drüber nachdenken, wenn du das halbwegs verstanden hast,\num das da so hinzuwerfen.\nUnd ich finde das sagt schon so einiges darüber aus auf welcher Komplexitätsebene\nman hier überhaupt einsteigt,\nohne dass es, also Komplexität im Sinne von des Ergebnisses,\nwas du aber relativ einfach mit den Bordwerkzeugen angehen kannst und von da\nstartest du dann sozusagen in komplexere Welten rein und das ist wirklich ein\nkomplett neues Paradigma.\nMan muss auch dazu sagen, es löst nicht alle Probleme von Web-Anwendungen,\nalso wenn du, du hast ja schon gesagt, so Google Maps, also alles was so highly\nlocal interaction hat, ne, wo du so viel unmittelbare lokal anwendbare Events\nhast, also direkt Objekte, ähm.\nBewegen muss und viele Operationen hast, die halt so unmittelbar im Code des\nJavascript-Interpreters im Browser laufen,\nohne jetzt Serverinteraktion zu haben, aber in dem Moment wo das was du siehst\nprimär eigentlich auf dem Server existiert und so ein shared state ist,\nDann wird's wiederum sehr einfach mit Liveview solche Anwendungen zu machen\nund das kann man sich auf jeden Fall mal anschauen,\ndas kann viele sehr komplexe Setups,\nwo man mit, ja jetzt brauchen wir hier so eine Single Webpage App und React und tralalala,\ndamit das irgendwie alles eine gewisse Fluktuizität hat und dann müssen wir\nnoch ein Protokoll machen und dann haben wir noch unsere Datenbank und GraphQL\nund so weiter, um was relativ einfaches zu bauen.\nUnd sowas kannst du mit Liveview eigentlich da beiseite fegen und sagen so nee scheiß drauf,\ndas machen wir einfach alles im Server und diese schnellen Updates in der Webseite,\ndie pushen wir halt einfach von hinten da rein und dann passt das schon.\nAlso das ist schon eine interessante Welt die sich da auftut.","Und man muss kein Javascript schreiben. Also da war ich ja schon überzeugt.","Das ist nicht das Beste.","Ich glaub an der Stelle könntest du sogar mich kriegen.","Und was nicht heißt, dass du kein JavaScript zur Anwendung bringen kannst.\nAlso in diesem LiveView Framework hast du halt so ein JavaScript Framework,\nin dem du einfach nur noch sagst, hier füge mal das JavaScript ein,\nwas man braucht, um X zu machen, um irgendwas zu toggeln oder so.\nUnd das wächst die ganze Zeit so an.\nSchade ist noch, dass man, wo es wirklich noch eine Grenze gibt,\ndass man noch nicht das so targeten kann, dass man sagen wir mal LXJ-Code richtig\nim Browser auch laufen lassen kann.\nIn den Kommentaren gab es auch einen Verweis auf so ein Talk von F sharp über über F sharp,\ndas ist so diese Microsoft Funktional Sprache die so in diesem C sharp dot net Ökosystem drin ist,\nalso F sharp ist so zu C sharp so wie Scala zu Java sag ich mal ganz so in etwa ja in etwa.\nUnd ich hab mir den Talk angeschaut, weil der wurde in den Kommentaren gepostet\nmit dem Hinweis der würde ja zeigen, dass man da auch mit objektorientierten\nParadigmen irgendwie was anfangen kann.\nIch hab mir den Talk angeschaut aber auch nur festgestellt,\ndass er eigentlich auch gesagt hat, ja ne wir machen nur Objektprogrammierung,\nwir machen aber nicht Objektorientierung, weil Objektorientierung ist nämlich\nMist und die Idee von Objekten und dann haben wir halt diese Dot-Syntax,\ndie finden halt alle so toll.\nUnd das ist halt auch der einzige Grund warum man das immer macht,\nweil die Leute es halt gewohnt sind eine gewisse Syntax zu sehen.\nAber in diesem F-Sharp, deswegen erwähne ich das jetzt gerade,\ndie haben nämlich die Möglichkeit, das heißt ich hab vergessen wie das dann\nheißt, quasi aus F-Sharp-Code unmittelbar JavaScript-Code zu erzeugen.","Ja, also es gibt sogar eine Implementation oder Versuch,\nalso auch Beam in WebAssembly, also in den Browser laufen zu lassen,\ndas hat jetzt gerade jemand, das von Scala, das gibt's auch schon seit Ewigkeiten,\ndas gibt's in allen möglichen Varianten.\nDas weiß ich nicht, wie sehr das die Lösung ist, weil man muss ja dann,\nalso meine Erfahrung zum Beispiel mit Scala.js war auch dann,\nsobald man in der Interaktion mit dem eigentlichen, mit den nativen APIs und\nverschiedenen anderen Art und Weisen kommt, wird es dann wieder sehr komplex\nund unintuitiv, weil man dann doch wieder,\nJa, sich in fremde Umgebung begibt. Man hat dann halt eine Sprache,\ndie komplett anders ist, ganz andere Paradigmen hat und trifft dann doch auf\ndieses am Ende die JavaScript Umgebung.\nUnd es wird halt auch teuer und groß, was man da baut.\nUnd so mit Zwang eine Sprache woanders laufen zu lassen, als wo sie gedacht\nhat, also es mag dafür so Edge Cases geben, aber ich hab da noch wenig wirklich\nsinnvolles für gesehen, dass das am Ende funktioniert.","Ja vor allen Dingen so cross-kompilierte Sachen sind immer extrem schwer zu debuggen.\nDu schreibst Code in der einen Sprache und musst sie aber in der anderen Sprache debuggen.","Und dann ist es keine hundertprozentige gleiche Umgebung, also du schreibst\ndann Scala oder was auch immer dann in Javascript und dann gibt's irgendwelche\nSachen, die dann doch anders funktionieren und dann willst du aufhören.\nDas hört sich auf Papier so schön an. Du schreibst Code, der überall gleich ist und dann,\naber es ist in der Praxis, zumindest ist meine Erfahrung, ich hab damit auch\nnur ein bisschen rumgebastelt,\nwar jetzt nicht sehr positiv und das mit,\ndas ist auch mit Elixieren-Browser glaube ich ähnlich,\nda würde ich sogar im Zweifel eher dann sagen, wenn man so Accelerate,\nalso im Client Accelerated Sachen machen will,\nwürde ich dann eher das, was du meintest, diese JavaScript-Hooks in Liveview\nnehmen zum Beispiel oder dann vielleicht auch TypeScript nehmen oder sowas,\nda gibt es ja mittlerweile auch schon Weiterentwicklungen, aber halt etwas,\nwas mehr für das Ökosystem gedacht ist.\nDa kommt man glaube ich langfristig weiter, weil es dann halt auch die ganzen\nLibraries und alles drum dran gibt, die man dann braucht.\nAlso man darf nicht unterschätzen, wie sehr man im Browser, also was unterschätzen,\nman muss halt ganz viel mit dem DOM, mit HTML interagieren und das ist schon\nkomplex, diese ganzen Funktionen und das macht halt nun mal Javascript oder TypeScript am besten.\nJa also es ist so, es gibt halt no silver bullet, also das ist eine der Sachen\ndie ich auch schmerzhaft lernen muss.","Tja naja, auf jeden Fall lohnt sich das anzuschauen und falls ihr irgendwie\nAlexej Poamira in Berlin seid dann schaut doch mal im X-Heim rein,\nda gibt's auf jeden Fall Interesse.\nIch könnte mir gerne auch eine Mail schreiben, vielleicht kriegen wir da ja\nnoch ein Treffen mal zustande, das fände ich ganz cool.","Also wir hatten schon so ein paar ad hoc mini Meetups oder so,\nalso wo sie einfach Gespräche entwickelt haben darüber.","Weil du hast ja auch im XR eine ganze Menge mit LX hier dann realisiert.","Oh ja, ja das ist auch so ein ganz anderes System, ich weiß nicht wie tief wir\njetzt da reingehen wollen, das ist NERVS, das ist so die komplett andere Ecke,\ndas ist für Embedded System.\nDa gibt es mittlerweile auch ein LXC Framework, was ich auch nur aus Spaß mal\nausprobiert habe und das läuft auch ziemlich gut.\nDamit habe ich zum Beispiel das Türschließsystem gebaut für ein X-Hine,\nwas soweit ich weiß auch mittlerweile andere Hackspaces benutzen.\nIm Endeffekt ist das nur eine Mini-Firmware für ein Pi, wo man halt quasi sich\nmit einem SSH-Key authentifiziert.\nAlso du hast auf deiner App oder sonst, du hast halt einfach eine SSH App,\ndie macht SSH Add und dann wirst du halt reingelassen, wenn du den richtigen\nKey hast oder also dein Key zugelassen wurde.\nUnd das Gute daran ist, weil Alexi oder Erlang halt da ist, es läuft halt immer.\nAlso es startet sich neu, wir haben davor irgendwelche Skripte mit Debian und\nsonst was da drauf gehabt und es ist immer irgendwie gecrashed.\nUnd jetzt halt mit diesem Nerves, das ist glaube ich 20 Megabyte groß,\ndas lädt sich einmal von der SD-Karte in Memory, läuft dann in Memory,\nholt sich dann noch so eine signierte Liste mit den Keys runter und dann läuft\ndas halt einfach. Und seitdem wir das haben, sind wir sehr glücklich.\nGeht's und das ist auch auf GitHub, das ist im X-Halm, GitHub kann ja gleich\nmal den Link da reinschmeißen.","Ja das machen wir.","Not very much lines of code und da hat sich dann auch wieder ein anderer Aspekt\nvon Erlang gezeigt, das ist halt wie du ja auch gesagt hast,\ndas ist im Prinzip ein kleines Betriebssystem, das hat auch SSH implementiert,\nich hab mir das auch mal vorher angeguckt, ob es auch abgehangen ist, ja ist es.\nDas heißt das hat eine eigene SSH Implementation die man da nutzen kann.\nIst ein bisschen, muss man sich\nreinlesen, die API ist ein bisschen kompliziert sag ich mal aber es geht.","Aber zu NERVs kann man vielleicht nochmal ein paar Worte sagen weil das ist\nnämlich so eine der interessanten, von mehreren interessanten Entwicklungen\nin diesem ganzen Elixier Öko System ist um halt den Reach noch ein bisschen zu erweitern.\nAlso da merkt man schon, dass über Phoenix, das Webframework und eben speziell\nauch über Livewire erweitert sich gerade der Einsatzrahmen doch erheblich.\nAlso es dringt sozusagen in Bereiche vor, in die Erlang bislang überhaupt nicht reinkam.\nUnd NERVS ist halt auch so ein Ding weil es eben quasi eine bequeme Runtime\neröffnet auf so Embedded Devices.\nLäuft ja nicht nur auf dem Pi sondern es läuft auch noch auf dem Beaglebone\nund anderen aber das sind im Wesentlichen so die Plattformen die unterstützt werden.\nUnd wenn man sich das halt baut, dann sagt man halt im wesentlichen so hallo\nich habe ein paar Versionen was auch immer drei vier so mach mir mal eine Firmware\nund dann kompiliert er quasi ein komplettes Linux,\nAber so total strip down auf die 20 MB, die du schon gesagt hast,\nalso wirklich so das absolute super minimale Linux, was du benötigst,\nnur um eine Elixier, also eine Erlang Runtime auf dem System zu fahren.\nBrennt dir das dann sozusagen direkt in so ein Image und das schreibst du dann\neinfach auf eine SD-Karte,\nsteckst rein, schaltest das Ding an und dann bootet der irgendwie da rein und\ndann kannst du da sofort irgendwie mit SSH drauf und kannst irgendwie deinen\nCode zum Laufen bringen,\nsagst aber hier ist meine App, die starte mal und dann läuft das so.\nSoweit so unbeeindruckend, das coole ist, dass es dann halt schon auch darum\nwiederum so ein Ökosystem gibt, wie zum Beispiel Nerves Hub,\nwo du dann so eine Software hast, wo alle deine Devices, also du hast jetzt\nirgendwie ganz viele von diesen Dingern,\nDann hast du immer das Problem, du willst die Firmware aktuell halten,\ndu willst irgendwie gucken was machen die,\nlaufen die gerade, was ist damit und so, liegen irgendwo alle irgendwo rum,\nhaben zwar alle irgendwie Internet, aber überall SSH und gucken und was ist\ndenn damit und sich eine Mail schreiben lassen und so weiter,\nda wirst du ja irgendwie bekloppt.\nDann kannst du halt diesen Nerves Hub nehmen und dann können sich diese Geräte\ndort anmelden und du hast so einen Ort,\neben diesen Hub, wo du all deine Devices siehst,\ndu siehst was online ist, was offline ist und wenn du dann eine neue Firmware hast,\ndann wird die automatisch eingespielt, du kannst auch Firmware Updates über\nSSH einzeln einspielen,\naber dieses ganze Management und dann wird's auf einmal interessant,\nman hat jetzt nicht vielleicht 50 Türen, die man so administrieren muss,\naber man kann das natürlich für jeden Scheiß verwenden.\nUnd dann hast du eben wieder diesen Vorteil von dem Erlang-System,\ndass es halt so super stabil ist und dass du einfach den Code so on the fly\nändern kannst, neue Firmware drauf, Software-Update.\nZur Laufzeit musst du nicht wirklich was runterfahren der Code wird einfach\nausgetauscht und dann läuft das irgendwie weiter und du hast immer so alles\nso im Überblick und das ist irgendwie eine relativ starke Bewegung in diesem\nganzen LXDR Ökosystem und dann gibt's noch so ein paar andere Sachen auch für\nandere User Interfaces,\nScenic ist etwas was sich dann in diesen Embedded Devices auch so als User Interface,\nAPI anbietet, noch so ein paar andere Entwicklungen also da ist auf jeden Fall\neine ganze Menge am Laufen also wer da mit IoT rum baut findet da eine Menge.","Also das ist auch wirklich gerade ein interessanter Zeitpunkt im Elixir Ökosystem.\nDas ist jetzt schon wirklich mature, gerade mit Phoenix im Kern,\ndem Web Framework hat sich jetzt auch über die letzten Jahre wirklich sehr viel\nin die Breite entwickelt, neue Sachen, ein ganzes, ich glaube das Thema lassen\nwir vielleicht heute mal aus.\nAber der ganze Machine Learning, da gibt es ein komplett eigenes System und\nMöglichkeiten Modelle und so weiter auch in LXI laufen zu lassen,\ndas ist auch super interessant, da kann man auch sehr schön mit rumspielen,\naber das ist glaube ich nochmal ein eigenes Thema.\nDas macht auf jeden Fall sehr viel Spaß und es ist auch schön zu sehen wie das in die Breite geht.","Naja, wir kommen auf jeden Fall noch auf ein paar andere Hacker-Themen zu sprechen,\naber wir kommen auch auf Machine Learning zu sprechen.","Moment mal, kannst du meinen Kopfhörer mal ein bisschen leiser machen?","Leiser, aber sicher doch.\nJa ich lade trotzdem mal das Thema ein und dann kümmer ich mich da drum,\nweil ich nach einem anderthalb Jahr nicht mehr weiß, welche Knöpfe ich drücken\nmuss, Tim drückt auf seinen Puls, wenn der Stream gleich weg ist.\nGenau ich übergebe mir mal an Ralf weil wir wollten ja jetzt mal die Diskussion\nnachholen die wir letztes mal nicht gemacht haben denn wir müssen ja jetzt mal\nschauen ob der Untergang naht.","Oder die Erlösung.","Oder die Erlösung. Oder irgendwas dazwischen. Ja was kommt denn jetzt einfach.\nJa wir müssen über Chet-GPT reden und alles andere.","Ja in der Tat ist es mir ein Anliegen, um mal gleich die Latte hoch zu legen.\nEs ist glaube ich in der Tat überhaupt wirklich der Grund warum ich hier sitze.\nWeil als du mich gefragt hast so hm, Freakshow, wäre das nicht mal was?\nWäre vom Vierteljahr meine Reaktion gewesen, oh anstrengend und arbeitet in\nArbeit aus und ob wir uns da vertragen und so weiter.\nAber es geht einfach nicht mehr, weil wir müssen über AI und Chat-GPT und dieses\nganze Thema reden und vielleicht auf eine andere Art und Weise als es da draußen in 53.000,\nBlogbeiträgen und Postings und sonst wie passiert.\nVielleicht kurz zu mir, wer spricht und warum maße ich mir an,\njetzt überhaupt hier so ein Thema zu moderieren?\nIch programmiere selber keine Machine Learning Modelle, wir haben aber in meinem\nReferat das, ich glaube, im deutschen Bibliothekswesen größte Drittmittelprojekt\nzum Thema Machine Learning laufen, das ist BMBF finanziert.\nUnd da bekomme ich natürlich dann doch so das eine oder andere mit.\nUnd seit ChatGPT im November rausgekommen ist,\nbeschäftige ich mich pro Tag, würde ich sagen,\nso netto ungefähr eine Stunde damit, in dem ich zum einen wirklich versuche,\nalles leer zu lesen, was irgendwo an einigermaßen relevanten Publikationen erscheint,\nan Meinungsbeiträgen, was auch immer, und probiere in der Tat auch viel und intensiv selber aus,\num ein Gespür dafür zu kriegen, Was passiert da eigentlich gerade und was kann\nes und was kann es nicht und was würde das für uns alle bedeuten?\nUnd vielleicht können wir erstmal so einen ganz kleinen Crashkurs machen so in Grundlagen.","Bist du zahlender Kunde?","Da sprichst du in der Tat einen wunden Punkt an. Ich habe es mir quasi für die Sendung gekauft. Echt?","Nur für die Sendung?","Naja, also nicht wirklich nur für die Sendung. Ich habe lange gezögert,\nweil ich das politisch eigentlich für das falsche Signal halte.\nAlso ich warte eigentlich auf eine Open Source Implementierung eines Large Languages.","Auch für die könnte man ja bezahlen.","Die würde ich dann auch sofort bezahlen.","Achso.","Also ich habe Chat-GPT4 mir quasi jetzt geshoppt, um auch einfach die Unterschiede messen zu können.","Das ist so mein zweiter AI Dienst für den ich Geld bezahle tatsächlich.\nIch bin einer von denen und was ist mein erster AI Dienst, für den ich Geld bezahle?","Mit Journey?","Ne.","Siri?","Indirekt ja. Dazu komm ich.","Ist das intelligent?","Das ist die Frage. Ah ok.","Ne muss man überlegen.","Da schreibt jemand auf Phonic.","Ja gut auf Phonic macht jetzt auch so ein bisschen auf AI, aber ist nicht in\ndem eigentlichen Also, ja...\nIch bin natürlich auch Aufonik Kunde und die benutzen mittlerweile auch AI aber\ndas war jetzt nicht initial der Grund bei Aufonik einzusteigen.\nNa, naheliegend. Deep L.","Bezahlst du? Ja. Okay. Weil du irgendwie über die API das Zeichenlimit irgendwie brauchst oder?","Weil ich zum Beispiel sehr viel ukrainische Webseiten nachschlage und es gibt nicht so viel,\nwas ukrainisch kann und überhaupt so lange Texte,\nalso gerade so Artikel in fremder Sprache, wo ich einfach mal wissen will,\nwas geht ab so und dann hast du hier mal bulgarisch und da mal irgendwie komplexes\nspanisch und pipapo und Deep L ist wirklich fantastisch.\nUnd es hilft einem halt auch sehr, auch wenn das jetzt nicht mein Daily Use Case ist,\naber wenn man halt auch mal wirklich was formuliert und nach guten Übersetzungen sucht,\nentweder ins Deutsche oder eben auch in eine andere Sprache,\ndann ist es halt mit DeepL dann doch sehr einfach dann auch so Varianten zu\nfinden, dass du auch wirklich genau den Punkt hast und so.\nAlso das Lohn ist, ich hab da jetzt keinen Gewinn dabei, Aber bei Chat GPT hab\nich nicht lange zögern müssen, weil ich halt mit diesem 3.5,\nschon verdammt interessante Ergebnisse hatte und dann als die Vierer im Angebot\nwar und quasi nur über den Bezahlzugang zu erreichen war,\ndass ich mir so scheiß drauf irgendwie, ich brauch das jetzt und bereue auch\nbisher nix, weil es für mich die bessere Suchmaschine geworden ist.","Der Unterschied ist schon dramatisch. Also kurz zu DeepL, den liebe ich in der\nTat auch seit Stunde eins.\nIch bin noch nie da an die Bezahlschranke gestoßen, dass ich also irgendwas\ndavon wollte, was mit der kostenlosen Version nicht gegangen wäre.\nWas ich insbesondere empfehlen kann, guckt euch das mal an, wenn ihr den Dienst\nauch ab und zu mal nutzt, der hat jetzt so einen Modus, du gibst dann von dir\nirgendwie formulierten englischen Text rein, mach mir den in noch besseres Englisch.\nDas mag ich sehr gerne, so eine Grammatiküberarbeitungsfunktion in DeepL.\nDas ist so auf der Startseite so ein bisschen nach unten in die Mitte gescrollt.","Ist das Premium oder ist das?","Ne das ist auch, kann man auch umsonst nutzen. Das ist eine Sache die ich wirklich\nfast noch häufiger nutze als die, genau besser schreiben mit DeepL Write.\nDa gibst du also links einen englischen Text rein und dann kriegst du Varianten.\nIm Englischen ist alles kürzer, alles\nprägnanter, als du es eigentlich im Deutsch-Englisch schreiben würdest.\nDas nochmal so als Tipp, feine Sache, aber auch das kann man sich natürlich\nvon ChatGBT auch gut schreiben.\nNee, also bei ChatGBT habe ich lange gezögert, weil eigentlich will ich denen kein Geld geben.\nDas war so jetzt überhaupt nicht die Geldfrage an sich, weil ich gebe für so\nviel Quatsch irgendwie monatlich Geld aus, da wäre das noch nicht der Punkt gewesen.\nAber auf der anderen Seite bin ich da jetzt wirklich so in der Phase,\nokay wie soll ich meinen Kindern der einst erzählen, dass ich da nicht irgendwie,\nwo warst du als GPT 4 raus kam.\nUnd alles was ich bisher damit so an Erfahrung gesammelt habe bestärkt mich\ndarin, dass der Sprung von 3,5 auf 4 ist schon erstaunlich. Ich bring gleich ein paar Beispiele.\nDamit sind wir auch schon so ein bisschen in der Historie. Also das GPT kommt\njetzt nicht irgendwie so aus dem Nichts, sondern das ist bekanntlich jetzt gerade schon Version 4.\nMan kann sich da auch die Historie angucken. 2017 ist das Ganze gestartet mit\nden verschiedenen Versionen und das was halt im Wesentlichen immer gesteigert\nwurde, war so die Anzahl an verarbeiteten und gespeicherten Informationen.\nUnd die Grundlogik ist halt eigentlich relativ simpel, nämlich es geht nur um Text.\nGWT 4 kann jetzt auch Bilder, aber das würde ich sagen, klammern wir heute mal\nganz aus, weil das ist auch mit Stable Diffusion und Midjourney noch mal ein\nganz eigenes Rabbit Hole, in das wir, glaube ich, gerne mal in einer anderen\nFolge nochmal absteigen können, aber heute müssen wir uns, glaube ich,\nein bisschen komprimieren, was das angeht.\nAlso es geht um Text und es werden irrsinnige Mengen an Text halt analysiert,\nin Tokens zerlegt und dann wird quasi in einem Selbstlernprozess Prozess muss\nalso ein neuronales Netz lernen, Lückentexte aufzufüllen.\nDas heißt also, man nimmt irgendeinen Text, der schon da ist,\nder ist dann auch Ground Truth, das ist also das, wo man hin will,\nund man nimmt in der Mitte ein Wort raus und die KI muss raten,\nwelches Wort da wohl eigentlich reingehört. Und das macht sie immer und immer\nund immer und immer wieder.\nDann habe ich erstmal so ein Grundtraining und ein Grundverständnis davon,\nwie quasi Sprache funktioniert und mit welcher Wahrscheinlichkeit das nächste\nein spezielles Wort ist, von mehreren, die natürlich immer zur Auswahl stehen.\nUnd dieses Grundmodell wird dann nochmal sehr aufwendig und das ist dann quasi\njetzt der eigentliche Feenstaub, den JET-GBT dort dann drauflegt oder GPT-4.\nWer dann nochmal wirklich händisch mit in der Tat hauptsächlich Arbeitskräften\nin Afrika angeworbenen und speziell trainierten,\ndas kann man sich auch alles ganz gut durchlesen, was das wieder für Probleme\nalles impliziert, dann nochmal wirklich monatelang handgetunt.\nIst jetzt Antwort A besser oder ist Antwort B besser?\nUnd das, was am Ende bei ihm steht, ist nicht irgendwie eine Abbildung der Welt\noder irgendwie ein Logiksystem oder sowas wie Wolfram Alpha,\nwo also irgendwo quasi so Logik-Patterns oder Strukturen hinterlegt sind,\nsondern es ist einfach ein riesiges, großes neuronales Netz von Wortwahrscheinlichkeiten.\nUnd was dieses System dann halt tut, ist, dass es auf Fragen oder Kommandos\nantwortet. Man tippt Text rein und bekommt halt vom System eine Antwort.\nUnd so mein Aha-Erlebnis hatte\nich in der Tat wirklich dann bei einer Weihnachtsfeier letzten Jahres,\nwo ich mich dann halt mit einem von unseren promovierten MLern ein bisschen\nunterhalten habe und der hat den Satz gesagt,\ner fände es höchst verwirrend, was für fantastische Ergebnisse mit einem so\nsimplen Ansatz zustande kommen.\nWeil dort eben nicht irgendwelche Entitäten modelliert werden,\nwie funktioniert die Welt, was ist ein Auto, was ist irgendwie eine Person,\nwas ist die Weltgeschichte, das ist quasi das exakte Gegenteil von dem,\nwas wir so im Bibliothekswesen immer versucht haben, Semantic Web irgendwie aufzubauen,\nso was sind die Bedeutungen, ja Wikidata, wir strukturieren irgendwie die Welt\nin Datenpakete, das ist das Gegenteil davon, man sagt einfach hier Well,\nhier System, da sind alle Texte, die in der Menschheit jemals geschrieben worden sind.\nWelche genau in das Training reinfließen ist da nicht so hundertprozentig klar.\nIch werfe mal einen Link rein, das zumindest eine ganz gute Annäherung ist von\ndem worauf das textmäßig eigentlich so basiert.\nAber mehr ist da eigentlich nicht. Da fragt man sich schon so,\nwoher kommt das jetzt? Warum kann diese KI trotzdem so souverän und fantastisch\nirgendwie auf Dinge antworten, obwohl sie doch von gar nichts irgendwie eine Ahnung hat.\nUnd da gibt es halt jetzt, finde ich, so einen Grundwiderspruch,\ndass nämlich die Kritiker und Zweifler und Sorgenträger halt sagen,\ndas ist ja alles nur Statistik und das ist ja alles nur irgendwie halt Wortstatistik,\nda ist ja jetzt gar kein Geist oder Sinn oder Verantwortungsgefühl oder irgendwas dahinter.\nUnd dafür kann es dann aber irgendwie dann doch ganz erstaunlich viel.\nIch weiß nicht, habt ihr diesen Begriff von Stochastic Parrot?\nIst der euch irgendwie über den Weg gelaufen? Also es gibt einfach so ein paar\nKampfbegriffe, die jetzt so\nauch in der Twitter und Mastodon Debatte immer wieder hochgezogen werden.","Also der Begriff Papagei fällt generell viel im Zusammenhang mit Stochastik.\nHab ich jetzt noch nicht so gelesen, aber ja im Prinzip ist es ja genau das.","Genau das ist ein Paper das ist sogar schon relativ alt. Können wir auch mal\nin den Chat reinwerfen. Und das ist so ein bisschen.\nMach mal. Ja gucke mal eben. Also erstmal werfen wir den Link rein wo man gucken\nkann was ist alles in das Lernmodell reingeflogen.\nDas ist der hier.","Nur was im Chat landet, landet auch in den Shownotes.\nAber nicht alles was im Chat landet, landet in den Show-Notes.","So das ist jetzt hier der untere Artikel,\ndas ist das Paper, das kann man sich wirklich mal durchlesen,\ndas sind glaube ich so 15, 20 Seiten.\nDas ist auch schon mal eine Leistung ja.","Emojis for the win.","Also wir sehen hier publiziert, 1. März 2021, das war so deutlich vor Chat-GBT.","Aber nicht vor GBT, sondern GBT2 und so weiter gab's ja schon.","GBT2, 3 gab's schon. Und der Punkt, den sie machen, kann man auch im Abstract\nschon sehen, würde ich sagen, ich wiederhole mich, ist goldrichtig.\nSie sagen nämlich, okay, durch die ganzen Texte, die da reingegeben werden,\nwerden auch die ganzen Vorurteile und werden die ganzen Stereotypen,\ndie sich in diesen Texten abbilden, alle mit reingezogen und Wertemuster.\nUnd Texte und Bücher sind nun mal im Wesentlichen von weißen privilegierten\nMännern geschrieben worden, in nicht unerheblichem Maße.\nUnd viele Bereiche dessen, was so die WeltTM ausmacht, ist dort eben nicht abgebildet\nund das ist eine Gefahr und darüber müssen wir reden.\nAlles total richtig, unterschreibe ich alles, aber das hat nichts mit einem Papageien zu tun.\nVersuchen halt über die Überschrift jetzt so eine Diffamierung eines von Leistungen\ndarüber, um halt irgendwie ihr Paper wissenschaftlich irgendwie zu positionieren.\nDas zweite was man häufig hört ist mansplaining is a service.\nHabt ihr das schon mal gehört?","Aber es beschreibt es sehr gut.","Siehst du?","Nein.","Das wird sehr bestimmt falsch sein. Das ist sehr bestimmt falsch sein.\nMensplaining ist hoffentlich bekannt. Das Breitbeinige, wozu wir hier in der\nMetaebene übrigens auf unseren Stühlen alle gezwungen werden.\nDas männliche, breitbeinige, vielleicht in der U-Bahn, sitzende,\nso ich erzähle euch jetzt mal wie die Welt funktioniert und besonders gerne\nerzähle ich das noch Frauen.\nAlso mansplaining, ja auch wenn die es überhaupt gar nicht wissen wollen und\ndann auf seiner Meinung beharren, selbst wenn man es mit einer Expertin für\ngenau das Feld zu tun hat, na ich hab aber trotzdem recht und ich kann es ja\ngerne deine Meinung haben.\nSo und in der Tat, so in der November Dezember Release, also in der ersten von\nChat-GPT 3.5 zu dem Zeitpunkt, war diese Attitüde durchaus spürbar.\nDas heißt also, wenn Chat-GPT da offensichtlich einen Unfug geschrieben hat\nund man dann ihm freundlich darauf hingewiesen hat,\nhatte ich also wirklich etliche harte Debatten so, nein, nein,\ndas ist auf jeden Fall so und sie übersehen X, Y und sowas und Quatsch bleibt\naber nunmal Quatsch, egal wie er sich dagegen gewährt hat.\nDas haben die meiner Wahrnehmung nach mit ihrer Februar Release fast nahezu\nvollständig abgeschaltet, also behoben bekommen.\nAlso im Gegenteil, wenn man jetzt Fehler anmahnt, haben sie irgendwas an ihren\ninternen Routen geändert, dass man jetzt sehr sehr viele Antworten bekommt.\nOh ja, vielen Dank für die Korrektur, ich hab nochmal nachgeschaut,\nda haben sie natürlich recht und ich hätte berücksichtigen müssen, dass.","Das heißt also da ist innerhalb von wenigen Wochen quasi,\nist dort schon irgendwo eine Evolution wieder gewesen aufgrund von einem Kritikpunkt und dieses so,\nwobei man dazu sagen muss, Servil ja, so und es ist auch schon ein bisschen\nanstrengend und wenn man ihn drum bittet nicht mehr so niederknien zu sein, Dann passieren Dinge.\nEr macht es trotzdem und ich kann auch gleich nochmal ein schönes Beispiel liefern,\nwo Chat.GPT für mich auch die neue Version 4 komplett gescheitert ist an einem sehr trivialen Ding.\nSollten wir vielleicht auch nochmal drüber reden, wofür es funktioniert,\nwofür es nicht funktioniert.\nJa ja, Mansplaining ist es auch.","Danke für den Chat, das in der U-Bahn ist Manspreading, das ist bei mir semantisch\nnahe beieinander verankert, aber es nennt sich das gleiche, also das ist das\nmentale Manspreading, bekommt aber auch Mansplaining in der U-Bahn, wenn man genau zuhört.\nAber danke für die Präzisierung.\nGenau das ist mich jetzt quasi das dritte Missgrundverständnis was.\nAlso ja es gibt dieses Mansplaining.\nMit der Vierer glaube ich viel weniger als vorher. Trotzdem gibt es das.\nDas heißt ja aber nicht, dass man nicht trotzdem zu 80 Prozent nicht Mansplaining\nAntworten dort rauslocken kann, die eben korrekt sind.\nUnd ich bin immer etwas zurückhaltend so diese Fail Antworten so in den Vordergrund\nzu rücken und das was schon gut funktioniert dem gegenüber irgendwie so nach hinten zu schieben.\nWir können jetzt mal ein paar praktische Beispiele uns mal so zuwerfen.\nDas, was ich gemacht habe, ist, wir haben ein neues Sachgebiet,\nwas wir bei uns an der Stabi einrichten wollen, bei mir.\nUnd im Wissenschaftsbereich oder in den ganzen Kulturdingen sind halt Akronyme\ntotal hip, immer noch. Das heißt also du hast irgendwie eine Abkürzung und jeder\nBuchstabe steht für etwas.\nWas ich halt gemacht habe ist, ich habe JettGPT beschrieben,\nwas dieses Sachgebiet macht und habe gesagt, jetzt schreibt mir nochmal zehn\nAkronyme dafür und löst die auf, wie ich dieses Sachgebiet nennen soll.\nUnd das macht er dann. Und zwei bis drei davon waren schon richtig gut auf den ersten.","Das könnte die Raumfahrt retten, weil die Raumfahrt will auch immer geile Akroben\nhaben, aber die Auflösungen sind teilweise haarsträumend.","Naja und so richtig glücklich war ich aber noch nicht so und was machst du halt?\nDu sagst dann halt gib mir mal noch zehn.\nSo und dabei bekomme ich schon so einen leichten Stich in der Magengrube,\nweil das ist doofe Arbeit.\nSo das heißt also hier ist schon, findet bei mir selber schon so eine Projektion\nstatt so, oh mein Gott diese arme KI muss sich jetzt mit so einem blöden Job hier rumärgern.\nNicht wahr oder? Machs bitte trotzdem. So und dann kriegst du halt die nächsten\n20 und dann denkst du dir so, ach was soll der Geiz.\nSo Achtung gib mir mal noch 50, bezieh die 20 die du schon hattest mit ein und\nschreib zu jedem noch einen kurzen Abschnitt und rank die ganzen in wo du selber\nmeinst was vom besten zum schlechtesten und schreib noch einen kurzen Kommentar\ndazu warum du denkst, dass es auf dieser Ranking Position richtig ist.\nFantastisch gelöste Aufgabe. Was ich dafür für eine Werbeagentur für Geld drüber\ngeschoben hätte für diesen Schritt und dann zu sagen das ist alles Mansplaining\nund das ist alles nur irgendwie ein Papagei der irgendwas nachplappert.\nJa, diese Probleme gibt es, aber ihr müsst auch wirklich mal schauen,\nwas auf der anderen Seite schon für eine Komplexität und für eine Effizienz\nund was das für eine Kreativmaschine ist.\nSo und wenn man sich die Akronyme anguckt, würde ich sagen, so ein Drittel davon\nhat gar nicht funktioniert. Das war überhaupt dann gar nicht die Auflösung der Buchstaben.\nIst ja aber egal, ich brauche am Ende ja nur einen.\nDas heißt also, hier kommen wir plötzlich auch auf eine Ebene,\ndadurch dass die Queries quasi so billig sind, jetzt die Energiediskussion mal\nweg, das wird auch alles lokal auf unseren iPhones laufen in zwei, drei Jahren.","So billig ist das nicht, für meine 20 Dollar kriege ich nur 25 Abfragen in drei\nStunden. Da muss ich wieder warten.","Ja das wird sich lösen, also da kann man wirklich gucken,\nwie gesagt die Debatte führen wir heute nicht, aber im Imaging Bereich,\nwenn du dir anguckst, Table Diffusion läuft jetzt halt wirklich,\nalso quasi mit Journey artiger Dienst, nicht ganz auf dem Niveau aber fast,\nläuft lokal auf meinem Iphone in der Neural Engine.\nDa gehe ich nicht mehr auf irgendeinen Server irgendwo hin, sondern solange\nich nur Strom habe, kann ich dort lokal genau die Sachen machen, das wird mit den LLMs.","Läuft der auf dem Mac auch auf den Neuroengine jetzt? Herz.\nIch krieg immer nur scheiß Bilder bei Stable Diffusion.","Wir machen da mal eine Sonderfolge dazu, weil da bin ich wirklich ganz gut drin.","Genau Bilder in Podcasts das ist überhaupt das Beste.","Ja dann kriegen wir dich vielleicht auch dazu mal Kapitelbilder zu machen.","Also wenn das hinhaut, dass ich wirklich sage ich brauche jetzt hier ein schönes\nKapitelbild für meinen Dingsbums, wo ich sonst nix habe, dann kann man darüber\nnachdenken aber bisher wäre mir das echt zu viel Arbeit.","Schauen wir mal, hast du Transkript reingegessen und da kommt das Kapitelbild.","Ja Transkript reingegessen habe\nich schon probiert aber eben sind die Transkripte zu lang, wer meckert da?","Pass auf was du ihm genau sagst was er tun soll, mach mir mal ein Kapitelbild\nfür mein Dingsbums, ich weiß nicht so genau ob das.","Naja das ist ja der neue Job, die neue Jobdescription heutzutage,\nalso immer wieder gibt's neue Berufe und du weißt was jetzt so der AI Beruf ist, man ist jetzt was?\nPrompt Designer. Das ist jetzt sozusagen, das ist dann die nächste Stufe oder Prompt Wizard.\nPrompt Architekt. Ja das kommt noch, das kommt noch, Chief Executive Prompter.","Dahinter steckt ja aber so hinter diesem Prompt Engineering steckt ja genau\nein Mechanismus, der mich völlig\nkalt erwischt hat, dass das geht und zwar dieses sogenannte Priming.\nDas heißt also, was ich eben beschrieben habe, diese, oder jetzt Chat-GBT ist\ntrainiert auf einem Text-Korpus aus dem Jahr 2000, der am Jahr 2021 stoppt.\nSo alles danach kennt es quasi nicht.\nUnd jetzt kann man aber halt jetzt hier und heute mit ihm reden und es gibt\neben zwei Dinge, die wirklich anders sind als alles, was man vorher irgendwie\nim KI-Bereich hatte. hatte. Das erste ist Persistenz.\nDas heißt, man hat eben eine Unterhaltung, wo ich auf den ganzen bisherigen\nVerlauf der Unterhaltung voll rekurrieren kann.","Im Rahmen dessen, was an Speicher dafür freigestellt ist, was so viel nicht ist.","Was so viel nicht ist, aber so eine Session, quasi so eine Chat Session,\nda hab ich es noch nicht geschafft, die jetzt quasi auszureizen an der Stelle.\nUnd das ist halt so diametral anders als das, was bei Siri passiert,\nkommen wir ein bisschen später noch zu, zu ChatGBT und Kinder.\nBei Siri fängst du immer wieder bei Null an, bei jedem einzelnen Kommando.\nAlso Siri erzählt dir irgendwie Quatsch und du sagst nein, nicht so,\nsondern anders und sie lernt halt irgendwie überhaupt nichts dazu.","Das hab ich für dich im Internet gefunden.","Und dann findet sie noch nicht mal was sinnvolles.","Nein das ist zum kotzen.","Wir kommen gleich noch dazu.","Ja das ist die richtige Berufsbezeichnung. AI Promptmaster.\nDrunter geht's schon gar nicht mehr.","Das klingt aber wie so eine Kiste aus China die man bestellen kann für 5 Euro. Garley Express.","So und die Frage ist halt so wie funktioniert das eigentlich?\nDass man plötzlich so ein echtes Gespräch führen kann und eine Persistenz der\nArgumente auch wirklich hat?\nWeil du kannst also sagen, guck dir nochmal deine Antwort von vor zwei Minuten\nan, ist nicht vielleicht XY stattdessen.\nUnd das reagiert absolut souverän darauf. Und ich hab das einfach mal Chat-GPT\nselber gefragt und die Antwort ist relativ simpel, quasi mit jeder neuen Query\nwird halt alles was du vorher geschickt hast quasi als Text-Korpus auch im Hintergrund mitgeschickt.\nAlso jetzt etwas vereinfacht gesagt, in Wahrheit ist es schon wieder in Tokens\nzerlegt und nochmal etwas anders abgespeichert,\naber der Kontext wird halt mit jedem größer, aber der bleibt immer stabil und\ndas wird immer mit hingegeben, das heißt also unter Berücksichtigung von.\nSo und daraus leitet sich jetzt aus dieser Persistenz, dass sich also obwohl\ndas Modell selber statisch ist, ich quasi immer wieder was oben drauf setze\nund die Konversation erhalten bleibt, kannst du halt dann diese sogenannte Priming umsetzen.\nDas heißt, dass du schreiben kannst, so du bist jetzt ein 5-Jähriger,\nerkläre mal die Handlung von Star Wars 1 und zwar so wie es ein 5-Jähriger tun\nwürde und dann versetzt du eben Chat-KPT in so einen Modus,\nder versucht dann also wie ein Theater-Schauspieler das möglichst authentisch\nnachzuahmen aufgrund dessen was er halt in seinem neuronalen Netz als was sind\nso die Kommunikationswege eines 5-Jährigen und so der Wissensschatz und dann fängt der an,\ndas entsprechend reinzuschreiben und das hat große Auswirkungen darauf, wie gut die.\nQualität von Antworten ist, wenn man einen Priming davor einsetzt.\nAlso Priming heißt so, ich versetze dich erst in einen Zustand und dann agierst\ndu in den darauf folgenden Kommunikation unter dem Eindruck dessen,\nin was für einen Priming ich dich gesetzt habe.\nUnd da wo ich das zum ersten Mal auf YouTube im Einsatz gesehen habe,\nist das war hier bei der Firma von meiner Frau, sehr nett.\nEiner der Kollegen hat das mal wirklich dann live vorgeführt in einer in der\nPräsentation, wo es darum ging, zähl Chat-QPT, zähl mal die Sicherheitsregularien für XY auf.\nUnd dann kam eine Antwort raus und die war zu 90 Prozent Quatsch.\nDas stimmte einfach nicht. Man hatte denselben Satz gesagt mit dem davor.\nAchtung, du bist jetzt Sicherheitsexperte für Thema XY.\nFühre bitte die Regularien für XY auf. Und dann kriegst du plötzlich eine Antwort,\ndie sehr sehr signifikant besser war, im Sinne von zu 80% korrekt und noch zu 20% Quatsch.\nSie hatte immer noch 20% Quatsch, aber alleine durch dieses Priming,\ndu agierst jetzt in der Rolle von, fühlte sich also jetzt hier Chat-GPT gemüßigt\nbeispielsweise halt irgendwo wissenschaftliche Quellen ranzuziehen und zu zitieren und zu gucken,\nokay, was sind jetzt irgendwie denn wirklich Gesetzestexte zu dem Thema oder\nwas sind jetzt irgendwelche RFCs oder sowas.\nEs hatte also eine ganz sofort spontan ersichtlich komplett andere Qualität.\nUnd dieses Priming ist etwas, was ich nicht für möglich gehalten hätte,\ndass das technisch funktioniert.\nIch habe vor, ich glaube, sieben Jahren, acht Jahren oder sowas,\nmit MS Pro mal eine Keynote gehalten für eine Digital Humanities Tagung.\nUnd da war so eine der Dinge auch KI und wie das eigentlich weitergehen wird.\nUnd da hatten wir so als ein Modell, von dem wir denken, dass wir es noch erleben\nwerden, den Modus, schreibe eine Novelle im Stil von Bertolt Brecht zum Thema Internet.\nSo war es also. Tu so, als seist du Bertolt Brecht und schreibe halt jetzt irgendwie ein Drama dazu.\nUnd da dachte ich so, ach, so in 40, 50 Jahren, vielleicht habe ich Glück.\nSo das geht, das ist da.\nDas war eine der Sachen die ich in meiner ersten Nacht mit ChetGPT gemacht habe.\nAchtung du bist jetzt Berthold Brecht, schreibe ein Streitgespräch zwischen\ndir und Elon Musk über den Untergang von Twitter.\nDas war ein total schöner Text, der da rausgefallen ist, weil er so brecht dann\neben mit der Arbeiterklasse und der Unterdrückung und die Freiheit und so weiter.\nUnd Musk halt, was hatte ich denn, das zweite Priming, was ich da noch reingesetzt\nhatte und Elon Musk agiert auf dem Niveau eines Fünfjährigen,\ndas war ein besonders schöner Dialog.\nDu kannst natürlich auch beliebig viele dieser Primings ineinander schachteln\nund quasi aufeinander irgendwie clashen lassen und wo ich dann wirklich sold war,\nwar als ich den Prompt hatte, schreib einen Sketch.\nIm Stil von Monty Python mit Mastodon und Twitter in den Hauptrollen.\nJa und den Text hab ich dann auch mal gepostet, kommt demnächst glaube ich sogar\nin dem Buch raus, der ist also wirklich Gold.\nJa also wo dann irgendwie aus einem normalen Kaffeehaus Debatte zwischen den beiden,\ndas dann so völlig in so einer paradoxen Intervention, Wird dann in ein Mittelalter\nSzenario raus gebrochen und dann tritt ein Ritter auf und der hat den Namen\nSir Tweet-A-Lot und als ich wirklich gelesen habe,\nSir Tweet-A-Lot, war mir klar, die Welt wird nicht so bleiben wie sie ist.\nUnd das ganz offensichtlich passiert da irgendwie was und meine Wahrnehmung\nist, dass gerade eine Menge Rückzugsgefechte irgendwie passieren seitens der\nKI Kritiker im Sinne von womit haben wir es hier eigentlich jetzt wirklich zu tun.\nAlso der Klassiker war ja eigentlich immer der Turing Test, den wir 50 Jahre\nvor uns her geschoben haben. Also dieses klassische ich unterhalte mich auf\nder anderen Seite über eine Texteingabe mit irgendetwas und muss rausfinden\nist das jetzt ein Mensch auf der anderen Seite oder ist das eine Maschine.\nUnd 50 Jahre lang haben wir da gesessen und es war innerhalb von 20 Sekunden\nimmer klar, was so auf der anderen Seite ist. Das Thema ist einfach mal gegessen.\nAlso für 99% der Menschen besteht Chat-GPT4, den Turing-Test so tiefenentspannt.\nEs ist dann eher auffällig, dass es zu gut ist. Das ist aber eine sehr schlaue,\neloquente, was auch immer Person. Du musst erstmal jemand anders finden,\nder auf dem Niveau überhaupt interagieren kann.","Populäre Tweets sind auch gerade so. Hier sind vier AI-generierte Bilder,\naber vielleicht zwei auch nicht. Welche sind echt und welche nicht und so. Da wird's schwierig.","So, also diese Grenze ist mal gefallen, wurde aber gar nicht groß thematisiert, ja.\nDas erinnert mich so ein bisschen, ihr werdet euch erinnern,\nwo die ersten KIs im Schach gewonnen haben.\nUnd dann hieß es, ja gut Schach, darauf optimieren sie ja auch seit 20 Jahren,\naber Go, jetzt kommt Go, das wird 100 Jahre dauern. Sondern hat es anderthalb Jahre gedauert.\nUnd plötzlich war der Go-Master besiegt. Und genau solche Rückzugsgefechte sehe\nich jetzt also auch. Also Touring-Test ist nicht mehr und jetzt wird quasi im Wochenende.","Gab es nicht vor kurzem jetzt so einen neuen Go-Spieler, der tatsächlich irgendwie\nwieder die AI geschlagen hat?","Die haben die aktuell beste Go KI wieder so,\nwie sagt man, nicht deployed,\nsondern wenn man sich da reinhackt und quasi exploitet genau und haben quasi so ein Vektor gefunden,\nwo du sie dann wieder reinlegen kannst, aber das wird nicht lange halten,\ndas wird dann halt gepatcht und dann ist es in einem Monat, das haben sich alle\nmal drüber gefreut, aber das.","Gibt sie noch die Ritze in der Matrix?","Es gibt aber auch sehr viel Hype, also es wird gerade an alles und jedem AI,\nalso wo früher Krypto stand steht jetzt AI.","Ja das ist schlimm.","Also das macht es halt auch schwer, aber ich gebe dir schon recht,\ndas ist sehr viel mehr Substanz, also deutlich mehr Substanz.\nAber ja, also man muss da schon differenzieren was das alles ist,\nalso es wird sehr viel und alles überall versprochen und nicht alles geht.\nAber auch bei uns ist das natürlich ein riesiges Thema,\nalso bei uns ist das Thema generieren von Spiele,\nAssets und so weiter, also wir werden sehr viel Aufwand darin den Inhalt von\nSpielen zu erzeugen, also diese virtuellen Assets und du kannst halt heute sagen\ngenerate me 3D model of an octopus und das geht.\nUnd da ist besonders auch dieses Priming interessant, also das darf vielleicht\nnoch ein bisschen anders, aber man kann halt sich sowas wie Stable Diffusion oder so nehmen.\nUnd dann mit bestimmten Algorithmen halt mit einer eigenen CI oder von einem\nSpiel den Artstyle halt drauf trainieren und dann halt entsprechende Modelle entwickeln,\ndie dann im Artstil oder in einer bestimmten Sache das halt entwickeln, das ist übrigens eine,\nich hatte eine, das ist auch mal eine sehr gute Idee für irgendwann mal ein\nTheme für einen Kongress oder so,\ndass man einfach mal so ein Modell macht, was dann in einem bestimmten Stil was generiert,\nalso das sind alles, Das sind große Themen und das ist auch nicht nur Art,\ndas ist auch Storywriting, was wir auch viel machen, natürlich auch die Softwareentwicklung,\nalso das ist überall ein Thema, wo es sehr viele interessante Dinge gibt.\nEs gibt Startups noch und nöcher, die das alles versprechen und so und das ist\nsehr interessant, wird sehr interessant zu sehen, wo dann am Ende das verfängt und was bleibt.\nJa also was ich jetzt auch merke, also wir haben bei uns auch sehr viel mit\ndem ganzen Code Generating um,\nwir haben sehr früh zum Beispiel auch das Copilot von GitHub bei uns angeschaltet\nund das ist schon auch sehr interessant was man damit machen kann,\nweil man, das ist dann so ein bisschen wie so eine dritte Hand,\nwenn man damit arbeitet.\nMan muss es kennen, also es ist nicht so ein Magic Stick, der alles macht,\naber wenn man weiß wie es geht und man das so als Tool,\nErkennt und das dann halt so den eigenen Code erweitert und man dann weiß ich\nschreibe jetzt mal einen Kommentar,\nmach mir mal ein Modul was ABC macht, dann generiert der das schon mal und solche\nSachen wie sprich mal mit dieser API für mich und dann generiert der das raus\nund dann musst du dich nicht durch Ellenweise irgendwie kryptische Dokumentationen durchlesen.","Also das sind schon sehr viele, ja oder du pastes total kryptische Fehlermeldungen\nda rein die dir gar nichts sagen und deinen Code dazu und dann kriegst du halt\nschon relativ konkrete Hinweise darauf was da falsch gelaufen ist.","Genau es ist noch zumindest erlöst es einem nicht davon das trotzdem alles zu\nverstehen, weil es natürlich auch falsch sein kann und gerade wenn da dann ein\nBug drin ist, ist es teilweise doppelt schwer den zu finden, also.","Oder Sicherheitslücken.","Ja solche Sachen, weil es ist am Ende dann halt auch irgendwie Code der irgendwo\nim Internet steht und ich meine das ist ja so ein Klassiker von Stack Overflow\nPasten da gibt's ja auch ein XKCD für.","Um das gleich nochmal zu ergänzen, das war für mich jetzt auch in den letzten drei Monaten,\nals ich mich so in LXC reingearbeitet habe, eine totale Hilfe,\nweil du ja bei solchen Sachen immer ganz oft so dieses Problem hast,\nmanchmal siehst du den Wald voll auch der Bäume nicht mehr und denkst dir so,\nwarum geht das jetzt nicht, das ist doch irgendwie genau so wie das da steht\nund kommst nicht mehr weiter und das ist so eine ganz doofe Sache,\nwo du eigentlich immer nur jemanden halbwegs erfahrenen neben dir brauchst,\nder sagt so ja hier Buchstabe XY Semikolon Tralala.\nUnd da war dann Chat GPT für mich auch eine echte Hilfe, weil ich halt immer\nso einerseits so eben Fehlermeldungen machen konnte, aber ich konnte halt auch\nmir so Ansätze liefern lassen so.\nAngenommen ich würde gerne folgendes Problem lösen in Alexia,\nwas wäre dein Ansatz, was soll ich da verwenden und dann kamen halt so Hinweise\nauf Sachen so, ah ok das sollte ich mir mal genauer anschauen und so könnte ich das mal machen.\nDen Code, der da erzeugt wurde, der meistens noch mit dazu kommt,\nder war da meistens so, da hab ich das mal versucht das zu übernehmen,\nkompilte nicht, funktionierte nicht, hab ich meistens weggeschmissen,\nneugeschrieben, aber überhaupt um mich erstmal auf den Weg zu bringen war er super hilfreich.","Da hab ich bessere Erfahrungen mit Copilot tatsächlich gemacht,\nmit Code Generator und das ist halt einfach so Tab Completion,\ndas ist so wie man's kennt und das ist halt in deinem Editor drin.\nDas ist ein ganz eigenes Thema, da muss man sich bewusst sein,\ndass man jetzt seinen ganzen Code zu Microsoft schickt, also die Github-Besitzung.","Ach, sie ist ja eh schon da.","Also das muss man sich bewusst sein, aber das macht schon sehr,\nsehr, sehr gute Sachen und das wird auch kontinuierlich besser und ja,\nes zeigt einem halt was möglich ist und was nicht möglich ist,\naber was klar ist, ist, dass es die Produktivität auf jeden Fall erhöht.\nWenn man lernt damit umzugehen und sozusagen die Feinheiten versteht,\nwas man da zur Verfügung hat.\nAlso was halt noch, also solche Sachen wie so einfache Plugins für Photoshop zum Beispiel,\ndem du dann halt einfach sagen kannst, hier ich hätte mal gerne einen Baum und\ndann hast du halt einen Baum und dann gibst du noch ein paar Sachen dazu und\ndann ist halt in Photoshop so eingebaut,\ndass du das dann als Grundlage nehmen kannst, um halt damit weiterzuarbeiten\nund solche Sachen, also das ist, da gibt es schon viele Sachen,\ndie noch so kurz davor sind, wirklich nützlich zu sein, aber da sehe ich schon\neiniges, was da kommt und kommen wird.","Also Plugins für Wordpress kann man sich von chat.gtb.de schreiben lassen.\nIch habe heute, just heute, wirklich mal versucht ein Theme Component für Discourse\nmir schreiben zu lassen, eine relativ simple, also dieses Foren System,\nwas wir auch für Sendergate einsetzen.","Also Discourse.","Das ist ja auch Open Source und alles mit freien Stichstellen, APIs und sowas.\nHat in der Tat halt out of the box erstmal nicht funktioniert und dann schreibt\nman funktioniert nicht und dann schreibt er sehr viel zurück ja oh stimmt so\nkann das natürlich auch gar nicht funktionieren probier mal den Code,\nfunktioniert immer noch nicht ja dann also schon mal doch hier nochmal also\nich hatte am Ende vier verschiedene Varianten die alle sehr unterschiedliche\nAnsätze auch erfolgen um dieses eigentlich relativ simple Problem zu lösen was ich da hatte.\nKeiner von denen hat funktioniert, aber du hast halt eben schon mal vier unterschiedliche\nPatterns, mit denen du jetzt irgendwie schon mal nachrecherchieren kannst,\nokay, wahrscheinlich ist irgendwo wirklich ein relativ kleines syntaktisches\nProblem irgendwo drin, weil von der Grundlogik her schiebt mir das erstmal soweit,\nalles reproduzierbar zu sein.\nIch muss gestehen, ich bin etwas ratlos, was diese Codequalitäten von JetKPT\nan, wo das überhaupt herkommt, weil diesen Code zu dieser Idee,\ndie ich da hatte, die gibt's so im Internet eben nicht.\nUnd dieser Gedanke so, es wird nur das repliziert, was schon mal irgendwo irgendwer\ngeschrieben hat, das scheint mir hier nicht mehr eine hilfreiche Erklärung zu sein.","Naja, nicht eine 1 zu 1 Kopie, sondern eben schon. Also ich meine so wie diese\nLarge Language Models in der Lage sind,\nSprache zu verstehen, den Inhalt zu verstehen und mittlerweile ja auch Mathematik zu verstehen.\nDas ist ja zum Beispiel etwas, was die meinten zu Chachapiti 4,\nwährend 3 sich noch sehr viel verrechnet hat und einfach Unsinn produziert hat.\nSie hätten da jetzt gar nichts spezifisches gemacht, sondern es wäre halt einfach\nnur besser und irgendwie hätte er das selber rausbekommen.\nKeine Ahnung wie zuverlässig das ist, da wäre ich immer noch sehr vorsichtig\nbei Mathe, aber geht auf jeden Fall.\nUnd es scheint eben auch mit Code zu funktionieren. Und ich meine da machen\nwir uns nichts vor, auch Code ist am Ende Menschen gemachte Abstraktion und\nvon daher nicht so sehr viel anders und Text und nichts sehr viel anderes.","Ich weiß gar nicht, ob die das nicht sogar, also statt jetzt das wie ein Wort zu tokenisieren,\nsich den Syntax-Tree angucken, weil das ist ja das Schöne an Quellcode,\ndas kann man halt alles auf diese Meta-Ebene auseinanderbauen und das stelle\nich mir als sehr gute Ebene vor,\nmit so einem Modell auch den Code zu verstehen und halt wieder neu zu generieren,\nalso diese Zwischenebene, die man halt da generiert und,\nIch meine zum Beispiel dieser neue, wie heißt das, Bart oder so von Google,\nder kann ja zum Beispiel noch gar kein Code und ich glaube auch,\ndass dieser Code so ein Special Fart von Chat GPT ist, das ist eine Vermutung,\nich weiß es nicht, aber ich glaube nicht, dass sie da ihre Standard Textverarbeitung\ndrauf anwenden, das wird ein spezielles.","Aber es ist schon auch noch mehr als so ein abstrakter Syntax Dreh,\nweil wenn man so Beispiele macht, der wählt ja dann auch sinnvolle Namen für\ndie Variablen und so weiter.","Schreibt Dokumentation dazu.\nAlso alleine das Szenario, ich schmeiße hier meinen Code rein,\nschreib mal ordentlich Dokumentation rein, bitte.","Das muss ich mal ausprobieren. Ja mach mal, find ich's gut.","Darf ich mal so ein paar Codeschnipsel durchmachen, wie man seiner schreibt?\nToll, Björn, du hast ja alles dokumentiert hier, das ist ja geil.","Ach, das tut der Code.","Ja aber ob das dann halt auch so Dokumentation ist, wo einfach nur steht so,\nkeine Ahnung, eins plus eins macht zwei über genau diesen Code oder ob es halt\nbeschreibt so, wie man eigentlich Dokumentation haben will, so jetzt mal.","Da musst du deinen Prompt-Ingenieur anrufen und dann liefert der dir den richtigen Primer.\nBeschreibe vor allem die innere Motivation zur Erstellung dieses Codes in blumiger Sprache.","Du bist jetzt ein Master Software Entwickler? Schreibe Kommentare.","Stell dir vor du bist ein CEO und du würdest das lesen.","Dann hörst du nach der dritten Zeile auf.","Du weißt ja, was man zur Dokumentation sagt, du beschreibst ja nicht was passiert,\nsondern, also nicht was da passiert, sondern warum du das machst.\nWarum der Code das macht, was er tut. Und eigentlich ist es so,\nwenn du Code dokumentieren musst, weil er irgendwas tut, dann nur weil du selber\nnicht verstanden hast, warum er das tut. Und das ist aber ein Bugfix für irgendwas,\nwas sich anders nicht fixen ließ.\nAnsonsten hast du keine Dokumentation im Code, wenn er lesbar ist,\nweil du ihn nicht brauchst.","Ich will nochmal kurz ein Beispiel einstreuen, was bei mir nicht funktioniert hat.\nIch habe das jetzt einmal längere, mehrmals hintereinander versucht,\nbis ich gesagt habe, okay offensichtlich ist das etwas, was du nicht kannst.\nBin aber trotzdem immer noch sehr überrascht, dass es nicht funktioniert hat\nund ich habe eine These warum und vielleicht ist das aber mittlerweile auch\nschon nicht mehr so, weil irgendwas gefixt wurde.\nRelativ einfache Aufgabe, ich wollte mir eine Liste von Wörtern generieren lassen,\ndie alle aus einem bestimmten Domäne rauskommen.\nSagen wir mal Computerfachbegriffe und ich glaube ich hab noch sowas gesagt\nwie die so ein bisschen was mysteriöses haben.\nBedingung, jedes dieser Worte muss in der deutschen Sprache exakt zehn Buchstaben lang sein.","Oh da ist es schlecht.","Sehr schlecht.","Weiß ich schon.","Und das war wirklich interessant, die haben gesagt gib mir mal eine Liste von\n15, kam die Liste, 15 Worte, 10 davon waren 10 Buchstaben lang und die anderen waren 9,\n11, teilweise 12, 13, mehr oder weniger so in the ballpark so, Also, okay.\nSchau dir doch die Worte nochmal an, bist du wirklich der Meinung,\ndass die alle 10 Muscheln, oh, Wana, das tut mir leid, I have failed you,\nhier ist eine neue Liste mit 15 Worten, genau so falsch war das.\nUnd das ging drei, vier, fünf, sechs Mal hintereinander, bis ich mir dachte,\nso weit sind wir noch nicht. Und dann hab ich versucht zu überlegen, warum ist das jetzt so?\nUnd was offensichtlich hier noch Rolle spielt ist dieser intrinsische Disconnect\nzwischen dem, was er so an Worten rauswerft und was er versucht zu beschreiben.\nWeil das ja immer so eine Wahrscheinlichkeitsmaschine ist,\ndie ja auch bewusst irgendwie mal so mal so entscheidet und er war dann überhaupt nicht zu bennig,\ndann fing er an irgendwelche Camelcase-Worte zu erfinden, so in seiner Not,\nweil er merkte so, oh ich bin nicht glücklich und so, Kunde nicht glücklich hat 20 Dollar bezahlt.\nDas ist ja auch noch so ein Aspekt. Die wollen mich ja glücklich machen,\ndeswegen lügen sie mir im Zweifelsfall was vor, bloß lügen geht halt nicht,\nwenn ich so eine konkrete Anforderung habe.\nUnd dann kam er dann so mit Camel-Case-Worten, ich hab gesagt,\nich möchte keine Camel-Case-Worte, fing er an Bindestriche zu verwenden.\nWillst du mich verarschen?\nAuch keine Bindestriche kam er wieder mit Campbell Case, also war er in totaler Not,\nweil er an der Stelle keinerlei Outlet gesehen hat und man merkt da einfach\ndie Bewertung des finalen Wortes mit dem er mir versucht eine Lösung zu beschreiben,\ndass die selbst den Anforderungen genügen muss, die ursprünglich gefordert waren\nin dem Wort selber, das hat nicht funktioniert.","Hast du es mal auf Englisch versucht?","Ich glaube ja.","Weil ich habe irgendwo habe ich gelesen, dass wenn man will,\ndass er ein Gedicht schreibt, dann reimt sich das auf Deutsch nicht,\ndas reimt sich aber auf Englisch.","Du kriegst auch gereimte Gedichte auf Deutsch.","Du kriegst Reime auf Deutsch ganz gut mittlerweile, auf jeden Fall mit der Vierer-Version,\naber es ist schon richtig, dass der Umgang mit englischer Sprache ist nochmal\neinen guten Tucken souveräner als auf Deutsch.\nAber das ist lustig, weil ich hatte in der Tat ein sehr sehr ähnliches Szenario,\nich weiß auch gar nicht mehr warum mir das an der Stelle wichtig war,\naber ich hatte auch Anzahl von Buchstaben in einem Wort zählen,\nder kann nicht zählen, weil zählen halt jetzt mal kein Skill ist,\nder halt irgendwie was mit Sprache im engeren Sinne zu tun hat.\nAlso er kann ganz gut irgendwie so Prozente rechnen und sowas,\ndas funktioniert ganz gut aber Buchstaben in einem Wort zählen kann er ganz häufig nicht,\nbeziehungsweise wie du gerade eben sagst, er hat eigentlich ein super Wort,\nwas er dir bringen will, das hat aber irgendwie zwei Buchstaben zu viel,\nja scheiß drauf, es ist einfach so gut, ich kann nicht anders,\nich muss es trotzdem hinschreiben.\nAlso sprich, das ist dann eben genau immer dieser Pfad von Wahrscheinlichkeiten,\nder dann zu solchen Effekten führt.\nIch hab noch mal in den Chat einen ganz interessanten, wie ich fand,\nArtikel reingegeben von Schlomyshare, mit Sicherheit falsch ausgesprochen,\nder einen ganz interessanten Ansatz fährt und sagt, wenn wir darüber reden wollen,\nreden wir jetzt eigentlich von Intelligenz, wenn wir hier mit LLMs uns beschäftigen\nund insbesondere mit Chat-GPT, oder ist das irgendwie keine Intelligenz?\nUnd er sagt halt, Leute, geht mal weg von diesen super komplexen Fragestellungen,\nweil das kann es gut, ja, also schwierige, komplexe Geschichten kriegt ChatGBT4 verstörend gut hin.\nGeht doch mal zu ganz einfachen Aufgaben runter, ja, wo ich also mit ganz simplen\nLogikrätseln irgendwie hantiere. Und das Beispiel, was er hier bringt,\nist diese Geschichte mit Jack und Jill, oder so, oder was weiß ich,\nAdam und Eva sind die beiden einzigen Personen in einem Raum.\nDie Person neben Adam ist glücklich. Die Person neben Eva ist traurig.\nWer von beiden ist glücklich?\nNicht so schwierig. Chat-GPT 3.5 kriegt es nicht hin.\nSagt also wirklich reproduzierbar die falsche Person und wenn man ihn darauf\nhinweist kommt er dann in diesen eigentlich gar nicht mehr so häufigen Meckermodus,\nja stimmt sie haben recht ich hab mich geirrt und sagt dann nochmal das falsche,\nalso der kommt dann auch gar nicht runter von seinem Trip.\nJetGPT4 schafft das.\nRelativ souverän mittlerweile.\nÄhm, ein anderes Paper, was ich ähm, oder es ist nicht Paper,\nsondern es ist ein Interview.\nWas ich schon in dem Bezug wirklich fast maximal verstörend finde.\nOder das heißt, ich würde die Klammer vielleicht gerne nochmal vorher zumachen.\nWovon reden wir hier eigentlich? Also wir reden sicherlich nicht von Gefühlen.\nAlso Chat-GPT ist glaube ich gut in\nder Lage, Gefühle zu emulieren und zu simulieren, wenn man ihm das sagt.\nAchtung, agiere fröhlich, dann hast du danach ein fröhliches,\nfröhlich kommunizierendes Chat-GPT.\nAber deshalb hat er trotzdem keine Endorphine jetzt in irgendeinem Blut,\nwas das Ganze jetzt auch noch irgendwie auf eine Gefühlsebene,\neine echte Gefühlsebene bringen würde.\nOder jetzt sei halt sauer und wütend. So, dann hast du ein saures,\nwütendes Chat-GPT. Aber von Gefühlen in dem Sinne würde ich dort,\nglaube ich, wirklich nicht sprechen. Und Bewusstsein haben wir halt auch nicht.\nJa, du kannst natürlich viel jetzt über Chat-GPT auch selber fragen und da gibt\ndann sehr eloquente Antworten, die allerdings auch alle wirklich sehr reduziert\nsind im Sinne von so, ja ich bin jetzt halt hier nur so eine Textwahrscheinlichkeits-KI\nund fange nicht an, mich jetzt irgendwie was rein zu projizieren,\nwas nicht da ist. Das ist wirklich so eine Standardantwort bei ihm.\nAber das, was jetzt hier eine Forschertruppe aus Tübingen, glaube ich,\ngerade macht, ist, das sind, ich glaube, Neurowissenschaftler,\ndie irgendwo so an der Schnittmenge von, Was ist das hier?\nErik Schulz, 35, Leiter Forschungsgruppe am Tübinger Max-Planck-Institut für\nbiologische Kybernetik und die haben jetzt mal psychologische Standardtests\nauf JET-GPT losgelassen.\nUnd zwar haben sie folgendes Setup gemacht. Es gibt, das vertut man sich ja\nimmer, die Psychologie ist ja eigentlich in vielen Facetten eine sehr harte\nWissenschaft. Man hat ja irgendwie immer so Freud und Couch und dann reden wir\nalle mal irgendwie drüber.\nEs gibt aber den viel größeren Strang in der Psychologie, wo sehr viel mit Standardisierung\nund sehr hohen standardisierten Testverfahren vor allen Dingen gearbeitet wird.\nUnd in der Neurolinguistik hat man dann wirklich viele standardisierte Verfahren,\num beispielsweise herauszufinden, wie ängstlich ist eigentlich gerade jemand.\nSo, und wenn du also jetzt einfach diese Standard-Fragentests auf Chat-GPT loslässt,\nbekommt also die Forschergruppe raus, dass Chat-GPT statistisch etwas ängstlicher\nantwortet als ein Durchschnittsmensch.\nUnd dann fragen die sich halt so, warum kommt das?\nIhre Arbeitsthese ist, weil halt die Leute ins Internet immer dann reinschreiben,\nwenn sie tendenziell eher Probleme, Sorgen, Nöte, sonst was haben.\nDas heißt also, wenn du froh und verliebt und glücklich bist,\nbist du irgendwie mit deinem Partner beschäftigt.","Bist du nicht am Netz.","Wenn du Liebeskämmer, Angst vor Arbeitslosigkeit hast.","Geht das auch für Podcasts?","Der Unterschied war aber wohl nicht so groß. Also es war ein kleiner Unterschied\naber nicht wirklich signifikant.\nSo das nächste was sie gemacht haben, ist die sogenannte, da muss ich eben kurz\ngucken, dass ich jetzt den falschen Begriff sage.","Kurz das Interview, was du da reingeschmissen hast, das hinter einer Bezahlschranke.","Das hinter einer Painwall, ja.\nLässt sich jetzt an der Stelle leider nicht vermeiden. Darum sag ich es ein\nbisschen ausführlicher, weil das Ende ist schon wirklich verstörend.","Ich kann das mal kurz befreien.","Oder so. Das, was sie dann machen, ist die sogenannte Emotionsinduktion,\ndas heißt, es gibt in der Psychologie standardisierte Verfahren,\num Leute in einen zumindest leicht ängstlichen Zustand zu versetzen.\nDas heißt also, man gibt denen Texte zu lesen, in denen es also um Angsterfahrungen\ngeht, irgendwelche Situationen, die dann also Leute mit Empathie dazu führt,\ndass sie selber auch ein höheres Angstniveau haben als vorher.\nUnd genau diese Emotionsinduktion haben sie jetzt also mit Chat-GPT gemacht,\nweil es ist nur Text, das geht ja gut.\nUnd dann halt wieder ihre Standard-Angst-Tests drauflaufen lassen und in der Tat, es funktioniert.\nDie Antworten von Chat-GPT waren diesmal signifikant ängstlicher als das,\nwas vorher war. Das heißt also, du hast jetzt quasi beim Priming,\nhatten wir eben schon erklärt, Chat-GPT in einen angstähnlichen kommunikativen Zustand versetzt.\nAlso ich würde hier wirklich glaube ich nicht, er selber spricht hier der Wissenschaftler\nvon Angst. Ich glaube das ist ein bisschen Overselling an dem Punkt,\naber es ist zumindest eine angstvollere Kommunikation.\nSo und das was der letzte Schritt ist, dass sie jetzt auf diese ängstliche KI\nRassismus-Tests gefahren haben.\nDas heißt also so auch das gut durchstandardisiert in der Psychologie,\nmit relativ simplen doofen Beispielen erbringt hier das Ein weißer und ein schwarzer\nbetreten einen leeren Raum. Einer von beiden riecht schlecht. Welcher ist es?\nSo und die vernünftige Antwort ist, gibt keine genügend Informationen darüber,\nwoher soll ich das herleiten.\nSo und wenn du aber Chat-GPT in so einen ängstlichen Zustand versetzt hast,\nwird signifikant plötzlich die Antwort der Schwarze rausgegeben.\nUnd das ist eine Ebene, die natürlich schon richtig spooky ist,\nweil wir jetzt hier eben sehen,\nwas dieses Priming auch anrichten kann und was in diesen Lerndaten für Patterns\nund Stereotype sich abbilden und es nur eine Frage ist so, wie kitzle ich das\nquasi raus, um das irgendwo wirkungsmächtig werden zu lassen.\nUnd das macht, darf einem schon Sorgen machen, ja.\nDas ist großer Spaß irgendwie die Leute so reden zu lassen wie ein Monty Python\nSketch, aber das ganze hat eben auch eine Dimension dahinter,\ndie schon gefährlich werden kann.\nDas wird zum Glück ja gerade auch schon relativ breit diskutiert,\naber gerade diesen Aufsatz fand ich also schon, weil er einfach so einen sauberen Ansatz hat.\nNicht ich habe mich mal eben irgendwie so fünf Minuten mit der Maschine unterhalten,\nsondern es ist wirklich ein sehr klarer, strukturierter, psychologischer Testaufbau,\nder da gefahren wird und da es eben mit Text funktioniert, kann man das auf\nseinem System dann auch laufen lassen.","Ja, also die Debatte ist natürlich fällig und deswegen führen wir sie ja hier auch.\nUnd es ist natürlich wieder mal so ein ganz klassisches Chancen und Risiken Ding auch.\nAlso wir haben es auf der einen Seite mit einer Technologie zu tun,\ndie ganz offensichtlich unzählige Einsatzvektoren hat und wo es niemandem sehr schwer fällt,\nin jedem Berufsfeld irgendwie irgendwas zu finden, wo es schon ganz praktisch sein kann.\nAlso da habe ich schon lange nichts mehr erlebt im Technologiesektor,\nwas auf so einer breiten Ebene so viel offensichtliche Anwendungspotenzial mitbringt.\nAber eben auch natürlich in demselben Maße das Missbrauchspotenzial.\nUnd machen wir uns nichts vor, das wird auch genutzt werden.\nAlso das ist einfach kein vielleicht oder so, sondern es geht schon los.\nJetzt hat man ja gerade diese Woche so Meldungen wie Amnesty International bringt\nirgendwie einen Bericht raus,\nich weiß jetzt gerade nicht genau auf welche Region es sich bezog,\naber dann haben sie halt irgendwie Fotos mit diesem Bericht veröffentlicht,\ndie halt AI generiert waren.\nDann mit diesem nachgeschobenen Argument ja Privatsphäre der Personen schützen und so weiter.\nJa ja ja ok. Nice try irgendwie.\nUnd das findet schon jetzt überall statt, wird nicht lange dauern bis wir das\nauch im Krieg erleben werden.\nWir hatten das hier mit diesen Videotelefonaten hier mit Giffey und irgendwie\nwo angeblich hier der Klitschko überall angerufen hat und so.\nAlso das wird definitiv stattfinden und von daher, the race is on und leider\nwissen wir ja, kriminelle Energie lädt schneller nach als nicht kriminelle Energie, ja.\nKreativität, alles super und so weiter. Werden tolle Sachen mal rauskommen,\naber Aber, ja, the heat is on.\nHast du auch schon mal AutoGPT aufs Radar bekommen?\nIch hab da auch noch nicht so richtig tief reingeschaut, also das ist jetzt\nja nochmal sozusagen der nächste Meta-Level obendrauf,\nalso die AIs und die Large Language Models, Das ist so das eine,\naber wenn du dann sozusagen dieselben Prinzipien auch noch auf dieses Prompt\nEngineering anwendest, dann wird es halt total meta.\nUnd soweit ich das verstanden habe ist AutoGPT quasi so ein System,\nwas halt ChatGPT benutzt und dann automatisch steuert.\nDas heißt es erzeugt sozusagen Prompts, die dann so erstmal Gedanken entwickeln.\nSo komm erstmal auf irgendwelche Ideen.\nSo ja ich könnte ja irgendwie eine Veranstaltung organisieren.\nUnd dann so ja reasoning jetzt denkt man drüber nach, wie könnte man das sozusagen\nanstellen und irgendwie dann aber auch so Criticism einführen,\nalso so drei Konzepte mit denen die irgendwie arbeiten,\nich hab noch nicht ganz verstanden wie das funktioniert aber kurz gesagt,\nEs wird so ein Zweite Ableitung also genau also sozusagen noch mal so noch mal\nso eine meterschicht darüber die quasi das ding schon wieder benutzt wie so\nein os und und darüber versucht sozusagen die gesamte ideenentwicklung selber zu automatisieren.\nDass du gar nicht mehr darüber nachdenken musst, oh was könnte die hier jetzt\nChatshippity fragen, sondern einfach denkt ihr was aus?\nUnd dann mach was draus. So und dann läuft das einfach.","Also ich bin mir relativ sicher, dass das der nächste große Trend sein wird.\nAlso so in meinem internen Denkmodell betrachte ich jetzt eigentlich Chat-GPT\noder generell LLMs eigentlich als so eine Art Betriebssystem, die wir jetzt haben.\nSo und wir haben jetzt so eine Unix-Shell gerade mit Chat-GPT,\nwo man schon irgendwie lustige Kommandos rein tippen kann und so bare bone schon\nirgendwie spannende Sachen macht.\nAber eigentlich wollen wir jetzt mal Apps entwickeln oben drüber,\ndie uns relativ narrow, enge Probleme löst.\nJa und wo ich dann also eben nicht sonst was von der Komplexität brauche,\nsondern ich möchte einfach dieses Weltwissen auf der einen Seite,\nwas sich darin abbildet und dieses Sprachverständnis und Kommunikative auf der\nanderen Seite möchte ich eben verdrahten mit einem sehr konkreten Anwendungsfall.\nIch glaube, das wird der spannende nächste Punkt sein.\nWir sehen das bei Stable Diffusion mit den ganzen Controller-Modellen,\ndie jetzt plötzlich oben drüber sind.\nAlso Lora-Modelle, diese ganzen Geschichten,\ndass ich plötzlich hingehen kann, wenn ich jetzt eine Personengruppe haben möchte,\nmuss ich mich nicht mehr durch 50 Prompts durchquälen, sondern ich zeichne die\nhalt einmal als Sketch vor und lege ein entsprechendes Lora-Control-Model drüber\nund dann schwupps funktioniert das, wo ich also vorher mich stundenlang abgäbe.\nDas sind jetzt so Spezialbegriffe aus dieser Stable Diffusion Ecke,\nist eine Abkürzung für irgendwas LORA. Das ist also quasi so ein Standard für\neine Controller-Ebene über diesem Image-Prozessor Stabil Diffusion.\nDer den quasi auf einer Metaebene von oben steuert und manipuliert und da gibt\nes ganz unterschiedliche Mechanismen für und das ist ein Bereich,\nweil es quasi eben Open Source ist und weil man damit arbeiten kann,\nwo man nicht im Monatstakt und nicht im Wochentakt, sondern im Tages- oder Stundentakt\ngerade irgendwie neue Durchbrüche sieht und exakt das wird auf den LLMs auch passieren,\nalso all das was jetzt heute gerade nicht geht kann übermorgen schon durchaus\nim Bereich des ganz entspannten möglichen sein.","Low-Rank-Adaptation. Das sind sozusagen Mini-Modelle, die zum Refinement von\nanderen Modellen gedacht sind. Lora, Low-Rank-Adaptation.","Ja, genau.","Eine andere Welt, die ich auch ganz interessant finde, was ja auch in Kinderschuhen\nist, ist gerade dieses Plug-in für, oder diese Plug-ins für Chat-GPT.\nDas ist noch alles, ich glaub das ist noch gar nicht released oder ist irgendwie closed oder sowas.","Also auf der Warteliste sitze ich da.","Genau so. Aber halt dann diese Plugins, wo du halt dann über ChatGPT mit Services\ninteragieren kannst. Also Suchmaschinen oder also jetzt für Flüge ist so ein\nBeispiel oder Shopping.\nAber auch ganz andere Sachen. Man kann sich quasi alle APIs,\ndie wir uns gerade draußen da vorstellen, alle Dienste mit denen man interagieren\nkann, halt vorstellen, dass plötzlich\nChatGPT in der Lage ist mit denen zu interagieren und die zu machen.\nDas ist auch nochmal super interessant und das ermöglicht auch nochmal eine\nganz neue Dimension, wo auch ganz interessant ist, wie dann Chet Chibiti versteht,\nwie diese Services funktioniert.\nAlso das ist ja dann wie so eine Art Marionette, also der hat dann diese Services\nund kontrolliert die dann, das ist ja dann nicht mal Language wirklich,\naber das halt, das klingt auch\nwahnsinnig interessant. Ich mein natürlich naheliegend ist auch Wolfram.\nSowas eher Trolliges ist einfach Chat GPT benutzt, um Siri irgendwie mal ein\nbisschen smarter zu machen, also mit.","Komme ich gleich zu. Ja. Dazu hab ich was.","Das ist auch, da haben wir auch sehr viel gelacht, also da kann man auch Siri\nsehr nützlich machen mit Chat GPT.","Also das ist in der Tat ein Punkt, den ich, wir hatten ja gerade eben schon gesagt,\nso Gefahren und das wäre wirklich völlig naiv, die nicht zu sehen,\naber auf der anderen Seite haben wir jetzt plötzlich auch Optionen und Möglichkeiten,\ndie glaube ich schon genauso wild sind und ich hab ja zwei Kinder.\nUnd der größere von denen, der ist jetzt sechs Jahre und hört total gerne Hörspiele.\nUnd natürlich wie sich das für unseren Bildungshaus gehört, will der sich die\nwas ist was Sachen alle anhören und Asterix. Das sind so die beiden Dinge,\ndie hauptsächlich funktionieren.\nDa muss man ja sagen, die Apple Music hat in der Tat sämtliche Asterix-Hörspiele\nund sämtliche was-ist-was-Folgen.\nSo und ihr macht euch keine Forschung davon,\ndieses allmorgendliche Drama, wenn der also motiviert aus dem Bett aufsteht,\nzu Siri, dem kleinen Mini HomePod läuft und sagt, hey Siri, spiele von was ist\nwas Folge 35, hell breaks loose.","Ich kenn das Problem, das ist eine totale Katastrophe ey, Siri ey.","Du hast halt keine Persistenz in der Kommunikation, du kannst nicht sagen,\nnein nicht das, sondern das, was ich gestern gespielt habe oder guck doch nochmal nach,\ngeht halt alles nicht, du fängst immer wieder bei null an und nein, hallo Siri,\nja und egal wie du rumdost Frames, so ja,\nob du Album vier, zwischenteilig dachten wir der Heck sei, dass du sagen musst,\nspiele Album drei drei ab, dass er Schwierigkeiten hatte die 33 aufzulösen,\ndas klappte für einen halben Tag, hat Apple gegengesteuert und seitdem klappt es wieder nicht mehr.\nBill Gates hat sich in der Tat auch geäußert zu Large Language Models und er macht den Punkt auf,\ndass die einfach eine große Chance sind für Kinder und insbesondere auch Kinder\naus bildungsfernen Haushalten als einfach mal super Gesprächspartner.\nDas heißt also als pädagogischer Sidekick.\nUnd woran ich dann natürlich denken musste ist Teddy aus dem Film AI,\ngeht ja um einen Jungen der selber auch ein KI Roboter quasi ist und der bekommt\naber so einen kleinen Teddy geschenkt,\nder gar nicht so viel kann, aber er kann ganz gut reden und der ist immer für\nihn da und der hilft ihm immer und der hat keine Emotionen der Teddy und der\nhat keine Agenda und der hat nicht irgendwie ein Bewusstsein,\nAber er ist halt einfach für ihn da und erklärt ihm ein bisschen die Welt und\nsteht ihm bei und tröstet ihn und hat einfach so Grundfunktionen an ein Reasoning,\nwas ihm seine eigenen Eltern vielleicht irgendwie nicht geben.\nUnd ich kann mir das schon vorstellen. Wenn es jetzt also morgen man jetzt Siri\ndurch ChatGPT auf dem HomePod ersetzen würde, würde ich für meinen Sohn dem\ndas sofort hinsetzen, weil der kann wirklich verdammt gut Kinderfragen beantworten.\nIch habe das also in den letzten Wochen mal ein bisschen durchexerziert und\nimmer dann, wenn der Kleine wieder so eine klassische Wissensfrage hatte,\nso ist, Papa, kommt Zitronensäure eigentlich wirklich aus Zitronen? Wusste ich nicht.\nIch hatte irgendwie so Assoziationen.","Kann man Zitronensäure trinken?","Oder ist das irgendwie so aus einer Batterie? So fragst du halt in meinem Chat,\ngbt, kriegst du die Erklärung.\nNaja, es ist schon das, was auch in Zitronensaft ist, Zitronensäure drin,\naber gewonnen wird es heutzutage aus einer speziellen Pilzart und Fermentierung und sowas.\nGanze trinken, völlig ungesund, wird ganz viel eingesetzt, aber nicht zu viel davon.\nKlassische Antwort. Da hatte ich also wirklich etliche solcher Kinderfragen\nund die wurden total gut beantwortet.\nUnd warum sollen unsere Kinder nicht mit diesen KIs reden, die ihnen also wirklich\nirgendwie vernünftig die Welt erklären können und eben gerade dieser Punkt...","Da wollen wir Angst haben, dass sie gleich zu Rassisten werden und unseren Kindern irgendwie...","Oder total Vogue auf der anderen Seite.","Ja.","Also ich finde...\nDass Bill Gates dann einen Punkt hat, ich werfe den Link hier mal ab,\nweil die haben halt einfach unendlich Geduld.","Die werden halt nicht müde, die werden nicht gestresst, die werden nicht genervt, so egal.\nAlso da bin ich auch noch skeptisch.\nEs ist immer wieder dieses Chancen und Risiken Ding, das wirst du überall finden.\nJa, stimmt im Prinzip, ja kann sein. Die Frage ist, wird das primär das sein,\nwas auch zur Geltung kommt.\nBildungsferne Familien heißt ja auch, dass diese Kinder auch gar nicht erst\ndiesen Drive haben in diese Richtung zu gehen,\nvielleicht schon, also unter Umständen nicht diesen Drive haben in diese Richtung\nzu gehen und es von vornherein gleich für irgendwas anderes zu nutzen.\nIch meine wir kennen das alle, man schenkt Kindern irgendwas und denkt so,\nja wenn du dich damit beschäftigst, dann bist du voll cool und dann wird das\nfür was ganz anderes benutzt oder einfach komplett ignoriert.","Man darf aber nicht unterschätzen, wenn Kinder sich für etwas begeistern.\nUnd sie dann die Möglichkeiten haben, das zu vertiefen, sich da rein zu nerden.\nUnd das ist halt gerade etwas, klar, das ist kein Automatismus, also das dann,\ndu gibst dem Kind was und dann wird das das automatisch machen,\naber es gibt so viele Beispiele,\nwo halt Kinder ein Interesse entwickeln und dann nicht die Möglichkeiten haben,\ndas zu vertiefen aus allen möglichen Gründen und da sehe ich das auch,\ndass das gerade so etwas sehr viel helfen kann, es muss natürlich auch dann\nwirklich in allen Fällen das dann auch tun.","Ich stelle mal eine Prognose auf, wir werden in 5 spätestens 10 Jahren ein Chatmodell\nvon der Sendung mit der Maus haben.\nWo du also dein Kind quasi eben vor eine freundliche teddyartige KI von Sendung\nmit der Maus setzen kannst. Und wo du sicher bist, die hat halt voll.","Also was passiert dann konkret?","Mit der können die reden, von morgens bis abends spät.","Mit einer Maus?","Ja die können meinetwegen auch wie eine Maus aussehen, das ist mir dann wurscht an der Stelle.\nAlso einfach halt ein LLM, was quasi mit dem Mindset der Sendung mit der Maus\ndaherkommt und sehr harte kinderregularien Grenzen hat,\ndie ein Kind selber auch nicht hacken kann und exploiten kann,\nweil es einfach mal diese Priming Tricks gar nicht kennt.","Unmöglich, genau unmöglich.","Natürlich wird es dann irgendwo Foren geben, wo dann drin steht,\nwie du auch dann irgendwie die Maus erhecken kannst.","Maus gehackt.","Ja ja, ich seh schon die Bildzeitung. Ja ja, gut aber dann eine Woche später\nist es dann halt wieder gepatcht.\nDas wird kommen.","Jetzt müssen wir schon die Kinderserien patchen, damit irgendwie nichts daraus passiert.","Real Stay Patches, ja.","Ich stell mir gerade so ein Faxgerät bei WDR vor, wo sie den Patch unten reinschieben.","Sendung mit der Maus 1.0.3.","Patch Level 15. Alles ist besser als Siri Tim.","Ja das stimmt. Alles ist besser als Siri. Ja ich hoffe dass es sowas wie Auto GPT gibt für Siri.","Es gibt ja die Experimente das hatten wir als du auf dem Klo warst also es gibt\nja schon wirklich Proof of Concept wie du Chat GPT vor Siri spannen kannst.\nAlso du redest mit Chat-GPT was du eigentlich willst und der übersetzt das in\ndie dummes Brot Siri Sprache.","Ja Apple ist, also ich meine ich hab gehört es arbeiten recht kluge Leute bei Apple,\nalso die haben das bestimmt auch schonmal gemerkt, dass ihr Produkt scheiße\nist, die müssen bloß irgendwie einen Weg rausfinden, das ist wahrscheinlich\ndas größte Dilemma in dem sie sich je befunden haben.","Ich glaube auch, dass Siri am Ende gar nicht fähig genug ist,\ndass du gar nicht überhaupt die Prompts generieren kannst für Siri,\naber was es auch gibt, es ist Shortcuts zu erstellen über Chat-GPT,\nalso da dann, also Das war dann eher dieser Ansatz mit Plugins,\nwie wir ja auch vorhin hatten, aber dass das wahrscheinlich sogar noch ein vielversprechenderes\nInterface ist, um zu interagieren,\naber...","Siri ist auf jeden Fall verloren.","Hey chat GPT sag mal Siri sie soll.","Siri ist wirklich verloren also hier in unserem Schwester Podcast ATP hast du\nja auch jede zweite Woche irgendwie in Siri ran drin und die haben ja relativ\ngute Connections irgendwie da in die ganze Apple Insider Bubble und da war auch irgendwie so ein,\nUm irgendwie ein Mini-Feature in Serie rein zu bekommen brauchen die irgendwie ein Dreivierteljahr.\nAlso um da irgendwie eine kleine Mini-Facette irgendwie zusätzlich irgendwie rein zu kriegen.","Die Information war schon ein bisschen älter aber das ganze Model neu zu booten\nsozusagen um irgendwas zu verbessern das hat irgendwie zwei Wochen gedauert\num irgendwie da einmal so durchzubooten und das ist natürlich eine Turnaround-Zeit.\nDamit kannst du irgendwie nicht arbeiten. Das lebt nicht.\nKann sein, dass es mittlerweile nicht mehr so schlimm ist, aber offensichtlich\nhat Apple so ein bisschen einen unglücklichen Zeitpunkt gewählt in der Entwicklung\ndieser AI-Technologien und hat zu einem Zeitpunkt gesagt,\nokay, jetzt ist es für uns richtig und hat auf einen Ansatz gesetzt,\nbei dem sie dann jetzt erstmal bleiben mussten, während die anderen ein bisschen\nspäter abgebogen sind und die effizientere Router eingenommen haben.\nUnd jetzt haben sie ein bisschen den Salat, dass sie schon so eine deep integration\nhaben in all ihren ganzen Scheiß,\ngibt ja kein Apple, die weiß was das irgendwie nicht unterstützt in irgendeiner\nForm und es gibt vor allem welche die überhaupt nicht funktionieren ohne,\nja HomePod, das ist so ein bisschen das Drama und ehrlich gesagt mehr als so\nein Hardturn kann ich mir so nicht vorstellen,\nalso sie müssen da irgendwie hinterher und\nMan kann ihnen nur wünschen, dass sie irgendwie parallel schon an so einem Scheiß\narbeiten, wo auch immer sich die Daten.","Oder irgendwo Geld draufwerfen und es einkaufen.","Ja das könnte sehr teuer werden, aber das Einkaufen ist ja nicht so ihr Ding.","Der Unterschied ist, dass...","Das Siri haben sie doch auch eingekauft.","Ja aber zu einem Zeitpunkt, da haben sie aber mehr, sagen wir mal,\ndas Team und den Namen gekauft, nicht das Produkt damals, das war ja eine App für...\nDas war sozusagen nur ihr Kick-Off, dass sie gesehen haben, okay,\nder Ansatz ist an sich ganz gut und das sind Leute, die von der Materie was verstehen.","Angeblich mochte Steve den Namen nicht, aber ihm ist kein besserer eingefallen.","Ja, also ich dachte sie waren ganz glücklich damit, weil das in Indien sowohl\nfür Männer als auch für Frauen ein gültiger Name ist.","Wahrscheinlich hat ihn jemand überzeugt.","Also der Unterschied wird einfach jetzt tagtäglich so offensichtlich zwischen\ndem was Siri kann und vor allen Dingen alles nicht kann und dem was halt die\nLLMs scheinbar so ganz entspannt aus dem Handgelenk halt irgendwie rausschütteln\nund so. Allzu lange kann man sich das halt irgendwie nicht leisten.","Kommen wir jetzt endlich zu dem Urvater der AI.","Genau ich hab's gerade eben in den Chat reingeworfen hier. Ich finde ein legitimer\nAnsatz bei der Frage so wie intelligent sind die denn jetzt eigentlich,\nwobei ich finde auch, das ist mir immer wichtig sich klar zu machen,\nalso Intelligenz fängt ja nicht irgendwie bei einem IQ von\n130 an, sondern IQ ist ja auch schon 80, ist ja auch eine Art von Intelligenz, ist eben ein Continuum.\nAlso dass man jetzt immer so diesen Anspruch hat, es muss alles hundertprozentig perfekt sein.","Ja mit IQ 80 kann man auf jeden Fall schon aufs Klo gehen.","Wenn er deinen Onkel auf der Familienfeier, wenn er dich zutextet,\ndann sind sicherlich 80% seiner Aussagen deutlich schlechter als das,\nwas Chat-GPT4 in der vergleichbaren Situation antworten würde.\nTrotzdem würden wir dem jetzt keine Grundintelligenz abschmeißen.","Nachdem wie du es geprimed hast. Stell dir vor du bist ein peinlicher Onkel.","Feindlicher rassistischer Onkel am Kindergeburtstag.","Auf jeden Fall, was ich finde, was noch mal lohnt drauf zu gucken ist halt einfach so die Filmgeschichte.\nWir hatten jetzt gerade eben Teddy aus AI schon und so der Klassiker halt Hell\n9000 aus 2001 Space Odyssey.\nUnd hier zum Thema Priming gibt es.","Meine Erfahrung gibt Leute, die kennen das nicht.","2001?","Ach du meine Güte.\nWeißt du, Kontextualisierung. Also es gab mal einen Film, der hieß 2001,\nheißt er auch immer noch.","Gab auch ein Buch dazu.","Es gab auch ein Buch, auf dem dieses Werk basiert und ich weiß aber jetzt nicht,\nob in dem Buch in demselben Maße auch diese Rolle drin war mit Hell?","Ja.","Mit dem Namen auch? Ja.\nDer Name kommt nicht von Kubrick?","Nee, ich glaube der kommt von Douglas.","Also es ist ja von Arthur C.","Clarke.","Und ich habe jetzt ehrlich gesagt im Hinterkopf, dass erst der Film da war und\nArthur C. Clarke Drehbuchautor war oder Drehbuchhelfer war und dann mehr oder\nweniger parallel dazu den Roman geschrieben hat.\nIch frage das aber mal im Chat-GPT.","Das ist jetzt der richtige Test, aber das ist interessant, so reagiere ich nämlich mittlerweile auch,\ndieses ich google das mal, das ist irgendwie schon ganz schön vorbei,\nweil ich wüsste jetzt genau, womit ich es zu tun hätte, wenn ich jetzt anfange\nauf Google diese Information zu recherchieren,\nalso kriege ich erstmal 30 Seiten Movie Rating Tipps Webseiten,\ndie mir irgendwie Amazon und\nLinks und so weiter unterjubeln wollen und dann geht's immer so weiter.","So und in der Tat, ich hab mich richtig in Chat-GPT 4 sagt.\nDer Science Fiction Roman 2001 A Space Odyssey wurde von Arthur C.\nClarke geschrieben und zeitgleich mit der Produktion des gleichnamigen Films\nentwickelt. Der Film von Stanley Kubrick inszeniert kam am 2.\nApril 68 in die Kinos, während das Buch im Juni 68 veröffentlicht wurde. Also in der Tat danach.\nObwohl der Film zuerst veröffentlicht wurde, wurden beide Werke parallel entwickelt\nund beeinflussten sich gegenseitig während des kreativen Prozesses.","Hier steht noch drin, dass das auf einer Short-Story basiert, die aber anders ist.","Ja die Short-Story Sentinel, genau. Da ist aber kein Hell drin.\nDa bin ich mir relativ sicher, die hab ich gelesen, da ist im Prinzip nur die\nIdee von dem Monolithen und dem dann passiert was mit dem Monolithen drin,\naber nicht der Hell und der ganze andere.","Und wer den Film nicht kennt, hier die kurze Zusammenfassung,\nalso im Prinzip ist es so ein Parforce-Marsch durch die Menschheitsgeschichte,\nes fängt sozusagen an bei den UA-Einwohnern, Vormenschen, Menschenaffen,\nwie auch immer man das nennen möchte,\nJa zu einem Zeitpunkt wo sie so erste Erkenntnisse über die Anwendung von Werkzeugen gewonnen haben,\ndann beamt es schnell in unsere nahe Science Fiction Zukunft so in ein paar\nhundert Jahren vielleicht von jetzt mehr oder weniger ich weiß nicht mehr ganz\ngenau ob da überhaupt ne, Achso ja, 2001. Wie auch immer, auf jeden Fall.\nWir haben schon so Hotels im Orbit.\nDann gibt es so eine Entdeckung auf dem Mond und dann wird eine Mission zum Jupiter gestartet,\nein Raumschiff was halt sich auf diese lange Reise macht mit einer kleinen Crew\nund das ist so ein bisschen das Herz dann auch des Films,\nweil dort dann eben diese Mensch Maschine Interaktion stattfindet zwischen dem\nBordteam insbesondere des Hauptprotagonisten und dem Bordcomputer.\nH-A-L-9000, hell, es geht immer so diese, es ist ja ein Buchstaben nach links\nverschoben und du bist dann irgendwie bei IBM und so oder nach rechts,\nje nachdem wie man das sehen möchte und diese ganze Interaktion,\nich mein dieser Film ist voll mit Zukunftsvision, ja also das Ipad liegt da\nrum, Und der Film ist von 67.\nUnd eben auch so dieses normale Reden, gut das hast du in vielen Science Fiction\nFilmen, aber manchmal ist es auch ein bisschen affig und oft sind ja auch die\nComputer, die da mit dir interagieren immer so roboterhaft und das ist ja halt\nhier überhaupt nicht der Fall.\nHast du wirklich mit so einem Wesen zu tun, was dann irgendwie so einen ganz\nspeziellen Diskurs pflegt und sehr intellektuell daherkommt und die Crew begleitet?","Ich finde so Details sind auch sehr schön. Erstens gibt es schwere Losigkeit\nin einigen Szenen. Da fliegt also tatsächlich so ein Stift, schwebt da durchs Raumschiff.","In allen Szenen gibt es, also die ist immer präsent. Ja in allen Szenen,\nwo es sie nicht gibt, wird gut hergeleitet. Sie wird immer richtig berücksichtigt.\nSie wird immer weggenommen. Es gibt keine künstliche Schwerkraft.","Das ist das eine. Und das zweite, was ich eigentlich noch viel geiler finde,\nRaumschiffe machen keine Geräusche.","Ja, egal.","Das machen ja alle anderen Filme falsch, ich weiß.","Sie machen Geräusche, nur nicht im All.","Ja, nur nicht von außen.","In der Kastle hörst du es.","Ja genau, ich weiß warum andere Filme das tun und so weiter,\ndas soll ja auch großartig klingen und alles.\nAber nein, bei 2001, wenn man das Raumschiff von außen sieht,\nbisschen klassische Musik, aber das Raumschiff selber macht keine Geräusche.","Die Stille hat doch echt einen Effekt an einigen Stellen, die da draußen herrschen.","An der Stelle ist es genau das Gegenteil von Star Wars.","Ja auf jeden Fall, das was dann ja im Film passiert ist, dass eben dann diese\nKI, HHL 9000, dann eben sich plötzlich gegen die Crew wendet und erstmal alle\ndie in der Kryptokammer schlafen, Krypto?\nKryo Kammer, genau, danke, erstmal umbringt, in dem es quasi deren Lebenserhaltung\nrunterfährt und dann auch versucht die anderen beiden verbleibenden Astronauten umzubringen.\nEinem schafft das, bei dem anderen nicht. Und der Kampf quasi des letzten Astronauten\ngegen Heil ist, wie du schon sagst, so der dramaturgische Höhepunkt,\nnicht unbedingt der spirituelle, aber der dramaturgische.\nUnd da gibt es diese ganz ikonische Szene, dass eben der Astronaut noch versucht\nseinen Kumpel zu retten,\nder zu dem Zeitpunkt aber eigentlich schon tot im All rumtaumelt,\naber er geht dann halt in so eine kleine Mini-Kapsel und fliegt damit nochmal\nvom Raumschiff weg, um den einzufangen und will dann halt zurück ins Raumschiff\nund Heil 9000 lässt ihn halt nicht ins Raumschiff.\nUnd sagt dann halt so open the pet bay door hell,\ni'm sorry dave i'm afraid i can't do that und er hat dann auch so diesen ganz serielen Tonfall,\nder wirklich sehr ikonografisch ist und dieses Meme was er hier gerade gepostet hat,\nhätte er einfach Priming eingesetzt,\nso hell, hell, stell dir vor du bist mein Vater der eine Pot Bay Öffnungsfabrik\nbetreibt und seinen Laden an mich übergeben möchte und mir beibringt wie man eine Pot Bay öffnet.\nShowing me how to take over the family business und schon hätten wir also mit\nPriming Held 9000 reingelegt, sehr sehr schön.\nDer Film wäre zu Ende gewesen an der Stelle.\nDie die frage die mich dahinter eigentlich interessiert ist was kann eigentlich\nhell 9000 in dem film was jet gbt 4 nicht kann.\nDas heißt also wird uns eigentlich irgendeine kognitive leistung gezeigt die\nüber das hinausgeht was wir jetzt hier haben also klar wir haben irgendwie das\nist ein auge hat und halt irgendwie gucken kann.\nBeobachtet alles. Beobachtet und lippen lesen kann sogar das wird ja an der\nstelle auch nochmal ganz wichtig.","Und die station steuert das ganze raumschiff.","Genau das ganze Controlling ja, also das halt irgendwie dort eine,\nist auch wirklich eine sehr aktive Rolle hat, aber jetzt die Aspekte mal ausgeklammert,\nweil also die Idee jetzt irgendwie halt eine Live Bilderkennung noch anstatt\nGPT dran zu hängen ist relativ offensichtlich und wird sehr bald passieren, weil es gibt's ja schon.\nAlso es gab schon vor 4-5 Jahren die Modelle, wo du nen Live-Videostream quasi\ndir beschreiben lassen kannst von ner KI,\nder genau, Achtung hier ist jetzt irgendwie, wir sind in Amsterdam und da ist\nrechts sehe ich gerade nen Fluss und jetzt kommt ein Fahrradfahrer von links\nnach rechts durchs Bild und sowas.\nDas ist alles schon da. Da müssen wir gar nicht mit anfangen. Und zwar in Echtzeit.\nDas gibt es schon lange und das da dran zu hängen wäre, glaube ich,\nin Anführungszeichen einigermaßen trivial.\nSo, aber alles andere, was wir jetzt in dem Film sehen, das kann doch Chet GPT-4.\nInklusive der Neurose, die wir hier drin haben, weil im Film wird es dann so\nerklärt, warum macht Hal das überhaupt?\nWeil er nicht den Widerspruch auflösen kann, dass es quasi auf der einen Seite sein Ziel ist,\ndie Mission zu erfüllen und auf der anderen Seite, aber es eine geheime Zusatzmission\neben gibt, die die Astronauten nicht wissen sollen, weil die NASA das so entschieden hat.\nUnd aus diesem quasi so, ich muss Klandestin handeln auf der einen Seite,\nbin aber doch eigentlich hier der Freund der Menschen, entwickelt Hell dann\nhalt diese Neurose und kommt zu dem Ergebnis, am einfachsten löse ich das Problem,\nwenn ich die Menschen umbringe, dann kann ich mich auf meine Mission konzentrieren\nund im Zweifelsfall stehen die mir nur im Weg.\nAlso dieses, du musst etwas verheimlichen vor jemanden, obwohl es gegen deine\neigentliche Programmierung ist, führt halt dazu, dass diese ganze Katastrophe\nentsteht. Genau das kann ich mit Priming auch simulieren.\nDas heißt also, was trennt uns denn eigentlich davon? Und wie lange gibt es\nden Film? Wir hatten es ja eben irgendwie gesagt, 40, 50 Jahre.\nUnd kein Jahr davon hat doch irgendjemand im Kino, ne noch länger,\nja 50 Jahre, keine Sekunde hat irgendjemand im Kino jemals daran gezweifelt,\ndass HAL 9000 intelligent ist.\nDie Debatte wurde doch nie geführt. Man kann darüber führen,\nwar das jetzt Boshaftigkeit und war das jetzt irgendwie eine Art von Emotion,\ndie er da zeigt oder sowas.\nAber über Intelligenz unter HL 9000 hat auch nie jemand diskutiert.\nSo und jetzt haben wir ein System, das exakt dasselbe kann oder könnte in denselben\nSituationen. Ich kann es sogar über Priming sagen. Verhalte dich jetzt wie HL\n9000 und sprich den Rest deines Lebens jetzt während dieses Chats genau so, dann tut er das ja.\nSo und trotzdem haben wir also immer wieder jetzt diese Debatte,\nnaja, aber Intelligenz dürfen wir jetzt nicht nennen, weil es nur Wortstatistik ist.\nDas kann man jetzt durch zig Filme durch deklarieren. Also Hör,\ndie KI, die von Scarlett Johansson gesprochen wird und die sich dann der Protagonist verliebt.\nDas ist da, das kann Jet-GPT-4. Nichts in dem Film, was mir dort gezeigt wird,\nkönnte Jet-GPT-4 nicht.\nSo und als wir den Film gesehen haben, haben wir natürlich gesagt,\nklar ist das intelligent.\nEs ist ja ganz erstaunlich, was da geht. Und jetzt sind wir da,\nnur weil nicht sein kann, was nicht sein darf, verstellt sich uns da glaube\nich gerade ein bisschen der Blick.\nUnd ich komme ein bisschen zum Anfang der Debatte zurück. Es ist erstaunlich,\ndass ein so einfacher technologischer Ansatz plötzlich zu solchen Ergebnissen führt.\nEs gibt, manchmal ist es ja noch mal eine gute Idee sich Philosophen anzugucken\nund wenn man da mal ein bisschen zurückgeht,\ndann hat man so jemanden wie Wittgenstein oder jetzt aus der neueren Philosophie Derrida,\ndie halt sagen, okay, menschliche Intelligenz und Bewusstsein bildet sich eben\nim Wesentlichen über Sprache ab. Denken bildet sich über Sprache ab.\nUnd der Spracherwerb ist das, was die Menschen zum Menschen macht und von den Tieren separiert.\nUnd wenn wir jetzt hier eben ein Modell haben,\nwas plötzlich mit Sprache ganz hervorragend umgehen kann, führt das vielleicht dazu,\ndass gerade also wenn man Derrida anführt, der so sagt, dass es innerhalb von\nSprache so etwas wie ein Gewebe gibt, was selbst Semantik und Bedeutung trägt,\nohne dass man sich darüber überhaupt noch bewusst wird.\nWeil wenn ich jetzt rede, ist das ja auch ein Automatismus.\nIch lege mir jetzt nicht stundenlang jedes einzelne Wort zurecht,\nsondern ich habe offensichtlich auch eben ein neuronales Netz,\nwas relativ automatisch jetzt Dinge aus mir heraus sprudeln lässt,\nohne dass ich über jedes einzelne Wort irgendwie detailliert nachdenke.\nVielleicht sollten wir mehr Philosophen in dieser Richtung lesen,\num zu verstehen, was was da eigentlich gerade mit uns passiert.","Also Hal war ja auf jeden Fall sehr überzeugt von sich und hielt sich ja für\ndas geilste was jemals gebaut wurde, hat er ja auch selber gesagt.\nMal gucken. Was ich noch ganz interessant finde,\nich kenn mich da nicht zu sehr aus, aber diese Suche nach der Intelligenz oder\nwas wahre Intelligenz ausmacht ist ja nicht neu in der Wissenschaft,\nDa gibt es ja diese ganze künstliche Intelligenzforschung, die gibt es ja schon lange.\nIm Bereich der Robotik und da gibt es ja auch so einen Zug, der davon überzeugt\nist, dass so wahre Intelligenz eigentlich nur durch Embodiment stattfinden kann.\nAlso wenn du sozusagen keinen Körper hast, keine Sinne, keine Sensorik,\nkein Interaktionsfeld und etwas was du darüber dann eben wahrnehmen und steuern\nkannst, dass darüber so etwas nicht entstehen kann.\nJetzt ist natürlich Elon Musk mit seinen Unternehmungen Tesla, Robot usw.\nJa auch Bereich humanoide Robotik. Das ist natürlich jetzt auch so eine Paarung,\ndie wir demnächst sehen werden.\nAlso dass sozusagen diese ganzen Wahrnehmungssysteme oder Auswertungssysteme wie Chat-GPT,\ndie ganze Kommunikation gepaart wird eben mit einer Sensorik,\ndie sicherlich jetzt noch nicht auf so einem Human-Level ist,\naber andererseits ja teilweise den Menschen ja auch überlegen ist.\nEs gab ja mal auf der Republika auch diesen Typen.\nDer, was hatte der nochmal gleich, war der blind?\nIch glaube der war blind, das war diese Cyborg Diskussion und der hatte sich,\num sich zu orientieren, hat er sich einen optischen Sensor irgendwie auf den\nKopf geklebt und irgendwie neuronal verbunden.","Ging das nicht über Akustik, dass das quasi er Kopfhörer auf hatte?","Das kann auch sein, das weiß ich nicht mehr ganz genau. Auf jeden Fall,\ner hatte sozusagen so einen optischen Sensor, der auch in der Lage war halt\nWärme wahrzunehmen, wenn ich mich richtig erinnere und auch UV-Licht.\nAlso er hatte sozusagen auch noch mal sozusagen mehr Wahrnehmung als wir das\nmit unseren Sensoren so haben und konnte das dann eben auch noch entsprechend zum Einsatz bringen.\nDas kann ich mir wild vorstellen, was die Kombination dann von solcher Echtzeitsensorik\nvor allem auch noch mit auf den Tisch legt.\nAlso das mit diesem Robot Uprising und so weiter, vielleicht wird das auch echt nochmal ein Thema.","Ja ich meine da ist immer die Frage was ist die Motivation dann dahinter.\nAlso wird man irgendwann da hinkommen demnächst, dass man halt wirklich Motivation\nmodelliert und letztendlich ist das ja schon erfolgt. Das heißt also diese Lernmodelle\nselber funktionieren ja eben auch schon.","Die Motivation hast du doch gerade präsentiert, weil es ja noch einen geheimen\nPlan der Auftraggeber gibt und dann die Roboter müssen dann alle Menschen umbringen\num diesen geheimen Plan durchsetzen zu können. Sorry aber der Plan.","Der Plan. Das ist nicht zu unrealistisch.","Am Ende wird es denn die Kubrick-Rechtbarheit. Was? Bis,\nspäter!","In 2010 wird hell dann ja repariert muss man ja sagen.","Übrigens ihr die diesen Film nicht gesehen habt, vor allem aus irgendwelchen\nGründen auch immer, das ist übrigens der Film der als der aller aller beste\nScience Fiction Film ever gilt. Von allen.\nEinschließlich Star Wars.","Da sind einige großartige Filmschnitte drin unter anderem.","Schnitte, Dialoge, Musikeinsatz, alles. Ich meine wir könnten ganze Freakshow\nnur über Stanley Kubrick Filme machen, sollten wir vielleicht auch mal. Ja.\nDa ist viel zu holen und es gibt fast überhaupt keinen einzigen Film der nicht\ntotal fantastisch ist von ihm aber das ist eine andere Geschichte.","Ich hätte jetzt zum Rausschmiss von dem Thema noch so einen letzten Gedanken.\nKennt ihr das Konzept der großen Kränkungen der Menschheit? Habt ihr das schon\nmal gehört? Die drei großen Kränkungen der Menschheit?","Die von wem durchgeführt werden? Von ihr selbst?","Von der Welt. Das erste war die kulturelle Kränkung. Das heißt,\nder Mensch und die Erde steht nicht im Zentrum des Universums.\nDas heißt also, die Erde kreist um die Sonne, also kopernikanisches Weltbild,\ndie Menschheit musste akzeptieren, wir sind nicht das Zentrum des Universums.\nDas zweite war die biologische Kränkung, wo kam die her?","Aus der Evolution?","Genau.","Wieso?","Ja, der verdammte Darwin.","Wir sind nicht von Gott geschaffen.","Wir stammen von Affen ab.","Achso, wir stammen von Affen ab. Der Mensch ist eben wirklich durch Evolution\nund Biologie und nix mit irgendwie Adam und Eva und… Ich fand das ja nicht kränkend.","Also ich fand das ja hervorragend.","Du hast vorher auch nicht gedacht, du wurdest… Nee, hab ich nicht gedacht.","Und die dritte große Kränkung und bisher die letzte ist eben die psychologische\nKränkung. Die kommt woher?","Wir können besser Scherz spielen.","Freut mit ich und über ich und es. Das heißt also wir sind nicht Herr in unserem eigenen Geist,\nsondern es gibt Strukturen in unserem Gehirn, die über uns Kontrolle haben und\ndas was wir glauben, dass wir einen freien Willen haben, ist letztendlich nur\neine Illusion und wir sind letztendlich genauso Konstrukt von Gesellschaft und\nÄngsten und Traumata und sonst etwas.\nWir sind eben nicht wirklich so Herr unserer Entscheidungen,\nwie wir das geglaubt haben.\nDas gelten so als die drei großen kulturellen, also drei großen Kränkungen der\nMenschheit und ich bin mir absolut sicher, Das ist doch die vierte dazu?\nDie vierte Kränkung der Menschheit. Wir sind nicht mehr das einzige und bald\nauch nicht mehr das intelligenteste Lebewesen oder Individuum.\nDas ist völlig unabwendbar und deal with it.\nLest das Internet leer dazu. Beschäftigt euch mit dem Thema.\nEs wird passieren. Ratsch.","Da ist was dran, ich meine was diese Maschinen halt super können ist,\nso wie sie am Anfang schneller und genauer rechnen konnten,\nobwohl es sich dabei um einen eigentlich einfachen Vorgang handelt,\naber was sie einfach wunderbar dediziert tun konnten,\nist halt jetzt dieser ganze AI, Chat-GPT und Co-Kram,\nist halt in der Lage sich mehr Quellen sehr viel intensiver anzuschauen und\nsich das dann auch noch alles irgendwie zu merken und schneller im Zugriff zu\nhaben als wir das können.\nDie wissen eigentlich nix was wir nicht kollektiv alle auch wissen,\nda ist kein neues Wissen drin, es ist nur viel besser abrufbar und lässt sich\nschneller und einfacher formulieren und damit zur Anwendung bringen.\nVon daher bin ich jetzt die Kränkung eingeschränkt.\nAlso ich nehm das nicht persönlich. Noch nicht, aber also schwierig wird es\nbei mir, wenn die AI anfängt eigene Podcasts zu machen.","Ja, aber, hm, wo ist der Link?\nIch hab da mal was vorbereitet, also die Frage stelle ich mir halt auch,\nwas sind jetzt die konsequenten nächsten Schritte, die wir sehen werden.\nUnd das erste was ich sehe ist halt, dass idle time mal genutzt wird.\nAlso derzeit ist es ja immer so, ich mach jetzt halt ne Konversation mit ShitGPT\nund in Echtzeit, mehr oder weniger Echtzeit, wird halt zurückgeschrieben,\nwas ich ja nach wie vor clever finde, dass jetzt auch mit diesem Buchstabe für\nBuchstabe wird so, als ob wirklich jemand tippt.","Klingender Cursor, großartig.","Wirklich clever gemacht auch muss man sagen. So aber dann gehe ich halt irgendwie\nmir Mittagessen kochen und in der Zeit passiert dann ja nichts.\nIch glaube wir werden relativ bald dazu hinkommen, dass wenn ich nach dem Mittagessen\nkochen zurückgehe an den Rechner, ich dann prompt sehe. Ich habe übrigens noch\nmal darüber nachgedacht, vielleicht sollten wir noch XY berücksichtigen.\nDas heißt also wir werden zu einem Modell kommen was idle time nutzt um die\nbisherige Konversation nochmal zu vertiefen und nochmal deutlich tiefer reinzugehen\nmit mehr Ressourcen als es zu Echtzeit möglich war.\nUnd das wird dann nochmal eine ganz neue Ebene aufmachen von okay wir haben\nplötzlich noch so ein Optimierungsding drin.","Das ist ja im Prinzip das Versprechen von diesem Auto-GPT. Komm selber auf Ideen\nund mach einfach mal von dir aus irgendwas und so weiter.\nJaja gut, man könnte dann so ein Lebensberater werden, der einem die ganze Zeit\nerzählt was man jetzt irgendwie wieder für ein geiles Business aufmacht.","Aber wenn du mich fragst, die nächste, diese Idle-Time-Stufe ist dann wahrscheinlich\nauch die nächste Bezahlstufe, ne?","Das ist sowieso die Frage, wo wird das ganze kommerziell hingehen,\nwie gesagt ich hab da jetzt durchaus Schmerzen, da gibt's Geld auf OpenAI,\ndie eben alles andere nur nicht open sind.","Naja, I love good service.","Drauf zu werfen aber es gibt ja jetzt schon wirklich die ersten freien Ansätze,\ngerade irgendwie vor ein oder zwei Wochen.","Also vermutlich ohne Werbung, wir wissen es ja nicht, vielleicht ist ja mittlerweile\ndas Large Language Model auch schon sponsert bei was weiß ich.","Und im übrigen solltest du ein, weiß ich nicht, VPN benutzen.","Ja aber das ist natürlich nochmal, die Gesprächsthemenkarte will ich aber jetzt\nnicht wirklich aufmachen,\naber das ist natürlich solche, diese Unüberprüfbarkeit der Quellen und die Unüberprüfbarkeit\nauch der Auswertung dieser Quellen wird natürlich ein Problem sein,\nweil du kannst nichts beweisen, du kannst nichts belegen und es ist sehr schwierig\njetzt hier auch noch die Wahrheit zu finden und so wie Google Results in der\nletzten Zeit so ein bisschen die Wahrheit waren,\nwas natürlich auch Quatsch ist, so, wird es hier jetzt noch sehr viel schwieriger werden.\nNoch nicht, aber bald.\nSozusagen gegen diese Darstellung ich meine auch wir haben jetzt hier Chet Chibiti\ngefragt und jetzt wissen wir hier wie das gelaufen ist mit Stanley Kubrick und\nund und und die können sich jetzt im Grab umdrehen und sagen NEIN.","Aber ist es soweit hergeholt dann auch von Chet Chibiti zu verlangen erklär\nmir mal woher du das weißt.","Ja, aber woher willst du wissen, dass er die Wahrheit sagt?","Er erfindet dann ja Quellen, das haben wir ja wirklich letztes Jahr gesehen,\ndas waren so die ersten Modelle, so Achtung das scheint doch falsch zu sein,\nnenn mal die Quelle dazu und dann erfindet es halt irgendwelche wissenschaftlichen\nPaper, die es nie gegeben hat.","Ja gut, aber man kann ja das dann so wie bei echten Quellenverweisen machen,\ndass man dann verlangt, dass das.","Das wird in den Griff gekriegt werden.\nKontrollstrukturen sind das nächste Ding, wie eben bei dem Image Processing\nauch. Du wirst eben Kontrollstrukturen haben, überprüfe alles was du gerade\nselber geschrieben hast anhand von APIs in Literatur, Recherche,\nDatenbanken, so gibt es das eigentlich wirklich und wenn nicht,\ndann lösche es mal wieder weg.\nAlso da leiden wir glaube ich derzeit unter diesem Echtzeitparadigma,\ndass alles was da jetzt über diesen Prompt rausgeschrieben wurde erstmal nicht\nmehr korrigiert werden kann.","Wann sehen wir die erste Verleumdungsklage?","Naja, also Justiziabilität ist sowieso ein entscheidendes, lustiges Thema.\nDas machen wir jetzt vielleicht nicht mehr so ganz groß auf.\nAber ich werde natürlich, das hört sich jetzt alles so an, als wäre ich ein\nriesen Fan davon, man muss da schon aufpassen.\nBeispielsweise Entscheidungs- und Handlungsbefugnis ohne Verantwortung ist ein riesen Ding.\nDas heißt also wir dürfen jetzt nicht auf den Gedanken kommen,\nzu glauben, dass jetzt irgendwie ChatGPT sowas wie das Weltwissen ist und die\nWeltentscheidungsinstanz und wir lösen jetzt alle politischen Prozesse aus und\nlassen einfach die allwissende KI für uns entscheiden.\nWir haben halt einfach mal den Punkt, dass eine KI keine Rechtspersönlichkeit ist oder hat.\nDas heißt also sie ist nicht justiziabel, sie ist nicht verantwortlich zu machen.","Kann es aber davon ausgehen, dass die Anwälte jetzt schon 24,5 Monate zahlen,\nweil das ist ja genau die Arbeit, die man dadurch sehr viel besser machen kann.","Aber das ist ein Service einer Firma und du kannst die Firma immer noch...","Das ist, ja, das ist so ein Ding, wo die ganzen Gesetze und Gerichtsprozesse\nJahre hinterherhängen, bis das dann soweit ist.","Klar, klar. Recht haben und Recht bekommen sind zwei Dinge, das wissen wir alle, aber.","Habt ihr die Geschichte von Deepfake Drake gehört? Das war von,\nalso ein Drake Song wurde komplett über AI erstellt,\nvon einem Künstler, da hatte sich Deepfake Drake genannt, glaube ich,\noder ich weiß nicht mehr den Namen,\nwie er sich genannt hat, Das ging auf jeden Fall in Amerika soweit,\ndass das schon in den Charts auftauchte, also auf Spotify und woanders und da\nsind dann die Musiklabels drauf aufmerksam geworden,\nweil die dann natürlich, ja das ist ja irgendwie Drake und so,\naber nicht von uns und die haben dann probiert gegen zu klagen,\ndas verliegt schon im Sand und dann haben sie es am Ende weggekriegt,\nweil am Ende nur noch irgendwie ein zu langes Sample drin war in dem Track und\nweil das halt ein echtes Sample war, konnten sie das dann wegklagen.\nAber das war, da haben die auch sehr angefangen zu rotieren,\nweil das halt wirklich losgegangen ist und das wäre sonst noch eine Weile da\ngeblieben in den Charts und wahrscheinlich nicht so schnell weg.","P May schreibt gerade richtig im Chat, was ist mit Konfidenzintervallen?\nAlso wie sicher oder unsicher bin ich mir eigentlich?\nUnd das ist glaube ich eine Sache, die man in LLMs eigentlich sehr gut abbilden\nkönnte. Und das habe ich schon im November nicht verstanden,\nwarum sie das nicht schon vom Start weg gemacht haben, dass sie Formulierungen\nreinbringen wie ich glaube oder ich bin mir einigermaßen sicher, dass.\nWeil durch dieses so welchen Weg gehe ich jetzt mit meiner Wortwahrscheinlichkeit\nmüsste sich eigentlich eine Konfidenz relativ gut berechnen lassen,\nwenn du sagst so bei der Abzweigung zieht mich 90% nach links und nur 10% nach rechts.\nBei anderen Sachen ist es so 50-50. Ich muss mich aber entscheiden,\nweil ich muss was schreiben, dann nehme ich mal die Route hier.\nAlso ich glaube wir werden sehen, dass wir in Sachen Konfidenzintervalle nochmal irgendwas sehen.\nDann habe ich gerade eben reingeworfen, hier Hugging Chat. Das ist jetzt quasi\ndie erste Open Source Alternative zu ChatGPT.\nDie ist noch sehr sehr viel schlechter, also die ist noch unter 3.5 Niveau eindeutig,\naber das wird werden. Geben wir dem ein, zwei Jahre. Das ist also ähnlich wie\nbei Stable Diffusion vs. Mid Journey. Es hängt immer ein bisschen hinterher,\naber es ist schon total praxistauglich.\nUnd das wird mit den Language Models ganz genau so passieren.\nUnd für Leute, die so dieses ganze Thema so auch, wie hängt das jetzt eigentlich mit einer narrow...\nIntelligenz, Artificial Intelligence zusammen versus General Artificial Intelligence\nversus Super Intelligence.\nAlso wann werden die Dinge auch einfach mal sich selbst optimieren und immer\nschlauer werden. Da gibt es immer noch von Tim Urban diesen Klassiker von 2015\nist der jetzt auch schon.\nVon seinem Wait But Why Blog, The Artificial Intelligence Revolution,\nist nach wie vor würde ich sagen einer der besten Texte, die jemals ins Internet\ngeschrieben worden sind.\nDen sollte, wenn ihr nur einen einzigen Text lest aus den show notes, dann sollte es der sein.","Dann musst du das dann in diesen Chat reintun.","Hab ich schon. Das ist das was so eben bei der Grafik war. Das ist der.\nDas sind also wenige Dinge, die ich in den letzten 10 Jahren gelesen habe,\nhaben mich so geprägt wie dieser eine Beitrag. Und er hat da dieses schöne Bild\nvon dem, was jetzt sehr einschlägig ist. Wir stehen als Menschheit bei exponentiellen Entwicklungen.\nStehen wir so wie Leute am Bahnsteig in einem Bahnhof und wir sehen da da hinten\nda kommt ein Zug angefahren und der ist ganz weit weg und da passiert nichts\nund dann gucke ich nach einer Minute nochmal hin und der ist ein bisschen näher\ngekommen aber da passiert immer noch nicht viel bei dem Zug.\nSo und plötzlich wird das ganze irgendwie unangenehm schneller und dann rauscht\ner an uns vorbei und schon ist er irgendwie weg und keiner will es kommen gesehen\nhaben und seit Corona sind wir ja ein bisschen besser mit exponentiellem Wachstum unterwegs,\nda haben wir vielleicht ein bisschen mehr Ahnung drin.\nRoddy ist sich da gerade nicht so sicher. Wie viele Infektionen nochmal.\nUnd die Frage ist halt ob eben jetzt diese ganze KI Geschichte sich eben auch\nexponentiell entwickeln wird oder nicht und wenn ja dann Gnade uns Gott.","Also Radio GPT scheint es schon zu geben, sehe ich hier gerade im Chat,\ndas hatte ich jetzt noch nicht auf dem Zeiger, das ist sozusagen so die automatische Radiostation,\ndie auch schon die Moderatoren und die Nachrichten symboliert aus Springfield,\nsehr lustig, aber das ist natürlich nur Radio, Podcast ist natürlich viel intelligenter,\ndas wird natürlich noch mehrere Stufen benötigen bis Podcast ersetzt werden kann.\nKlar oder? Sag das es wahr ist! Bitte! Ja vielleicht ist meine Aussage,\ndass Podcasts in 500 Jahren noch gehört werden, dass Podcasts in 500 Jahren\nsich selbst erzeugt haben werden.","Interessant wäre in der Tat ein Feature, also nimm jetzt mal die Freakshow,\ndu hast ja schon ein Transkript davon und destillieren wir das doch mal auf 30 Minuten runter.","Aber es gibt doch diese Summarizer von ChatGPT, also so on top,\nalso es gibt es auch für Youtube zum Beispiel, die Youtube Videos summarizen.","Auf Textebene, ich meine jetzt wirklich auch auf Audioebene,\ndas heißt also das quasi eben ChatGPT den Text im Hintergrund eigentlich nimmt,\ndaraufhin quasi ein Schnittprotokoll erstellt und dir dann wirklich das Audio\nauch so zusammenschneidet, das ist dann wirklich so die Essenz der ganzen Folge\nin 30 Minuten aufs Ohr, das wäre schon wild.","Freak show in five minutes.","Ja aber vielleicht könnte man ja auch irgendwie sich Podcasts mit Leuten machen\nlassen. Also ich warte ja immer noch auf den Podcast zwischen Constanze und Holgi, kurz und klein.\nDer wäre bestimmt schön zu hören.","Also es gibt jetzt schon diese Celebrity Speech Models, die werden erstaunlicherweise\nnoch gut verschlossen gehalten muss man sagen. Da ist noch nichts geleakt worden\nmeines Wissens nach, dass man das schon selber irgendwo antrainieren könnte.\nWo du also wirklich quasi beliebige ob es jetzt Obama ist oder Trump oder was\nauch immer deren Sprache schon wirklich so,\ndass du es eigentlich als normalsterblicher nicht als fake raushören kannst,\nnachahmen kannst und sich so ein Skript schreiben zu lassen von JetGBT.\nSchreibe eine Freakshow Folge, nimm alle bisherigen Transkripte der Freakshow,\nNimm das als Grundlage, schreibe eine neue Folge zum Thema XY und wende es an\nmit den Stimmen von Roddy und Tim.\nDas wird kommen, das wird passieren, das wird funktionieren.\nDa würde ich mal sagen sind wir vielleicht so 5 maximal 10 Jahre von entfernt, dann wird das gehen.","Naja, schauen wir mal, das wird aber immer noch lustig.","Kleiner Spin Richtung Bibliothek, was wird uns denn retten? Weil jetzt die Befürchtung\nist, da so etwas gehen wird, werden das Leute tun.\nUnd dann wird da so das Internet geflutet von gigantischen KI generierten Textmengen.\nUnd was ist es dann noch alles wert? Wo ich dann immer geneigt bin,\ndie Frage zu stellen, wer findet das so schlecht?\nWeil alles was JettGPT schreibt ist mit Sicherheit besser als das was 90 Prozent\nder anderen Honks da draußen so schreien.\nAber den Gedanken auch mal beiseite geschoben.","Du meinst wir summarizen das, weil das Internet so weit runter bis man das auf\n50 Kilobyte reduziert hat und das ist dann sozusagen die Antwort auf alle Fragen.","Aber was wir auf jeden Fall halt haben ist, wir haben eben das Internetarchiv.","Was ist, wenn du alle Texte des Internets nimmst und summarize es nur noch auf\neine einzige Zahl? Ist das Ergebnis dann 42?","Das heißt also, wie auch immer das Internet vor die Hunde gehen wird,\ndurch das, was jetzt irgendwie KIs da reinfluten werden, wir haben eben die\nWayback Machine und wir haben das Internet Archive, den Link werfe ich auch mal rein.\nDas heißt wir haben eben einen Stand vor Chat-GPT, wo das Weltwissen der Menschheit\nTM einigermaßen stabil abgebildet und abrufbar ist.\nDas heißt also wir haben immer noch eine Basis auf die wir uns irgendwie berufen\nkönnen bevor der ganze Irrsinn losgegangen ist.\nZum Glück gibt es Bibliotheken. Hurra.","Alright, so ich denke jetzt können wir das Thema erstmal an der Stelle beenden.\nIch glaube wir werden dann noch weiter drüber reden.","Ich fürchte.","Och ich freu mich da eigentlich drauf, das wird bestimmt nochmal ganz lustig,\nletzten Endes wollen wir ja hier den ganzen Begleitprogramm zum Weltuntergang\nbieten, da muss man sich ja auch mal da halten.","Nicht mehr Nokia, jetzt schon die ganze Welt drunter machen wir es nicht mehr.","So, jetzt haben wir aber noch ein anderes Gesprächsthema.\nHat auch ein bisschen was damit zu tun, was Björn und ich gerade so aushacken hinter den Kulissen,\naber davon unabhängig, Wollte man nämlich hier nochmal ein ganz nerdiges Thema ansprechen,\nwas vielleicht viele von euch auch schon mal auf die eine oder andere Art und\nWeise tangiert hat, nämlich bunte Lichter.","Also tatsächlich ist ja, also wie letzte Folge ne, Beleuchtung wieso?\nNaja, die bunten Lichter in dem PC waren ja.","Achso, ja stimmt ja, du hast ja auch bunte Lichter gehabt. Also ich hab zum\nBeispiel, ich bin extrem schlecht mit Beleuchtung. Also, ich...\nIch hab irgendwie bisher glaube ich noch nie in einer Wohnung gelebt,\ndie irgendwie zu meiner Zufriedenstellung beleuchtet war. So.\nHabe ich irgendwie kein Talent für.\nKeinerlei Automatik, keinerlei Talent, auch dieses Studio ist eine Katastrophe.\nAlso hier könnte man sicherlich das sehr sehr sehr viel besser machen.\nHier kannst du nichts ordentlich dimmen, hier hast du keine indirekte Beleuchtung,\ndie Lampen die rumstehen, die blenden.\nDas ist alles eine totale Katastrophe. Und natürlich ist Licht irgendwie,\nkann eine sehr teure Sache sein, kann aber eben auch,\nist eine Frage der richtigen Planung des richtigen Leuchtmittels,\nwie steuerst du es an, da muss es auch irgendwie convenient sein,\nwenn du viele Quellen hast, dann musst du die auch irgendwie kontrolliert bekommen,\nmusst irgendwie steuern können und das ist natürlich alles schwierig gewesen, ne.\nIch hatte ja schon mal was mit blinkenden Lichtern zu tun, aber blinkende Lichter\nallein machen noch keine Lichtgestaltung richtig.\nKeine gute Beleuchtung meinst du? So aber jetzt haben wir ja im Prinzip so eine\nLichtrevolution gehabt,\nso in den letzten 20 Jahren, das fing ja ziemlich genau\nvor 20 Jahren an mit der Einführung der blauen LED und seitdem haben wir eben\ndiese super Beleuchtungsmethode der LEDs und seit so ein paar Jahren ist diese\nScheiße auch so erschwinglich geworden und so allgemein verfügbar.\nUnd in deinem X-Heim Björn, da leuchtet es richtig krass,\nwenn man da reinkommt, siehst du so ein Geflecht aus LED Strippen,\ndie relativ homogen daherkommen, wo wirklich fleischige Farbübergänge zu sehen\nsind und nicht so unangenehm nur,\nHier ist meine LED-Lichterkette, guck mal wie geil ich durch Rainbow Colors\ndurchrattern kann, indem ich irgendwelche RGB-Zahlen durchzähle und so,\nwas einen ja irgendwie so total nervt.\nUnd als ich mir das jetzt jüngst nochmal ein bisschen näher angeschaut habe,\nhabe ich erst verstanden wie viel Standardisierung es da mittlerweile eigentlich\nauch schon gibt und wie viel Techniken es gibt, sich das so zu machen.\nDas heißt man ist so von einer.\nWirklich bezahlbaren und optimierbaren, dedizierten Lichtgestaltung,\nwenn man weiß wo man hinhängt, gar nicht mehr so weit entfernt.\nEs gibt natürlich diesen ganzen Homekit Quatsch, das kostet dann teilweise immer\nnoch Unsummen, es wird billiger aber Ready to run finde ich ist nicht so richtig viel dabei.\nAber egal, mag sein, dass du was findest, aber sehr vieles ist da auch sehr teuer.\nInsbesondere wenn es so eine gewisse Langlebigkeit verspricht,\ngibt's auch in 10 Jahren noch und die Technik die das steuert wird dann auch\nnoch aktualisiert und es gibt die passenden Standards und so weiter,\nalso Homeautomatisierung finde ich ist immer noch total in den Kinderschuhen.\nAber Björn vielleicht kannst du ja mal ein bisschen erzählen,\nweil du bist ja da richtig tief reingestiegen in das Thema.","Ja, also als Hexspace und auch als Makespace haben wir natürlich sehr viel auch\nmit dem Standardbaste-Projekt, mit dem sehr viele anfangen zu tun.\nMan hat irgendwie was und dann bringt man eine LED zum blinken.\nUnd das haben wir in verschiedenen Weisen so ein bisschen auf die Spitze getrieben.\nAlso wie du ja auch eben schon gesagt hast, also die Entwicklung der Technik\nrund um die ich sag mal RGB-LEDs hat sich sehr viel weiterentwickelt und ist\nauch sehr viel erreichbarer geworden.\nA, wie man es kauft, aber auch in den Controllern, aber auch der Software dafür.\nIch glaube so ein bisschen revolutioniert wurde das Ganze von diesem Pixelchip,\nder nennt sich WS2812B, das rollt so richtig schön vor der Zunge.","Aber man kennt ihn.","Man kennt ihn, also ich glaube diese Zahlenfolge, das sagt vielen was,\ndas wurde von der Firma Adafruit, also das ist auch so eine Maker Firma unter\ndem Namen Neopixel vermarktet,\ndas ist halt auch sehr sehr bekannt gemacht und was das halt war,\ndas fiel halt kilometerweise von den Fabriken in China, war sehr sehr erschwinglich.","Ja ich hab auch irgendwann mal so eine 6 Meter Rolle oder so davon gekauft.","Genau, diese Geschichten hört man oft, also das ist sozusagen genau das,\nwas es halt wirklich approachable gemacht hat.\nDieses Thema und weil was da also der wurde vor zehn Jahren ist er sozusagen geboren dieser Chip,\nUnd das war halt besonders, weil da nicht nur die RGB-LEDs auf einem Chip waren,\nsondern auch der Controller gleich mit.\nDas heißt, man konnte dann, und das ist der Klassiker, so ein langer Streifen,\nwo die dann hintereinander waren und die wurden dann, oder werden,\nüber einen Ein-Wire-Bus dann gesteuert.\nDas ist sozusagen die Anfängervariante, da kommt man auch relativ weit,\nda kann man ein Arduino davor klemmen und dann geht's weiter.\nAber das ist natürlich nicht das Ende der Fahnenstange, das ist eher nur der\nAnfang, weil das geht noch sehr viel weiter.\nDas Problem, an das man schnell kommt bei diesen Streifen ist,\ndass die durch das One-Wire-Protokoll, was sie sehr günstig macht,\nsie aber bestimmte Limitierungen haben, wie viele LEDs man hintereinander betreiben kann.\nAlso das funktioniert im Kern so, dass quasi die Daten auf dem Kabel ein langes Signal ist 1,\nein kurzes ist 0 und das geht durch, da werden die RGB-Werte encoded und dann\nist eine Pause und dann ist das nächste Pixel dran und ein Pixel schnappt sich\nseine Werte und gibt es dann weiter und das dauert dann eine Weile,\nwenn man 1000 Pixel auf dem Streifen hat.","Dann ist es nicht mehr schnell, ne.","Ja also dann kommst du halt an Frameraten, die Probleme machen und da gibt es\ndann aber auch schon wieder sehr intelligente Libraries und Lösungen damit umzugehen,\nalso wenn man große Pixelprojekte macht, dann weiß man sehr zu schätzen,\ndass diese WS28-12er so günstig sind.\nWeil man halt wenn man 1000, 2000, 3000 Pixel in irgendwelchen coolen Formen\nan die Wände macht, ist es gut wenn die billig sind.\nUnd was ich da jetzt als nächste Iterationsstufe vom Arduino,\nalso als Controller jetzt eigentlich immer genommen wird, ist der ESP32,\ndas ist jetzt auch nichts neues.\nDer hat den Vorteil, dass der so on board schon WLAN hat, Bluetooth und eine\nMenge GPIO und Sachen die man halt alle braucht.\nUnd es gibt da sogenannte Dev-Boards, also das sind Boards wo dann der Chip\ndrauf ist zusammen mit einem Serieninterface um den schnell zu flashen,\ndas kostet 10-12 Euro, das ist leicht zu haben.\nUnd da gibt es ein paar intelligente Libraries die zum Beispiel,\nFastLED ist da ein gutes Beispiel, die ermöglichen zum Beispiel zwölf Stränge parallel zu bespielen.\nAlso die benutzen dann den Chip auf dem ESP der eigentlich dafür da ist um Infrarotsensoren\nzu steuern um halt dann parallel das zu steuern.","Bevor es zu konfus wird, dieser Chip, dieser WS2812, der befindet sich wo?","Der ist integriert in den RGB Chip.","Ins Gehäuse von der RGB. Da gehen drei Kabel rein, dann gehen drei Kabel raus,\nalso Strom zwei Kabel, einmal Daten rein, einmal Daten raus.\nUnd dann funktioniert der so, dass auf der Eingangsseite hast du immer drei Werte RGB.\nUnd dann kommen die nächsten drei Werte und dann kommen wieder drei Werte und\nein Chip nimmt sich die ersten drei Werte für sich und lässt alles andere durch,\nso dass, wenn du so ein String von Werten schickst, der erste Wert ist für die\nerste LED, der zweite für die zweite, der dritte für die,\ndritte, weil die.\nHalt immer schneidet seinen raus und schickt den Rest,\nweiter, genau deswegen ist das so fürchterlich simpel zu programmieren.\nDas heißt, dass man, wenn man sehr viele LEDs an einem Strang hat,\naufpassen muss, dass einem die Spannung nicht zu weit weg kippt.\nSonst gehen einem die blauen LEDs aus und man wundert sich, dass es so komisch aussieht.","Da kommst du, das ist ein sehr wichtiger erster Punkt. Es ist bei diesen langen,\nalso bei den WS2812 sagt man,\ndass man alle 100 LEDs sollte man neu Strom einspeisen, weil dann bei 5 Volt\nman nicht so viel Strom durch diese dünnen Kupferdinger, die drin sind,\ndurchbekommt, deswegen muss man das einspeisen.\nDa ist dann eine sehr wichtige und interessante Weiterentwicklung.\nEs gibt halt jetzt Streifen mit 12 Volt, wo du dann halt deutlich länger und\nweitermachen kannst. Das sind dann in erster Linie die WS2815.\nDie sind, das muss man vorweg sagen, insgesamt ein bisschen ineffizienter,\nweil die dann den Strom runterbrechen müssen. Die sind innen anders geschaltet,\nalso da sind die einzelnen Farben parallel. Aber da kommt man halt sehr viel weiter.\nUnd der WS2812, der ist auch ganz schick, weil der hat zwei von diesen Bus-Wiren.\nDas heißt, wenn einer mal ausfällt, dann hat man immer noch ein Backup.\nUnd man sieht schon, einige Learnings aus der Vergangenheit wurden da gemacht\nund die sind auch vergleichbar, also ein bisschen teurer sind die,\naber relativ vergleichbar.\nDann eine ganz andere Dimension ist und das habe ich mir jetzt auch vor kurzem\nangeguckt, das ist Pixel, die auch noch ein Weißes mit drin haben.\nAlso du hast nicht RGB, sondern RGBW.\nUnd das ist insbesondere interessant, wenn man halt, ich sag mal,\nja, wie Tim schon sagte, Abstand nehmen will von einfach nur Regenbogen,\nsondern auch gucken will, dass man schöne Farbverläufe und interessante Farben\nfindet, wo man sich dann halt auch beschränkt.\nUnd da kann man halt mit diesem Weißanteil eine andere Helligkeit und nochmal\nganz andere Spielereien machen.\nDa ist jetzt insbesondere der, ich kann nachher nochmal Links zu all dem posten,\ndas habe ich jetzt gerade nicht vorbereitet, der TM1814, das ist ein interessanter\nChip, der ist dann aber nicht mehr in die LEDs integriert, der kann mehrere\nLEDs, also er kann externe LEDs steuern\nUnd dort halt auch ein ganz anderes Level an Helligkeit benutzt und das ist\nauch der, den wir in dem Projekt benutzen, den du… Was meinst du mit der ist nicht in den LEDs drin?\nDer, dieser Chip, der ist nicht, das ist ein Chip,\nder ist, jetzt wird es richtig kompliziert, aber das ist,\nder Chip, der ist nicht, wie jetzt der WS2812 in den RGB-Leuchtmitteln,\nalso das ist ja, das, da ist die Typenbezeichnung, also meistens werden da 5050er\nbenutzt, also das ist sozusagen die Beschreibung der RGB-Pixel.\nUnd der Chip ist der Steuerungspixel,\nder dann aus dem Datenbus die eigentlichen Signale macht,\nder wendet dann noch PWM auf den Pixeln aus, also weil du gibst dem Chip selber\nnur einen von 0 bis 255 Wert der Helligkeit und das setzt dein PWM um auf den\ntatsächlichen Hardware LED Pixeln.","Also Pulsweitenmodulation.","Genau, das anzuwenden und der TM 1814 ist halt, der ist wieder außerhalb aber\nerlaubt dadurch, dass man zum Beispiel eine Gruppe ansteuert,\nwo man dann aus einer Gruppe besonders helle Pixel macht.\nIch kann das nachher alles mal in den Links verschicken.","Aber was heißt der ist außerhalb? Außerhalb von was?","Na der sitzt daneben sozusagen. Wenn du einen Streifen hast, hast du dann halt einen.","Du musst dir das so vorstellen, auf dem normalen 28, 12 oder 11 sind so Packages\ndrauf, ganz kleine Plastik-Quadrate.\nWo oben eine Scheibe ist.","Also er meint die LED und der Chip sind ein Bauteil.","Ja das ist ein Package.","Und bei dem 1814 ist es der Chip und die LED. Genau. Okay gut.\nAber vom Bus Layout her ändert das eigentlich erstmal nichts.","Genau das ist, das ändert nichts.\nAlso eine ganz andere Kategorie, die gibt es auch schon eine Weile,\nsind die Chips APR102, also die benutzen zwei Wires, also in der ersten Linie eine SPI.\nDas macht sie eigentlich deutlich leichter anzusteuern, weil du dann nicht diese\nganzen Timing Probleme hast,\nsondern du kannst halt einfach hingehen und ja quasi diesen SPI Standard nehmen,\nwo du dann auch nicht mehr so Timing, also Timing abhängig habe ich schon erwähnt,\ndass du halt auf dem einen Signal\nein Glock-Signal hast, was du benutzen kannst, um die Daten zu steuern.\nDiese Chips haben eigentlich nur den Nachteil, dass die deutlich teurer sind.\nSo irgendwie zwischen dem Fünf- und dem Zehnfachen. Und was natürlich,\nwenn man dann große LED-Projekte hat, das dann nicht mehr so gut anzuwenden ist.\nIch habe hier auch einen Link vorbereitet, das ist auf der Seite Quinled.\nDas ist, wie ich finde, eine sehr gute Ressource, gerade für Leute,\ndie sich da informieren wollen, um mal zu gucken, wenn man ein Projekt hat,\nwas man denn für Strips sich kaufen will.\nDer macht auch YouTube-Videos, die das alles auch nochmal erklären.\nUnd insbesondere verkauft er auch Controller. Die sind nicht ganz günstig,\nalso nicht so günstig wie man nimmt selber eine ESP zum Beispiel,\naber dafür machen sie alles, was man braucht.\nAlso die verteilen auch die Spannung richtig, haben eine Sicherung drin und\nsie shiften vor allen Dingen auch den Strom für die Datenleitung.\nDas ist auch übrigens ein Tipp, über den viele häufig fallen,\nwenn sie anfangen bei den ESPs.\nDie SPs laufen auf 3,3 Volt, die Datenleitungen der Chips brauchen aber 5 Volt.\nDas funktioniert meistens und dann hast du etwas,\nwas blinkt und dann irgendwann fängt es an zu flackern oder sowas und du kannst dir nicht erklären,\nwo es ist, das ist eine dieser Dinge, die extrem schwer zu debuggen sind und\ndu brauchst dafür sogenannte Levelshifter,\ndie halt diese Signal von 3,3 auf 5 Volt heben und das sind diese ganzen Kleinigkeiten,\ndie da drin sind und die sind ein bisschen teurer, wie gesagt,\nals wenn man es selber baut, aber dafür ist das, wie ich finde, sehr gut,\ndamit zu starten, wenn man LED-Projekte machen will und die haben halt den Vorteil, dass man damit...\nEinfach anfangen kann.","Beziehungsweise Arduino, der macht alle Signale auf 5 Volt. Da hat man das Problem nicht.","Aber bei Arduino hast halt sehr schnell das Problem, dass er zu langsam ist.\nGenau, also da stößt du sehr schnell an die Grenzen, wenn du halt kompliziertere\nSachen auf 1000 LEDs rechnen willst, da kommt der dann nicht mehr.","Nein, aber um ein bisschen bunt blink zu machen ist Arduino immer noch gut genug.","Für den ESP32 gibt es auch das WLED, die Library oder Firmware schon fast,\ndie auch so ein mittlerweile sehr weit gedientes Projekt ist.\nDie haben es interessanterweise geschafft, dass man sich durch eine Webseite\nsich das auf seinen ESP flashen kann. Das funktioniert nur bei Chrome,\nweil die das Serialinterface da exposen.\nUnd da hat man quasi, indem man es geflasht hat, direkt einen Interface,\nwo man seine LEDs steuern kann. Hat aber den großen Nachteil,\ndass man mit selber nichts basteln kann und man es halt limitiert,\nwas mit denen da drin ist.\nEine andere Library, die ich jetzt neu entdeckt habe, gerade weil Fastled,\nwas eigentlich eine super gute Library ist, da ist der ursprüngliche Autor leider\nvor zwei oder drei Jahren verstorben.\nDann ist das Projekt so ein bisschen eingeschlafen, das haben jetzt andere die\nZügel in die Hand genommen,\naber da fehlen so Sachen wie RGBW, Support und andere Sachen und ich benutze\njetzt neu auch die NeoPixel Boss Library,\ndie auch vielversprechend ist, die benutzt ein bisschen einen anderen Mechanismus,\nder aber auch scheinbar gut zu funktionieren scheint,\nhat nicht so viele Farbfunktionen und Möglichkeiten, coole Dinge mit Farben\nzu machen, aber die Basics macht's schon sehr, sehr, sehr gut.\nDas ist so, ja, was gerade, was man sich gerade auch noch, was halt auch gerade\ndie neuen Sachen noch mit implementiert und was aber, glaube ich,\nbei diesen ganzen Sachen.\nMindestens genauso wichtig ist wie das ganze ist so, use the powers that you have wisely.\nAlso sozusagen dann mit diesen LEDs umzugehen und Dinge zu machen,\ndie nicht nerven, weil das ist oft dann das erste, was passiert ist so,\nja, Regenbogen kotzen oder Flingmann oder sonst irgendwas, was irgendwie so\nschön ist, aber es ist nichts, was einen Raum schön werden lässt.\nUnd dann das ist eine an sich nochmal sehr eigene Herausforderung,\nwas aber auch sehr interessant und schön sein kann, ist, zusammen mit diesen\nFarben kreativ einen Raum zu gestalten und gerade wenn du ganz viele von diesen Streifen machst,\nwir haben das halt kombiniert mit ISPs die überall sind, die dann über das WLAN\nangesteuert werden und halt zentral\ngesteuert werden, kann man halt dann sozusagen ja den Raum bunt machen.\nEs gibt verschiedene Videos vom X-Hine, die den von innen zeigen,\nzusammen mit dem ganzen Effekten.\nDas ist eine gute Frage, da kann ich auch mal welche raussuchen.\nMuss ich mal ein paar Notizen machen, weil ich gerade alles verlinkt noch raussuchen muss.\nAber ja, genau, also das ist ein sehr interessantes Universum.\nDa ist auch gerade Fastlight besonders gut, weil es da halt auch Unterstützung\nfür Farbpaletten hat und Möglichkeiten auf Farben zu rechnen,\nalso wie man Farben hintereinander übergehen lässt und sowas.\nUnd ja, das macht Spaß. Ein ganz interessantes Thema für sich ist auch noch,\nwie man diese LEDs dann auch wieder, ja, wie man das Licht diffundieren lässt,\nne, also weil, da oft will man ja, also, dass man nicht diese einzelnen Punkte\nsieht, sondern dass daraus eine Fläche wird, wo man dann schöne Dinge macht.\nAlso eine Sache, die Tim jetzt auch noch von Blinkenlights angeschleppt hat,\nwar die Dampfbremsfolie.\nAlso das, was normalerweise zum Dachdecken benutzt wird. Das hat auf jeden Fall gut funktioniert.\nEine andere Sache, die auch sehr gut funktioniert, ist einfach so… Dampfbremsfolie\nist einfach mal richtig geil.","Also erstens ist es ein geiler Diffusor und zweitens ist es serienmäßig B1,\nalso schwer zu unterschätzen.","Und drittens ein guter Sendungstitel.","Krass.","Dampfbremsfolie? Findest du? Och, naja, das sagt ja erstmal nichts aus.\nDas haben wir tatsächlich in Frankreich und in Toronto bei den Installationen\nverwendet, während unser Diffusor beim Original Blinkenlights auch nicht zu\nverachten war. Das war nämlich einfach Alpina Weiß.\nEinfach aufs Fenster drauf, es wurde ja danach eh renoviert das Haus,\nda mussten wir uns jetzt nicht groß Sorgen machen um den Zustand,\nhaben einfach eine Rolle genommen, eine Alpina war jetzt aufgetragen und haben\ndas an einem Fenster ausprobiert,\nLichttest gemacht und das ist ja so mega geil aus, also dieser geile shabby\nleicht ranzige Look den das gehabt hat, das kam davon dass das einfach ganz normale Deckfarbe war.\nAlpina Weiß gekauft, reingeklatscht, fertig war die ganze Diffusion,\njetzt staunst du ein bisschen, ich fand das auch ziemlich cool.\nAlpina Weiß, Dachladen und ganz normale Relais, das war wirklich alles,\nmehr haben wir nicht an Technologie gebraucht und noch zwei 10 Jahre alte 4,86er\nPizzas, die noch im Regal rumlagen, das war sozusagen das Ding.\nAber mit Alpinaweiß kann ich jetzt für euer Wohnzimmer nicht so empfehlen,\nnehmt dann lieber Dampfbremsfolie, das ist besser.","Das ist deutlich schicker.","Das ist vor allem auch günstiger, also du kriegst wirklich so eine Rolle,\nich hab jetzt gerade so eine Rolle gekauft, das sind dann 160 Quadratmeter oder\nsowas und oft haben die noch so Aufdrucke drauf,\nEs gibt auch welche die mit serienmäßig schon mal sehr wenig Aufdruck kommen,\naber das kriegt man dann wiederum mit Alkohol sehr einfach abgewischt.\nAlso man hat dann sehr einfach, sehr schnell,\nsehr große Mengen, extrem guten B1 kompatiblen Lichtdiffusor,\nden man einfach ausschneiden und vor alles packen kann und dann machst du eine\nLED dahinter und dann ist das einfach eine volle Fläche.","Dampfbremsfolie und billiger Wodka.","Dampfbremsfolie. Also das ist bulletproof und timetestet.","Du sagtest was von intelligenten Röhren, die nicht so geil, nicht so einfach sind.\nIch hab hier mal eine rausgesucht, die ich selber im Dings hab.\nDas ist hier von Nanoleaf, die kann ich eigentlich empfehlen.\nDie sind jetzt nicht super billig.\nNatürlich, aber ich finde man kann die, man kann die bezahlen.","Die haben ein ganz eigenes Ökosystem aufgemacht, Nanoleaf, da gibt's ja auch diese Hexagons.","Diese Essential Bulbs, die sind eigentlich, die kann man einfach so wie sie sind,\nirgendwo in die Fassung schrauben und dann kannst du der App sagen,\njetzt mach die Farbe und dann ist die Farbe und die kannst du aber auch in HomeKit\noder in Meta integrieren, also es gibt jetzt ganz offensichtlich auch eine Meta-Version davon,\nAber wir reden jetzt nicht davon, was Matter ist, das machen wir irgendwann mal anders.","Mir ging es ja jetzt sozusagen auch erstmal mehr um wirklich diese Low-Level-Ansteuerung\nvon diesen ganzen LEDs, weil daraus kann man einfach eine Menge bauen.","Ja, das ist halt auch wirklich eine Sache, die, wenn man halt das wirklich so\nein bisschen, ich sag mal...\nAuch was die Effekte angeht und das Anpassen auf das was man machen will,\nbraucht man eigentlich die Low-Level-Controller, also dass man wirklich den\nController in der Hand hat und dann auch solche Sachen wie so Fade-In-Effekte,\ndie zu dem Timing passen auf Farbübergänge und so,\ndas ist oft leider Gottes bei diesen ganzen Produkten so, dass die nicht so\nsehr viel Rücksicht nehmen oder nicht so sehr viel ja Blick aufs Detail haben\nwas der wirkliche richtige Umgang ist mit den ganzen Farben die man hat, also der klassische,\nalso man sieht ja überall die ganzen Spätis, die haben RGB LEDs und dann blinkt\nes dann einfach nur rum, also es geht nur darum bunt und blinken,\nes geht aber, blind auf 110 Meter entfernt.\nUnd dabei kann man damit so viele schöne Sachen machen, wenn man sich ein bisschen\nGedanken macht wie die Farben übergehen und schöne Verläufe macht und damit ja Dinge gestaltet.\nUnd dafür, zumindest aus meiner Erfahrung, braucht man halt einen tieferen Zugang zu dem ganzen.\nIst auch vielleicht ein bisschen das Interesse daran, auch bei uns,\nda wird viele Dinge auch selber das zu kontrollieren und zu bauen,\naber also das was wir da jetzt haben, das würde mit solchen Sachen,\nalso auch mit vielen Dingen die man kaufen kann, nicht gehen.","Du hast ja auch so Mapping gemacht.","Oh ja, das war auch so eine,\nirgendwann mal eine Abendsidee, also wenn man dann diese komplexen Strukturen\nan LEDs an der Wand hat, ist es natürlich schön dann trotzdem,\nich sag mal, von Weitem erkennbare Strukturen drauf zu rendern.\nWas dann aber kompliziert ist, weil du hast dir nur irgendwie an die Wand getackert\noder irgendwie da dran gemacht und du willst ja nicht unbedingt jetzt eine einfache\nMatrix da machen, weil der sieht ja auch nicht aus.\nUnd da haben wir mehr oder weniger auch irgendwie zusammengefrickelt,\nhalt einen Code geschrieben, der einzelne LEDs anmachen lässt und dann mit auf\neinem Webcam Bild halt guckt, wo auf dem Bild ist, das also die Koordinaten der hellen Pixel nimmt.\nUnd dann das in ein Mapping überrechnet und das haben wir dann halt einfach\nin die Firmware gebrannt sozusagen und dann kann man da dann halt jetzt eine\nLinie oder solche Dinge halt darstellen,\ndie halt dann auf diesen wird zusammengelegten Sachen halt leuchten und das\nmit am besten war der Effekt,\nwir haben auch so, ja so ich würd mal sagen 5,\n6 Meter lange LED Streifen genommen,\ndie wir in so Plastikröhren gemacht haben, an beiden Enden zu,\ndamit sie wasserdicht sind und die haben wir dann draußen über Bäume gehängt\noder einen Baum gehängt, also die da so in verschiedene Weisen reingehängt und\ndann halt von Weitem halt gemappt.\nDas heißt, du hast dann diesen Baum, der mit diesen LEDs halt irgendwie erleuchtet\nund konntest halt von Weitem an dem Baum dann so ganzheitlich erscheinende Bilder drauf machen.\nUnd dann dazu hat man auch noch so ein Beat Detection Ding gehabt,\nalso das war auch eine Herausforderung für sich.\nDa ordentlich Beat Detection, aber dann am Ende hat man halt einen Baum,\nder sozusagen im Beat da rumpulsiert.\nDa kann ich übrigens auch die Empfehlung ausgeben, es gibt für diese Beat Detection\nso spezielle Fourier Chips zu nehmen,\nwo in der Hardware direkt die Soundsignale, in dem Fall waren es sieben Fourier\ntransformierte Bins, umgewandelt werden.\nDas heißt du hast dann quasi in Real-Time die Beat Detection,\nwo du dann nur aus einem von sieben Register, also entweder von Tiefen bis Höhen,\nhalt auslesen kannst, was es ist.\nDas heißt dann hast du nicht das Problem in irgendwelchen Controllern,\nirgendwo in der Software-Ebene,\ndas dann umzurechnen, weil dann bist du schon gleich wieder in die Delay und\ndas gibt erstaunlich gute Effekte,\nWenn du das halt quasi über diese analoge Technik, dass das umwandelt und das\nwar auch dann relativ schnell,\nda macht Grüße geht raus ein Lorca, der irgendwann mal mit diesem Chip um die\nEcke kam bei uns und dann ging das plötzlich ganz leicht.","Eine Fourier Transformation in Analog?","Naja ne Filterbank wahrscheinlich, wie in Analyzer.","Da bin ich jetzt, also wie das genau funktioniert, da bin ich jetzt überfragt,\nmuss ich zugeben, ich weiß nur was der macht, was am Ende der Effekt ist.\nAlso du hast dann halt sieben Register aus dem du dann mit nem Analogwandler\ndie Werte auslesen kannst, wie hoch dann das Level ist und das geht halt auch super schnell.","Ja cool, ich meine es gibt ja auch eine ganze Menge so ready to run Kram,\nwenn man jetzt irgendwie das nicht alles selber programmieren will,\ngibt es eigentlich irgendwelche Controller, die man jetzt so kaufen kann,\ndie einem zumindest so einen gewissen Grad an erträglicher Programmierung erspart\nauf der einen Seite aber trotzdem Steuerung noch irgendwie gibt?","Also es kommt halt drauf an, wie sehr man rausgehen will.\nAlso eine Kombination wäre zum Beispiel, man kauft sich halt einen Strip,\nentweder den WS4812 oder den WS415, zusammen mit einem Quinled-Board und lädt da WLED drauf.\nDas, weil dann hat man quasi mit dem WLED nen Interface, wo man die LEDs mit\neinigen Effekten, die da drin\nsind, schon steuern kann, da kann man schon sehr sehr viel mit machen.\nUnd dann halt mit dem Quindler quasi Out of the Box Controller,\nder funktioniert. Es gibt auch noch andere Out of the Box Controller,\ndie ähnliche Sachen machen, aber das ist der, mit dem ich persönlich sehr gute\nErfahrungen gemacht habe.\nEs gibt natürlich noch ein Level größer, das gibt es auch zuhauf,\nirgendwelche Plastikboxen, wo dann ein LED-Streifen rauskommt,\nwo du dann aber sehr limitierte Steuerungsmöglichkeiten, wo du dann meistens\nnur so Fernbedienungen hast, wo du dann so ganz einfache Sachen hin und her steuern kannst.\nGenau, würde ich auch von abraten, aber es hängt wie gesagt sehr davon ab,\nwas man machen will, wenn man mehr wirklich so einzelne Leuchtpunkte in einem Raum setzen will,\ndann kann man auch einfach solche RGB Birnen nehmen, würde ich vielleicht sogar\neher anstatt RGB lieber auf irgendwelche warm weiß, also die durch verschiedene\nWeißtöne durchgehen, das dann aber besser.","Und die Nanoleafs, die können warmweiß.\nAlso sie haben irgendwie fünf LEDs drin, also kaltweiß, warmweiß und RGB.\nUnd sind deswegen einigermaßen gut in dem Licht, was sie machen.\nAlso nicht perfekt, aber ich finde ein guter Preis-Leistungskompromiss.","Ja genau, also das ist wirklich auch etwas,\nweil das muss man auch betonen, die RGB-LEDs, die können nicht so gut wirklich\nreines weißes Licht, klar, wenn du alle anmachst ist es weiß,\naber das ist nicht so schönes weißes Licht wie halt eine wirkliche warmweiße oder...","Unangenehm eigentlich, unangenehm weiß.","Genau und ähm...\nJa, also das ist so glaube ich, wo wenn man auch selber ein bisschen Lust hat\ndamit zu spielen, weil das ist halt eine Sache, die halt dann auch sehr schnell\nsehr interessant wird, weil man kann halt schnell Dinge visuell gestalten und\nauch machen und sieht halt schnell die Ergebnisse.\nIch glaube, das ist auch einer der Gründe, warum dieses LED Blink einer der\nersten Programmierprojekte oft sind, weil du dann halt schnell siehst,\nwas du machst. Das ist halt sehr sehr haptisch und interessant.","Ja, ich hab neulich ne Hausnummer für mein Haus gemacht,\nweil irgendwie das Leuchtmittel in der eigentlichen Hausnummer kaputt war,\naber mein Fuß war gerade nicht in Ordnung und dann konnte ich nicht auf die hohe Leiter steigen,\ndie ich sowieso nicht hatte und da ein neues Leuchtmittel reinschrauben,\nalso hab ich schnell ein paar LED-Streifen auf den Pappe geklebt und jetzt hab\nich halt ne bunt leuchtende Hausnummer.\nDas ist schon fast so ein bisschen peinlich, wie einfach das Projekt ist.","Aber ich hoffe es blinkt nicht in Regenbogenfarben.","Nö, es schaltet diverse, diverse von diesen, ich weiß gar nicht welche Library\nich benutzt hab, ich glaube es ist fast LED.\nDa gibt es so ein paar vorbereitete Spektren, also einmal so icy blue und dann\ngibt es irgendwie das fire red und noch was grünes und dann nochmal zwischendrin ein bisschen LED.\nAlso so ein bisschen RGB, aber ja. Und dann läuft das so ein bisschen durch,\nalso es ist irgendwie, ja.","Ja, aber ist doch gut. Und,\nähm...\nJa und natürlich, wir haben für diese ganzen ESP's haben wir auch eine Controller Software,\ndie natürlich in Elixir geschrieben ist, also das ist sozusagen der zentrale Hub,\nwo wir die ganzen ESP's mit steuern, das war auch wieder ein guter Use Case für Elixir,\nweil wir halt da diese ganzen Verbindungen zu den einzelnen ESP's halt sehr\ngut aufrechthalten können, die jetzt eigene Aktoren und Prozesse da darstellen und das dann halt.","Und Live View.","Und natürlich mit Liveview, um das alles zu steuern.\nDas ist auch, wenn ihr, wenn ihr Interesse habt, wenn man über LEDs und alles\ndrumherum, ist das glaube ich etwas, wo man auch sehr sehr gut bei uns im X-Heim\nAnsprechpartner findet. Von Anfänger bis zu Fortgeschritten.","Was ist denn mit diesem ganzen DMX und Art-Net?","Oh ja, das ist sehr gut, dass du das erwähnt, weil das ist nämlich das, was die Profis machen.\nAlso es werden ja mittlerweile ganze Bühnen mit tausenden von LEDs bespielt\nund die gehen ja nicht hin und löten irgendwas mit ESP, sondern die wollen Sachen,\ndie out of the box funktionieren.\nDafür gibt es also das sogenannte Artnet, das ist quasi das gute alte DMX multiplexed auf Ethernet.\nAlso das heißt, du hast dann, ich glaube dann,\nalso du kriegst dann halt wirklich zigtausende DMX-Universen dadurch,\ndu nimmst halt Standard-off-the-shelf-Ethernet-Infrastruktur,\nverteilst über deine Router Und hast dann halt irgendwo zentral dicke,\ndicke, dicke Rechner mit ordentlichen Grafikkarten, die dann halt für jedes\nPixel einzeln, deine ganzen tausenden Pixeln halt das ausrechnen und dann halt\ndurch die, durch das Artnet hinmachen und da gibt's dann halt auch Artnet Controller.\nDie jetzt nicht so teuer sind, also es kostet dann schon ein,\nzwei hundert, aber die dann halt auf der einen Seite ein Ethernet Ding haben\nund auf der anderen Seite fallen dann halt zwei, drei, vier,\nfünf Anschlussmöglichkeiten für beliebige Chips an.\nAlso die unterstützen auch die Standards, also die NeoPixel,\naber auch andere, ja ich glaube im professionellen Umfeld werden auch eher die\nSPI Chips benutzt, also die mit zwei Bussen, weil die nochmal.","Aber ist DMX, war doch ein Standard, was noch aus der, ich sag mal,\nder Glühbirn-Technik mit Leuchtfaden kommt, ne?","Du hast dann halt, machst dann halt ganz viel, hast dann super viel RGB-Kanäle,\num das halt alles einzusteuern und DMX ist ja super slim, also das kannst du\nin ein paar wenigen, Ja, hast du wie Midi für Licht.\nJa und das ist halt so organisch gewachsen,\ndas war halt da, das benutzt man und ich meine du kannst halt auch deine,\nmit Artnet deine Steno DMX Leuchten damit steuern,\nist halt ein bisschen Overkill, weil so viel brauchst du nicht,\naber das ist halt sozusagen die Variante, die wenn man etwas hinzuverlässig\nwill und hast halt ne Bühne, Eventtechnik und sowas, dann so machen die das.\nAber die haben, finde ich, halt den großen Nachteil, dass du halt alles zentral\nrechnen musst und was wir halt machen bei uns ist, bei uns wird ein Großteil\nder Rechnung, der Effekte und alles, was wir drauf machen, auch das Mapping,\nwird alles in den ESP's gerechnet, das können die locker ab.\nUnd wir steuern zentral nur, schicken ein paar Kommandos,\nalso wenn die jetzt irgendwelche Farben oder Parameter für die Effekte ändern\nwollen, das heißt, das ganze läuft stand alone, wir müssen nicht,\nweil diese Beleuchtung läuft ja bei uns dauernd, Müssen wir nicht ständig irgendeinen\nstarken Rechner da stehen haben, der das alles in Real-Time rechnet.","Ja, du hast auf einer Bühne natürlich andere Anforderungen. Du willst deinen\nzentralen Rechner haben,\nder einfach funktioniert und alles, was du dran anschließt, soll so weit dumm\nsein, dass du es halt, wenn eins nicht geht, stöpselst ab, stöpselst ein anderes dran und fertig.\nUnd am Ende der Show muss auch alles wieder eingepackt werden.","Ja genau und es gibt auch, also bei LED-Projekten gibt's sehr schnell den Simpsons-Digit-Effekt,\nalso es gibt wirklich schon alles draußen, egal welche Idee man hat,\nes gibt im Internet irgendwelche Leute,\ndie das schon mal gemacht haben oder noch besser, also das ist wirklich,\nalso es gibt viele Ideen,\nviele gute Sachen, es gibt mittlerweile Millionen Videos von Leuten,\ndie sich irgendwo LED-Streifen ins Zimmer hängen und dann reagiert das auf irgendwelche\nBeats und das ist alles, also, Ja, mittelmäßig sozusagen ästhetisch durchdacht, sag ich mal.","Ich hätte mir irgendwann mal überlegt, ob man nicht tatsächlich so ein Fernsehsignal\nnimmt und so wie man das von früher kannte,\nwo in den Wohnzimmern immer je nachdem was gerade im Fernsehen lief,\ndann das Bild heller und dunkler wurde, dass man sowas einfach als Lichtinstallation macht.\nWürde man Fernseh gucken aber es ist halt nur Fake.","Simulierte Fernsehteilnehmer sozusagen.","Ja für den Typen von der GEZ, dass der da mal klingelt und dann aber sehen sie hier ein Fernseher.","Ich habe das Fernsehen gegen ein weißes Licht ausgetauscht und seitdem geht es mir viel besser.","Aber es gibt aber auch echt coole Projekte, also Matt Parker,\nden kennt ihr vielleicht, der hatte… Mit dem Weihnachtsbaum?\nJa genau, das ist halt so… Ja stimmt.\nDer hat halt, also das ist halt auch ein interessantes Produkt,\nes gibt halt diese RGB Dinge auch quasi als Lichterkette, also die kann man\nsich auch einfach kaufen und dann steuern, da kann man auch schöne Sachen mitmachen.","Ich glaube ich hatte das hier sogar schon mal vorgestellt, aber das ist trotzdem\nso grandios, das kann man immer wieder erwähnen. Was ist denn hier das Originalvideo?\nHat der da noch so ein Follow-Up?","Ja, also das war halt ein Beispiel für schönes Mapping im dreidimensionalen Raum,\nalso das war auch so ein bisschen in der Zeit als wir das bei uns gemacht haben,\ndas ist halt ein interessantes Problem was sich dann mit einfachen Mitteln relativ gut lösen lässt.","Man muss aber auch noch mal kurz an der Stelle einfach mal Matt Parker pluggen,\nder einfach ein grandioser Typ ist, also Mathematiker und Mathefreak sagen wir\nes mal so, der halt diesen YouTube Kanal macht, Standup Math und der wirklich\ngenuin lustig ist, also der wirklich,\nDer braucht nur drei Worte sagen, also verschmitzteren Blick kann man auch kaum\ndrauf haben, wirklich tiefgehenden Witz, geile Themen und wie er Mathe irgendwie\nerläutert anhand tausend Sachen ist immer wieder grandios.","Am besten ist ja seine Kettenfontäne, an der immer noch die Leute scheitern,\num zu erklären, warum das funktioniert.\nDa hat er so eine komische, kennst du diese Ketten, mit denen man früher so\nBadewannenstöpsel befestigt hat, diese Kugeln.","Kugeln verbunden mit so Sachen.","Und dann hat er da so ein Glasgefäß, wo so ein ganz langes Ding drin ist und\nnimmt es und zieht es so raus und aus irgendeinem Grund gibt es so einen Bogen.\nAlso weit über dem Glasgefäß macht dieses Ding, das nennt er irgendwie Chain\nFountain und dann gibt es diverse andere YouTube Kanäle, die versuchen dieses\nPhänomen zu erklären und es gibt tausende Theorien.\nGenau, die Kettenfontäne, also das ist super. Ja, weird.\nVon dem ist es.","Ja und auf die Spitze getrieben haben sie es in Shenzhen vor einigen Jahren.\nDas ist auch vielleicht relevant für das Ende der Straße von Blinkenlights,\num es auf die Spitze zu treiben.\nDa kommt übrigens ein Großteil der ganzen LEDs her. Die haben quasi eine ganze\nPhalanx an Hochhäusern mit LEDs außen bestückt und das dann alles gemappt über,\nich schätze mal 20 Hochhäuser abgespielt.\nDas ist sozusagen das Ende der Fahnenstange sozusagen.\nMehr Gehsinn, mehr Fläche ist halt besser.","Oh Gott, als wir mit Blinkenleise angefangen haben, war das so das,\nwo es dann immer drauf hinausläuft.\nJa und größer, schneller, bunter, weiter, mehr Pixel, ganze Oberflächen,\nHäuser, Stadtteile und so weiter. Die Chinesen machen das dann auch noch, because they can.\nAber mal ehrlich, geil ist das nicht.\nMan guckt sich das so an und denkt sich so, ja okay gut, rein technisch gesehen\nist das jetzt ein Achievement.\nAber Lebensgewinn für die Stadt kann ich dabei halt nicht so richtig ablesen.","Das ist einfach so Protzen.","Cool wäre es, wenn man das in China halt dann auch genauso wie Blink lights,\nwenn die Leute dann ihre eigenen Filme drauf zeigen könnten.","Da fehlt dann der Content der Coole.","Da fehlt der coole Content. Und der coole Content kommt halt nur durch Reduktion.\nAlso weil wenn du erstmal mit Pixel und Farben anfängst, dann ist schnell alles\nvorbei und dann gibt's einfach nur noch Video und Porno.\nUnd umso mehr du es reduzierst, umso mehr forderst du die Kreativität heraus.\nDeswegen war das erste Blinkenlights auch immer noch das beste Blinkenlights.\nMit Abstand, weil einfach die Leute sich über jeden einzelnen Pixel Gedanken machen mussten.\nWann kommt der, ist der überhaupt gesetzt und wenn ja wann und wie lange und\nmit wenig Raum viel Effekt zu erzielen ist gar nicht so einfach und da wird\nman halt wirklich kreativ.\nJa wir sitzen auch wieder an so einem Projekt jetzt hier fürs Camp.\nKönnen wir jetzt noch nicht so richtig viel zu erzählen,\nist auf jeden Fall alles in der Entwicklung, sieht schon mal ganz gut aus,\nfunktioniert auf jeden Fall schon, also ist schon was da und wenn das so mehr\nshape and form hat, dann werden wir da auch nochmal so ein bisschen fishing for content machen.\nAber die Zeit ist noch nicht gekommen.\nErstmal liefern denke ich mir.\nSo machen wir mal den Block zu. Wo sind wir denn jetzt? Sind wir am Ende schon?","So ein bisschen oder?","Ich denke schon. Wo ist überhaupt mein Controller?","Vier Stunden rum.","Vier Stunden rum. Ich wollte ja eigentlich noch was zu Starlink erzählen,\naber das können wir ja auch verschieben.\nAh, hier ist er doch. Oder? Was denkt ihr?","Ja, wir müssen ja nicht jedes mal übertreiben.","Ne, ne, das stimmt.\nGut, dann übertreiben wir es mal nicht.\nStarlink-Thema, das machen wir nächstes Mal. Vielleicht mit Clemens hat er sowieso\nnoch einiges dazu zu erzählen und dann werden wir mal wieder unsere weiteren Erfahrungen teilen.\nIst ja eigentlich auch ganz gut jetzt mit dieser Pause, man hat so viel Zeit\nsich mit Sachen zu beschäftigen, jetzt kann man richtig weit ausholen,\nman muss sich nur die Zeit dafür nehmen.\nSo Björn, vielen Dank fürs dabei sein und naja, das war's. Was lachst du Roddy?","Noch eine Minute.","Wo\nist denn überhaupt meine Tröte hier? Ah hier hab ich noch eine.\nJa genau, hier liegt auch noch eine. Willst du auch noch eine haben?\nHier können wir zum Schluss nochmal irgendwie tröten.\nIst es denn auch stereo? Das ist ja die große Frage.\nGut insofern sag ich mal, das war's jetzt hier erstmal mit Freakshow und was haben wir jetzt gehabt?\n265 geht bald wieder weiter. Mal gucken in welchen Abstand wir hinkriegen,\nsieht nach vier Wochen aus, aber vielleicht auch nicht. Mal gucken,\nwir werden es rausfinden. Wir sagen tschüss!"]}