{"v":1,"episode":275,"speakers":["Tim Pritlove","roddi","Dominik Wagner"],"t":[22,71,72,84,87,91,95,108,110,127,144,148,148,152,156,157,158,161,163,163,165,166,169,171,172,176,178,180,187,189,210,211,243,255,258,261,289,320,509,517,530,534,537,539,553,554,633,650,955,967,995,996,1042,1043,1044,1128,1141,1179,1188,1192,1199,1203,1211,1212,1214,1233,1256,1258,1259,1266,1281,1281,1283,1284,1285,1371,1373,1377,1379,1440,1443,1474,1475,1480,1483,1485,1495,1496,1497,1498,1509,1516,1536,1549,1564,1579,1583,1602,1607,1609,1623,1668,1671,1673,1676,1711,1714,1732,1734,1740,1747,1761,1763,1764,1765,1774,1800,1829,1857,1881,1985,2056,2063,2065,2067,2070,2072,2078,2079,2084,2101,2111,2116,2179,2190,2217,2218,2223,2231,2234,2239,2241,2243,2372,2396,2450,2462,2464,2521,2523,2544,2545,2549,2564,2599,2602,2655,2660,2668,2694,2701,2782,2788,2790,2919,2922,2923,2924,3007,3052,3059,3066,3183,3236,3242,3243,3246,3248,3250,3251,3269,3272,3276,3282,3287,3310,3319,3321,3322,3326,3330,3343,3346,3379,3453,3466,3508,3587,3591,3611,3621,3633,3683,3728,3731,3736,3747,3791,3891,3992,4007,4019,4049,4057,4124,4129,4129,4137,4138,4178,4206,4226,4240,4249,4257,4319,4326,4329,4340,4342,4415,4457,4458,4459,4484,4486,4486,4488,4498,4500,4510,4512,4515,4617,4736,4765,4784,4811,4813,4825,4827,4993,5047,5117,5129,5167,5169,5181,5200,5215,5218,5219,5247,5250,5406,5663,5773,5773,5775,5779,5782,5784,5788,5790,5793,5803,5807,5867,6002,6004,6108,6157,6218,6352,6366,6376,6413,6414,6430,6482,6502,6535,6599,6608,6718,6763,6765,6765,6767,6768,6769,6797,6817,6953,6954,6959,6960,6961,6965,6967,6979,6980,6986,6998,7044,7052,7056,7059,7062,7068,7070,7075,7104,7115,7156,7161,7201,7204,7207,7209,7211,7225,7230,7333,7409,7440,7446,7448,7463,7475,7483,7485,7486,7488,7490,7496,7504,7534,7538,7557,7560,7565,7569,7694,7702,7710,7721,7728,7796,7848,7929,7944,7945,7950,7954,7991,7992,7993,7994,8135,8195,8196,8236,8308,8386,8402,8477,8483,8756,8759,8768,8803,8853,8936,8948,8952,8954,8966,9050,9052,9054,9058,9061,9074,9118,9217,9337,9345,9422,9439,9443,9446,9453,9457,9572,9577,9578,9587,9591,9712,9713,9716,9719,9719,9720,9752,9765,9851,9854,9859,9866,9867,9875,9880,9880,9881,9885,9909,9911,9924,9979,10003,10141,10145,10182,10190,10191,10239,10307,10313,10316,10319,10323,10385,10418,10421,10422,10424,10444,10458,10467,10486,10500,10563,10570,10574,10585,10643,10648,10815,10835,10839,10841,10849,10902,10941,10972,10975,11245,11248,11252,11254,11256,11265,11266,11267,11272,11275,11346,11363,11369,11375,11566,11568,11580,11583,11587,11634,11643,11651,11708,11779,11782,11790,11796,11834,11838,11880,11882,11929,11947,11972,11973,11993,12029,12094,12114,12117,12147,12152,12234,12238,12240,12242,12399,12439,12463,12465,12476,12477,12484,12493,12510,12515,12519,12592,12599,12604,12673,12721,12729,12753,12755,12757,12762,12767,12793,12801,12807,12807,12817,12821,12822,12835,12841,12843,12845,12852,12869,12907,12912,12914,12915,12924,12927,12939,13015,13016,13019,13026,13039,13079,13099,13111,13115,13123,13138,13168,13176,13183,13200,13210,13217,13233,13234,13250,13257,13280,13287,13288,13295,13296,13297,13304,13307,13318,13319,13321,13361,13364,13605,13607,13609,13610,13627,13670,13693,13734,13739,13743,13750,13917,13935,13995,13998,14001,14022,14023,14039,14044,14058,14061,14064,14084,14088],"s":[0,1,0,2,0,2,0,1,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,1,0,1,0,1,0,1,0,1,0,2,0,2,0,1,0,1,0,1,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,1,0,2,0,1,0,2,1,2,1,2,0,2,0,1,2,1,0,1,2,1,0,2,0,2,0,1,2,0,2,1,2,1,2,1,2,0,1,2,1,0,2,0,2,0,2,0,2,0,1,0,1,0,1,2,1,2,1,0,1,2,0,2,0,2,1,2,0,1,2,1,0,1,2,1,0,2,1,2,1,0,2,1,0,1,0,2,0,2,1,2,0,2,0,2,1,0,2,1,2,0,2,0,1,2,1,0,2,1,0,1,2,1,2,0,2,0,2,0,2,0,2,1,2,0,2,0,2,1,2,1,2,0,2,0,2,0,1,2,0,2,0,2,0,1,0,2,1,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,1,2,0,2,0,2,0,2,0,2,0,1,0,1,0,2,0,2,0,2,1,0,1,2,1,2,1,2,0,2,0,2,0,2,0,2,0,1,0,2,0,2,0,1,2,0,2,0,2,0,2,0,2,0,1,0,2,0,2,0,2,0,2,0,2,0,2,0,1,2,0,2,0,2,0,1,2,0,1,2,0,2,0,2,0,2,0,1,0,2,1,0,1,2,1,0,1,0,2,0,1,0,1,0,1,0,1,0,2,0,1,0,2,0,2,0,2,0,2,0,2,0,2,0,2,1,0,1,0,2,0,2,0,2,0,1,0,1,2,0,2,1,2,1,0,2,0,1,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,0,2,1,2,0,1,0,2,0,2,1,2,1,2,0,1,2,0,1,0,1,0,2,0,1,0,1,0,2,1,2,1,2,1,0,2,0,1,0,1,2,1,2,1,0,2,0,2,0,1,2,1,2,0,2,0,1,0,2,0,2,0,1,0,2,0,2,0,2,0,2,1,2,1,2,0,2,1,2,1,2,1,2,1,2,0,1,0,2,0,1,0,1,0,2,1,0,1,0,1,2,1,0,1,0,1,0,2,1,2,1,0,1,0,1,2,0,1,0,2,0,2,1,0,1,0,1,0,2,0,2,0,2,0,1,0,2,0,2,0,2,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,2,0,2,0,2,0,2,1,2,0,2,0,2,1,0,2,0,2,0,2,0,2,0,2,0,1,0,1,0,1,2,0,2,0],"x":["Hallo und herzlich willkommen, hier ist die Freakshow und zwar die 275.\nFreakshow. Das ist ganz schön viel eigentlich, ne? Also, was man so überlegt.\nGibt natürlich auch Leute, die haben schon tausende von Podcastsendungen,\naber die sind ja alle nicht so lang.\nUnd irgendjemand hat ausgerechnet, dass wir mit allen Freakshows bis zu 274\ninsgesamt 998,5 Stunden gesendet haben.\nIn einer anderthalb Stunde, um 21.30 Uhr, haben wir 1000 Stunden voll und ich\nhabe keinen Shampoos kaltgestellt. So sieht das aus.\nAlso Leute, so gut vorbereitet sind wir hier.\nHallo, ich bin's Tim und heute haben wir eine kleine Runde. Roddy ist natürlich da. Hallo Roddy.","Ja, guten Abend.","Ralf ist unpässlich, kann man sagen, also kann ich, aber dafür haben wir Dom\ndabei, live zugeschaltet über das Internet.","Guten Abend. In Bild und Ton hier.","Als wärst du ein Teil dieser Runde.","Ralf aus Berlin, über München, außerhalb.","Und wir haben alles aufgefahren und ich bin ein bisschen stolz,\ndass gerade alles so richtig geil funktioniert.\nJetzt haben wir so alle Features, die so in der letzten Zeit immer in der Diskussion waren.","Noch ist die Sendung nicht zu Ende.","Und noch hat die noch nicht richtig angefangen, weil bei den letzten Malen,\ndie hat ja auch immer so gestartet und dann ist irgendeine Technik mit mir in die Hose gegangen.\nDas Video ist ausgefallen, der Ton war weg, sonst irgendwas, das geht gleich weiter.\nKnock on wood, dieses Mal wird alles Suppi.","Das ist richtig, ja genau, jetzt gucke ich gerade mal, steht da Ton ein oder aus?\nJetzt ist das richtig gut. Gut, dass du das erwähnt hast, ich habe gleich noch ein Setting gemacht.\nJa, nee, aber das stimmt doch nicht.","Du hast jetzt gleich ein Setting gemacht und ich höre dich nicht mehr gescheit. Was?","Du hörst mich jetzt nicht mehr?","Du hast mir jetzt ein Setting angemacht, jetzt bist du wie aus der Dose. Ach echt?","Aber es ist doch genau genau das Setting, was ich einschalte, damit das nicht so ist.","Achso.","Warte mal, jetzt bin ich aber ein bisschen...","Jetzt bist du wieder besser.","Jetzt bin ich besser?","Nee.","Jetzt bin ich schlechter?","Ja.","Und jetzt bin ich besser? Wenn ich es ausmache, ist es...","Jetzt habe ich den besseren Ton.","Das ist aber jetzt genau andersrum.","Aber es war so ein bisschen so ein Übergang. Es war kein digitales Feld.","Keine digitale Welt.","Du hast den Knopf gedrückt und dann wurde es langsam wieder besser.","Ja, ist so schön. ich lasse das jetzt so. Aber dafür gibt es Ton auf dem Klo.","Das hilft mir wenig.","Das hilft dir jetzt wenig, aber fühle einfach mit uns.\nAlso wir können jetzt hier auch aufs Klo gehen und nach wie vor der Sendung lauschen.\nDas war immer so die Disruption schlechthin, dass man bei solchen Toilet Breaks\neinfach den Faden verloren hat.\nDas könnte der Grund sein, warum hier manchmal einfach alles so hin und her\nund kreuz und quer geht und so.","Daran liegt es.","Klare Analyse.\nMal so.","Nö, es war super. Hat gut geklappt und der gute Ulf war echt viel witziger, als ich erwartet hatte.\nDer hatte so einen schönen, trockenen Humor, also das fand ich wirklich gut.","Ja, ich war auch ganz zufrieden mit der Dynamik.","Also du wirst das ja als Podcast-Folge auch raushauen, ne?","Ja, na klar. Ist alles aufgenommen worden, hat funktioniert und ja,\nmuss nochmal in den Schnitt und dann wird das vermutlich sogar noch diese Woche\ndoch mit Sicherheit morgen veröffentlicht werden,\nsollte sich da nicht noch irgendwas in den Weg stellen.\nJa, aber das ist gut und ich will auch ohnehin mehr on stage sein, jetzt in diesem Jahr.\nDa wird noch so einiges passieren. Mal gucken, ob wir das auch mit der Freakshow hinbekommen.","Also, wenn die Sendung rauskommt, da Raumzeit mit dem guten Ulf, dann hört ihr euch an.\nDas ist echt, da kann man mal eine Hörempfehlung aussprechen.\nDas hat sehr viel Spaß gemacht.\nIhr habt zwar dann leider nicht das Planetariumsbild dabei, das,\nfand ich war dieses Mal aber auch ein bisschen gedämpfter als die erste Variante.\nDu hattest da ja schon mal was gemacht und da hatten die deutlich mehr Zip Zap gemacht.","Ja, da war mehr Zip Zap. Das hat zwei Gründe. Der erste ist,\nes gab da irgendeinen internen Abstimmungsfehler, sodass eine andere Person\ndavon ausging, das zu fahren.\nUnd außerdem hat halt das Thema nicht ganz so viel Material hergegeben wie jetzt\ndiese Bodenteleskope, weil die ESO,\ndieses European Southern Observatory, was diese Teleskope macht, das hat halt...\nDas hat halt schon sehr viel von diesem 180 Grad Videokram geschossen für Planetarien.\nUnd darauf konnte man dann halt zugreifen und dementsprechend gab es halt viel.\nJa, genau. Aber das ist tatsächlich jetzt ein Punkt, auf den ich jetzt nochmal kommen wollte.\nUnd zwar, ich habe das auch hier schon mal, glaube ich, schon mal angesprochen.\nAber jetzt gerade wegen dieser Live-Geschichte und speziell auch Raumzeit,\naber im Prinzip wäre es auch etwas für die Freakshow, was Podcast und Live-Podcast\nauf eine interessante Weise ergänzen könnte,\nwo es aber ein spezifisches Problem gibt.\nUnd das ist eben visuelle Begleitung.\nAlso ich mache ja keine Videopodcasts und mache kein Gesicht in die Fresse halten,\nYouTube-Channel und dieser ganze Selfie-TikTok-Kram und so weiter,\ndafür bin ich zu alt und das war einfach noch nie mein Ding.\nIch bin dafür nicht zu alt, natürlich bin ich völlig geeignet dafür,\naber ich will halt, also wenn man sozusagen Leuten einen weiteren.\nKommunikationskanal anbietet, den sie dann konsumieren sollen und dann einen\nweiteren Sinn quasi in Beschlag nimmt, so ein Ressourcen-Acquiring,\nbetreibt, dann muss da auch Mehrwert kommen.\nDas hasse ich halt immer so an diesen, mach mal heute YouTube an,\nso, dann ist erstmal bla bla bla, Quatsch Quatsch Quatsch, ich rede jetzt mal über irgendwas,\nwährenddessen schaut ihr doch bitte Bitte diese 1.000.000 3-Sekunden-Stock-Videoclips,\ndie ich in meinem Standard-Abo mit drin habe und die ich einfach mit Dreck und\nDrop aus irgendeinem Archiv raussuche und meine AI,\nda muss ich nur drei Suchworte eingeben und dann habe ich schon irgendwas.\nUnd ich sehe immer diese selbe düsselige Stockfoto-Imagerie,\ndie überhaupt nichts damit zu tun hat.\nDas ist im Prinzip so die kolossale Fortführung von so Tagesschau berichtet\nüber Arbeitsamtzahlen.\nJeden Monat kommen so die Zahlen vom Arbeitsamt raus und was sehen wir?\nDas Arbeitsamt in Recklinghausen schwenkt irgendwie Leute, die irgendwie arbeiten,\nLeute, die nicht arbeiten, Leute, die irgendwo in einer Warteschlange stehen,\nimmer dieselbe Footage, immer das gleiche, weil es gibt visuell nichts zu berichten.\nEs ist einfach nichts da, kein Fleisch.","Es gäbe Fleisch, aber das machen die da nicht ran.\nEin paar schöne Grafiken, ein paar Kurven könnte man bei dem Thema durchaus bringen.","Ja, das kommt auch irgendwann, aber das hält halt nur für fünf Sekunden.\nDu kannst nicht 30 Sekunden lang diesen ganzen Bericht machen,\nwie sich das jetzt entwickelt hat, sondern du musst immer irgendwas zeigen.\nAlso zeigst du immer das Gleiche.","Und jetzt ist es spannend und du hast eine Idee oder was? Du machst mich ja ganz kirre.","Ich habe immer Ideen. Das ist das für die Frage.","Eine Umsetzung, meine ich halt. Ideen sind...","Naja, also im Falle von Raumzeit on Stage, das ist jetzt das dritte Mal,\ndass das stattgefunden hat.\nUnd bei all drei Malen gab es diese visuelle Begleitung. Also zweimal habe ich\nes in Berlin gemacht, einmal habe ich es in Darmstadt gemacht.","Ah, okay.","Und das waren dann Gott sei Dank auch mal ganz mehr oder weniger dankbare Themen.\nAber das eigentliche Problem ist, wenn ich jetzt sozusagen losziehe und sage,\nich suche mir jetzt irgendwo eine Bühne und mache Raumzeit live,\nwas ich durchaus vorhabe auch, dann möchte ich gerne diese visuelle Begleitung\nhaben, weil das ist einfach für Live-Teilnehmer, Du hast es ja schon angesprochen, das ist ganz nett.\nAlso du redest über das Gymnasium in Greiz, wo er aufgezogen ist und dann hast du davon ein Foto.\nUnd dann redest du über das Max-Planck-Institut in Stuttgart und dann hast du\nda ein Bild und dann siehst du den Campus und bla bla bla.\nUnd dann redest du über das und dieses und diese Rakete und dieses Modul und\ndiese Raumstation und dann hast du halt einfach Imagery.\nDas ist natürlich jetzt im Planetarium eine besondere Herausforderung,\nalso in dem Planetarium ist es jetzt gerade noch eine besondere Herausforderung,\nweil sie parallel derzeit die 180 Grad Projektionen und dann noch zusätzlich Beamer haben.\nDas heißt, der ganze 16 zu 9 Web-Content kam sozusagen von separaten Beamern.\nDas ist nicht eine Software, in der das so eingeblendet wird.\nEs gibt derzeit noch keine Möglichkeit, sozusagen non-planetary Content einfach\nso in dieselbe Produktion reinzukriegen.\nDas ist aber etwas, woran die gerade arbeiten. Also das ist sozusagen das Problem.","Okay, ich hatte mich schon gewundert, weil es nie 100% opak war,\nsondern immer der Sternenhimmel durchschien.\nGenau. Aber dass das jetzt so ein echtes mechanisches Problem war,\ndas habe ich nicht mitbekommen.\nAlso das hat man nicht gesehen, sagen wir mal so.","Ja, das ist auch gut so, dass man das nicht gesehen hat. Das ist ja auch nicht\nso wichtig. Aber am Ende war es halt ein Mehrwert. Und jetzt werde ich aber nicht,\nImmer in Planetarien gehen, sondern halt auch mal einfach einen Ort suchen,\nwo nur so eine normale 2D-Leinwand ist. Das reicht auch aus.\nDas hatte ich damals, als ich das in Darmstadt gemacht habe, auch.\nJetzt die Frage, wie bespielst du das?\nUnd das Besondere daran ist ja, das ist ja jetzt kein fertig geschnittenes Video,\ndas findet ja live statt.\nUnd du weißt zwar in etwa, auf welche Themen du eingehst, aber der Witz ist\nja, dass man mit der visuellen Begleitung dem Inhalt dynamisch folgt.\nDas heißt, man macht ein neues Themenfeld auf, so bla bla bla und jetzt reden\nwir mal über Science Fiction und dann, weißt du, kommt Douglas Adams ins Spiel\nund das stand vorher auf keiner Liste und jetzt möchte ich halt in der Lage sein,\ndem schnell zu folgen, ohne dass jetzt Leute einem dabei zuschauen,\nwie man auf dem Webbrowser bei Google irgendwelche Suchbegriffe eingibt und\nirgendwelche Bilder erklickt.\nDas ist das, was ich auf keinen Fall möchte.\nWas ich also suche, ist eine Software, die eigentlich so ein bisschen funktioniert,\nwie so VJ-Software funktioniert. funktioniert.\nWeil VJ-Software ist ja im Prinzip genau das.\nDu hast dein Material, aus dem du so auswählst, Still Images,\nMoving Images und dann fügst du die mehr oder weniger live in so eine Playlist ein.\nAlso entweder du hast es schon vorher so gebaut, wie das so abläuft oder du\nziehst da halt irgendwas rein.\nIch muss zugeben, ich habe nicht viel Erfahrung mit VJ-Software.\nIm Wesentlichen habe ich eigentlich nur anderen Leuten dabei zugeschaut, wie sie die benutzen.\nUnd natürlich Natürlich ist jetzt der Funktionsumfang von klassischer VJing-Software\nfür meine Zwecke auch völlig over the top, weil ich brauche jetzt nicht 30 Millionen\nFilter und Rotationen und so weiter,\naber sagen wir mal so eine Software, die folgendes macht, die im Wesentlichen,\nin irgendeiner Form so eine Input-Queue hat, wo man so Sachen reinwerfen kann,\nsodass man zum Beispiel in einem Team mit zwei Leuten arbeiten kann.\nDie eine Person reagiert quasi auf den Inhalt, folgt dem Inhalt,\nmerkt so, ah, okay, Douglas Adams, wir müssen jetzt was mit Douglas Adams,\nich muss mal ein Foto von Douglas Adams und dann habe ich ein Foto von Douglas\nAdams und dann schmeiße ich das quasi für die VJ-ende Person in so eine Art Inbox.\nShared Folder, was auch immer, API, keine Ahnung, Irgendwas,\nWebseite, Programm, Command Line, mir egal.\nAlso irgendwie werfe ich das da rein, sodass die Person die Visuals steuert,\nder das sozusagen dann so als Input-Element aufpoppt und weiß, aha.\nDas muss ich jetzt in irgendeiner Form verwenden.\nAber ich kann dann in dem Moment auch schnell durch ein paar Tastenkontrollen\nso Sachen machen wie, was weiß ich, dass man das irgendwie kurz maskiert,\ndass man da irgendwie eine Transition hat, wie das reinkommt.\nSo, ja, das ist nicht so plopp jetzt dieses Bild, next slide,\nsondern dass man, was auch immer jetzt gerade angezeigt wird, sagt, okay,\njetzt kommt hier ein Foto und dass die Software es einem irgendwie einfach macht,\nmit so Aspektratios dann kreativ umzugehen, damit das nicht alles zu bekloppt\naussieht oder dass man da was weiß ich, einen Ken Burns Effekt macht oder das\nreinrauscht oder was auch immer.\nAlso in irgendeiner Form eine gute Kontrolle über die visuelle Präsentation,\naber halt als Output immer nur ein Screen, wo jetzt keinerlei User Interface auftaucht.\nAlso du arbeitest quasi an dem Rechner mit einem Hauptbildschirm,\nda hast du sozusagen die Kontrolle und dein Output ist halt dann letzten Endes\nder Beamer dieser Veranstaltung, wo das dann eben für alle Teilnehmer zu sehen ist.\nAber du kannst, du musst dann, du kannst also das trennen, dieses Recherchieren\nund den Zugriff auf diese Fotowelten, Datenbanken, was auch immer vorbereitetes\nZeug oder so oder das Web und dann.\nAlso elegant und klar das dann sozusagen in diese Input-Queue geben,\nsodass die Software dann auch so eingestellt werden kann, dass, was weiß ich,\nwenn jetzt gerade die Playlist oder die Queue so weit abgearbeitet ist,\nman zeigt halt sozusagen jetzt gerade das Letzte an, auch wenn man sich vielleicht\nnoch fünf Bilder mal vorbereitet hat und wenn man dann die durch ist und kommt\nwas rein, dann schaltet es auch automatisch darauf um, also irgendwie sowas.\nDas ist eine Software, die ich suche und ich habe so ein bisschen die Vermutung,\nes könnte etwas geben im VJ-Bereich, was sich vielleicht anpassen lässt,\nalso indem man im Wesentlichen seine Features, ganz viele Features erstmal ausschaltet,\ndamit es irgendwie einfach zu benutzen ist, um dann sowas zu machen.\nUnd wenn es sowas gäbe, dann wäre schon, das wäre schon die halbe Miete,\nweil dann könnte man sich sozusagen so ein Content-Jockey-Podcast-VJ-Team aufbauen,\nwas das dann auf solchen Veranstaltungen machen kann.","Ich habe das Gefühl, du versuchst gerade eine neue Software-Kategorie loszutreten.\nAber die Ideen sind eigentlich alle offensichtlich, wenn man das Problem verstanden hat.","Also ich denke grundsätzlich, es gibt schon so Software auch.\nInteressanterweise ist das, was aus dem Produkt, das ich damals zusammen mit\nBoing's gemacht habe, Boing's TV, ist so eine Live-Mischer-Software auch.\nDas kann sowas. Also das ist halt relativ flexibel, heißt Mimo Live inzwischen.\nMal gucken, ob das jetzt genau den Anwendungsfall erfüllt, weiß ich nicht mehr.\nIch bin ja da schon lange raus, aber da habe ich mich ja mal mitgeschrieben. Das gibt es noch, ja.","Mimo Live.","Mimo Live heißt das jetzt, Mimo Live 6 oder so, keine Ahnung,\ndie sind auch im Einsatz für Live-Fernsehschnitt-Geschichten,\nalso es ist halt mehr so ein Broadcast-Studio in der Box,\naber lower certs und Grafiken einblenden und das Ganze kann man und man kann\nDinge vorbereiten vor allem.\nAlso man könnte damals bei BoingTV schon Plugins selber machen über Quartz Composer\nund ein bisschen JavaScript und Co., um sich dann eben ein bisschen so eine\nArt von Animation zu bauen, die man so gerne braucht.\nAlso tendenziell könnte das schon was sein, was hilft, wenn das noch gut ist.\nIch habe es schon lange nicht mehr angeguckt.\nAber so Software grundsätzlich gibt es schon auch. Es ist ja mehr so gefühlt\nso ein bisschen mehr so ein Live-Keynote, was du gerne hättest, oder?","Ja.","Live-Modus für Kino.","Genau, also es könnte auch sein, dass man in dieser Präsentationssoftware-Kategorie\nvielleicht mehr Erfolg hat.\nAber Broadcast ist natürlich, hast du natürlich recht, hat ja im Prinzip genau dieselben Aspekte.\nAuch gerade dann mit so Überblendungen oder dass man vielleicht so eine bestimmte\nMaske hat, dass unten immer irgendwie da noch ein Logo steht und so eine Sachen. Ja, tatsächlich.\nAber was eigentlich dahinter steht, ist eben auch so eine Art und Weise,\nwie man eben Podcasts visualisiert und ähnlichen Bedarf hätten,\nkönnten wir ja hier jetzt auch haben.\nAlso wir haben ja immer diesen Konflikt, wir machen eigentlich jetzt ein Produkt,\nwas für Audiokonsum gedacht ist, wir wollen halt irgendwie über alles reden\nund manchmal ist es schwierig, dann werden wir heute auch wieder so einen Tag haben,\nweil wir wollen halt über die Vision Pro ganz viel reden und wir versuchen die\nganze Zeit irgendwas zu beschreiben und dann tendiert man immer schnell dazu,\nirgendwie auf dem Bildschirm zu zeigen und sagen, wie man hier sieht und das\nfunktioniert natürlich nicht.\nAndererseits wäre es aber ganz cool, zumindest auch für so ein Live-Publikum,\nvielleicht eben so ein Screen tatsächlich mit zu maintainen.\nAlso dass man so ein Live-Modul hat, wo dann quasi immer der Content ist,\nder gezeigt wird, aber man eben dafür auch noch einen Video-Jockey hat,\nso ein Content, so ein Podcast-Video-Jockey.\nUnd das könnte ja … Das ist halt so ein bisschen das Punkt.","Den brauchst du halt extra, weil das kann ja keiner von uns parallel machen\ngroßartig. Oder wenn wir da alle mitmischen kollaborativ, wäre es auch furchtbar.\nRichtig. Da ist ja der Slack-Channel schon so das, was es gibt.","Genau, das ist nämlich schon sehr schwer, einen Chat-Channel zu bespielen.\nAber wenn man das sozusagen externisiert und sagt, man hat jetzt sozusagen so\nein Content-Team, was dann live zuhört und das dann sozusagen auch für live Podcasts macht,\nkann man ja im Prinzip für beliebige Podcasts machen und das so halbwegs gewissenhaft\nmacht, dann könnte was Interessantes bei rauskommen.\nUnd dann hätte man auch ein Material, wo es sinnvoll wäre, so eine Podcast-Aufzeichnung\nals Video zu veröffentlichen.\nAlso natürlich hast du im Wesentlichen den Ton, aber du hast dann quasi die\nVideospur so als optionale Begleitspur, die du dir einblenden kannst,\nwenn du möchtest, aber du musst es halt nicht.","Könnte ja auch ein motivierter Hörer bei der Freakshow machen,\nweil die Links und so weiter sind ja alles da, wenn jemand schnell ist und einen\nStream parallel macht und Zweitverwertung.","Ja, aber dazu müsste es halt die Software geben. Vielleicht.","Oder die sind ja vielleicht so drauf. Man weiß es ja nicht. Manche Leute machen\nsowas in ihrer Freizeit einfach und dann können die.","Machen im Sinne von sowas programmieren oder machen im Sinne von sowas durch?","Irgendwie benutzen. Irgendwie ihren Twitch-Channel bespielen können,\nweil sie live bespielen können, schon mit irgendeinem Setup und die würden das\nmal ausprobieren wollen.","Ja klar, aber trotzdem brauchst du ja immer noch diesen Input-Kanal.","So Kamerakind für Freakshow-Werden.","Wenn ich jetzt hier einen Screenshot habe, über den ich reden möchte und den\nich sozusagen da anzeigen will, dann muss ich den ja hier während der Sendung\nmit Drag & Drop oder so irgendwie in diese Queue kriegen.\nAlso diese Queue ist schon, sagen wir mal, der entscheidende Faktor.\nDas ist jetzt nicht ein Nebenaspekt oder so, sondern das ist schon so das, was zählt.","Ja, wobei der Slack-Chat ja schon diese Queue ist für uns eigentlich,\nweil da meistens Links und Bilder und so weiter sind.\nJa, aber Rohmaterial hätte man da genug, denn da kann man nicht einfach abbilden,\naber wenn man jemand hätte, der praktisch den Content,\nden wir da reindonnern, aufbereitet in einem 16 zu 9 oder iPhone-Format einfach\nschönen, also wenn jemand das mal machen möchte, fände ich interessantes Experiment.","Ja, aber Er wüsste dann auch.","Welche Tools man braucht.","Er unterschätzt nicht die Chaotik und Dynamik eines Live-Chat-Channels.","Leute, die Twitch streamen und so weiter, wir haben bestimmt doch Hörer, die sowas auch machen.\nDie haben da so ein gewisses Potenzial an Wissen, wie man denn das visuell da\nmacht, weil du brauchst ja schon noch so ein bisschen Engagement und ein bisschen Witz dabei.","Klar, natürlich.","Auch Style.","Auch ganz wichtig.","Auch Style.","Naja, aber es muss dann trotzdem natürlich ein,\nwie soll ich sagen, ein eigener Stil dabei sichtbar werden.\nUnd nicht einfach nur so ein hier ist das nächste Bild, hier ist das nächste\nBild, hier ist ein Webbrowser.\nDas ist langweilig. Es muss auch und deswegen rede ich vielleicht auch von VJing,\nweil ein VJ ist ja nun auch nicht einfach nur so ein Knopfdrücker,\nsondern VJing bedeutet ja auch, da so eine kreative Note reinzubringen und einen Stil zu haben.\nAlso eine Handschrift, das ist vielleicht das, was ich suche, das Wort.\nGenau, also ich wollte das auch nur mal so in den Raum stellen und bin für alle\nTipps dankbar und ich würde mir auf jeden Fall mal dieses Mimo anschauen,\ndas vielleicht auch eine Option ist, aber alles steht und fällt mit diesem Channel-Ding.\nAlso es muss sozusagen von mehreren Leuten also mindestens zwei Personen,\nzwei Plus-Personen gestaltet werden können und dann wird es erst spannend.\nJa.\nDann, wir haben uns ja hier über Staubsaugerroboter unterhalten.","Ja.","Gestern ist bei meinem die Cloud ausgefallen.","Okay.","Ja, womit das Ding zwar weiterhin seinen bisher programmierten Zeitplan verfolgt\nhat, aber man konnte keinen Einfluss mehr drauf nehmen, wann dieser Zeitplan\nist oder stoppen oder sonst irgendwas.\nEinfach nur so, nein, einmal am Tag wird jetzt geputzt. Und das war's dann.\nIch hab ja so ein Nito. Und ein Nito ist vor einem Jahr oder zwei von Vorwerk gekauft worden.\nUnd Vorwerk hat jetzt aber sozusagen Nito gedroppt.\nAlso die Nito-Webseite sagt so, wir sind irgendwie außer Business.\nUnd du kannst aber hier noch auf den Support-Button klicken und die Cloud läuft\nhalt noch, aber das war es dann auch und dann hast du noch irgendwie so die\nganzen Hilfe-Seiten, die auch nicht so richtig helfen.\nJa, und ein bisschen unklar, was sie damit vorhaben, aber das scheint nicht\nso ein geiler Move geworden zu sein.\nIch glaube, Vorwerk hat noch unter eigener Marke auch noch solche Staubsauger-Roboter am Start.","Ja, schon immer gehabt eigentlich.","Ja, weiß aber auch nicht, wie sie damit vorgehen, aber die eigentliche Frage,\ndie damit natürlich wieder aufkommt, so ist,\nokay, okay, was mache ich mit meinem Produkt, wenn die Cloud abgeschaltet wird,\nweil die Firma ja dann sozusagen gar kein Geld mehr damit verdient,\nsondern es nur noch Kosten hat und die ganze Zeit irgendwelche Pfennigfuchser\nin der Vorstandsentage halt darüber entscheiden müssen,\nwie lange sie da sozusagen noch einfach Geld reinfanneln, damit sie nicht so\nschlecht dastehen, obwohl es ihnen eigentlich irgendwie auch egal ist.\nSo haben die Leute doch einen neuen Sturmsauger gekauft.","Eben, eben, eben.","Ja, hurra Cloud.","Ich habe einen Roborock, der funktioniert ganz gut.","Deren Cloud ist noch online.","Ja, auch das. Ich weiß aber nicht, wie viel Cloud die überhaupt braucht,\nwirklich. Also für Updates und so schon, aber ansonsten ist der eigentlich,\nder ist, glaube ich, autark.\nIch glaube nicht, dass der die Cloud braucht für irgendwas.","Man kann die benutzen.","Um was zu machen.","Das glaubst du nicht wirklich, oder?","Naja, er hat obendrauf halt den Jetzt-Bitte-Staubsaugen-Button und ich glaube,\nwenn die Cloud ausfällt, funktioniert außer diesem Button dann auch nicht mehr mehr viel.","Die Cloud ist ja, die App, spricht die mit dem auch mit der Cloud?\nIch dachte, die spricht mit meinem lokalen Netz.","Nee, tut sie nicht. Spricht über die Cloud mit dem Staubsauger und der zeigt\ndir dann, wo er gefahren ist und dieses und jenes und dann kannst du deine Pläne\nbearbeiten und so weiter und ich glaube, wenn die Cloud ausfällt,\ndann kannst du halt noch den Homebutton drücken und den jetzt Staubsaugen-Button\nund dann war es das wahrscheinlich.","Tja, es müsste sozusagen so eine\nkommerzielle Cloud geben, wo man alle Staubsauger drüber fahren könnte.\nWenn eine Firma Out of Business gibt, dann übergibt sie das sozusagen einfach da an die Staub-Cloud.","Es gibt für Roborock, gibt es so eine Open Source Cloud,\nwo man dann mit irgendwelchen VPN oder DNS-Hacks irgendwie den Zugriff auf die\nCloud, auf die eigene Open Source Cloud umbiegen kann, aber das ist natürlich….","Aber da merkt man wieder, wie naiv ich bin. Ich gehe einfach davon aus,\nwenn die hier im lokalen Netz einen Web-Server laufen haben und die sind ein\nComputer, weil die haben doch eh Strom.\nWieso brauchen die eine Cloud, um irgendwie den Raum festzufahren?\nDie brauchen doch keine Cloud.","Keine Ahnung, weil man heutzutage halt alles in der Cloud macht,\nwenn man in der Cloud ist.","Naja, für den ganzen AI-Kram mit irgendwie Bilderkennung, trainieren,\nverbessern, hochladen und so weiter, das ist dann alles nicht so super optional.\nDann hast du diese ganze Zeitplanung von außen mit von aktivieren von außen.","Das kann ja optional sein. Diese ganze Zeitplanung ist ja optional.","Könnte.","Also kenn mal deine Räume und speichere die Bilder von den Gegenständen,\ndie du umfahren hast, weil du denkst, die sind Hundekacker.\nDas geht doch auch lokal auf dem Gerät. Dafür ist es doch so ein riesen Robot Dingsbums.","Ich bin ganz bei dir. Chat sagt auch, Roborock funzt rudimentär ohne Cloud,\ndas ist ja auch schön und das ich muss auch sagen, ich bin dann hier so ein\nbisschen zusammengezuckt und\ndachte mir so, ich wollte die eigentlich doch noch ein, zwei Jahre nutzen,\nund dann habe ich halt aber auch schon Pläne gemacht, okay, was machst du denn\njetzt, wenn sozusagen jetzt deine,\ndein Staubsauger in die ewigen Cloud-Gründe verschwindet,\nund ja, dann ist es mir natürlich hier deine Story mit deinem Roborock eingefallen\nund ich muss auch zugeben, ich habe mir die,\nDiesen S8, diesen Nachfolger davon angeschaut, der sieht schon wirklich sehr\nschick aus. Also das wäre eigentlich genau das Richtige.","Er wischt ordentlich, er saugt ordentlich.","Hast du auch einen V7?","Saugt, bläst, er hat einen V8.","Also ich habe irgendwie das Maximallmodell 7 so mit Waschen und Ding-Doc.\nDas ist eine gute Grundreinigung schon mal, wenn man es laufen lassen kann.\nBei uns ist es eher so, dass die Lego-Obsession des Nachwuchses etwas dafür\nsorgt, dass wir den nicht einfach so rund die Uhr\nfahren lassen wollen, weil ansonsten haben wir Ligo-Teile vermisst,\nKleinteile, die zwar da in den Filter landen und so, wäre schon okay,\naber also die Situation, dass der immer saugen kann, weil der Boden frei genug\nist und nicht voller Kinderspielzeug, ist halt selten.\nDeswegen ist er seltener im Einsatz, als man gerne hätte.","Das ist aber, glaube ich, herstellerunabhängig, das Problem.","Genau, das hat nichts mit dem Ding zu tun. Wenn es fährt und wenn man es regelmäßig\ngenug Boden Klarheit schaffen, dann war es auf alle Fälle eine super Bereicherung,\nweil er halt einfach so, wenn der einmal am Tag fährt, ist halt einfach mal\neine ganz andere Raumsituation gefühlt.\nDas ist schon angenehmer. Auch wenn er saulaut ist natürlich.","Ich finde den nicht laut. Also klar, auf Max.","Wenn der wieder ankommt. Achso, ja, wenn er sich wieder entleert.","Die Basisstation saugt den ja wieder leer und die macht das doch mit Werbe.","Das hat sie bei unserem Teppich auch nicht geschafft, weil unser Teppich macht zu sehr Knäuel.\nAlso da muss man auch mal nachhelfen. Aber ich meine, das ist ein bisschen nachhelfen.\nDas ist trotzdem eine Verbesserung.\nIch mag meinen Raubsauger-Roboter.","Raubsauger.","Raubsauger, ja.","Raubsauger.","Ja, wenn zu viel Lego rumliegt, dann kassiert mir das ein. Der Raubsauger.","Naja.\nSo. So, ich war unterwegs diese Woche und das Wochenende,\ndas letzte Wochenende und habe die Gelegenheit ergriffen, mir dann auch mal\nso eine Vision Pro ins Gesicht zu halten.\nUnd du Dom, hast du das auch getan? getan.","Genau, ich habe die Gelegenheit ergriffen, mir von einem Bekannten,\nder hin und her sich bewegt zwischen Amerika und hier, eine mitbringen zu lassen.\nIch habe eine eigene, ich habe mir diesen Luxus gegönnt, weil ich einfach scharf,\nwie auch schon in den Folgen davor gemeint bin, scharf drauf zu wissen,\nwie dieses Interaktionsmodell funktioniert und deswegen bereue ich das auch nicht.\nIst aber scheiße teuer, ist schon so ein Luxusding, wenn man sowas machen will.","Definitiv. Ich war jetzt ganz froh, dass ich mir keine kaufen musste. Das war auf jeden Fall,\nUm es mal vorwegzunehmen, es war auf jeden Fall sehr interessant.\nAlso ich hatte vorher, habe ich dann gemerkt,\nich hatte vorher so richtig keine klare Tendenz zu irgendeiner Meinung oder\nzu keinem, also ich war noch nicht mal vorurteilsfähig.","Ich finde es super spannend, weil du warst ja so wir haben ja die Sendungen,\ndie sich so, das hat sich ja angebahnt über Jahre gefühlt und du warst so lange super anti,\nwas der Dreck soll und sowas will noch niemand und dann hat es ein bisschen\ngekippt und jetzt bist du neutral und dann bist du neutral darauf zugegangen,\nalso ich fand diese Wandlung fand ich spannend, weil es interessiert mich nicht, was soll denn das Ja.","Also um es vielleicht dahingehend mal vorwegzunehmen Also meine Ablehnung oder\nmeine Skepsis ist generell gegenüber eben diesen Headsets als Benutzung im normalen\nsozialen Kontext und auch als Alternativ zu den anderen Geräten.\nDa habe ich ja auch benannt, was ich primär als Problem sehe.\nDiese Abschottung von anderen Menschen, 3D macht nicht unbedingt immer Sinn,\nAuflösungsproblematik etc.\nEtc. Kann man alles nachhören.\nUnd ich finde auch nach wie vor, dass das alles absolut viable Punkte sind.\nDann kam das Announcement von Apple und ich fand es halt schon bemerkenswert,\ndass sie auf viele von diesen konkreten Dingen eingegangen sind.\nMit diesem Display außen und mit diesem Blickkontakt.\nWir haben ja einen riesen Aufwand gestartet jetzt eigentlich.\nUm quasi ein Produkt in die Welt zu bringen, wo sie sagen können so,\nja, wir haben auch Freakshow gehört, wir wissen, was die generellen Probleme\nmit dieser Kategorie sein können,\naber wir haben dann auch mal was vorbereitet und guckt auch mal hier.\nDas fand ich jetzt sozusagen interessant. Und,\nJetzt habe ich mir natürlich in der Zwischenzeit auch viele von diesen ganzen\nReviews, die reingekommen sind, andere Podcaster, die darüber berichtet haben,\ndas habe ich mir alles angehört und da waren halt viele interessante Details dabei.\nIch habe aber auch gemerkt, dass es sehr schwierig ist und das wird auch heute\nwieder sehr schwierig sein, dass wenn man das nicht wirklich selber ausprobiert,\ndann ist es sehr schwer zu vermitteln, was da sozusagen wirklich passiert,\nwir werden es aber trotzdem probieren.","Ja, vielleicht, weil es gerade nochmal so in dieser Genese ist von diesem Produkt,\nwas ich ja ganz spannend finde.\nWir haben ja, glaube ich, in der Freakshow habt ihr auch drüber gesprochen, so dieser Humane AI Pin.\nAlso die Firma, die Leute, die mehr oder weniger Humane gegründet haben,\nsind die Leute, die zu dem Zeitpunkt Apple verlassen hatten,\nals die Vision Pro in Planung war.\nAlso die haben genau, auch aus einem ethischen, dystopischen Grund mit,\ndie Leute wollen nicht diese Displays auf dem Gesicht, das ist nicht eine Zukunft,\ndie wir gerne hätten, haben die auch verlassen.\nAlso der AI-Pin ist jetzt auch nichts geworden, finde ich, aber ich finde es\neine interessante Background-Information,\nweil die haben ja das in ihren Medien, in ihrer Präsentation mehr oder weniger\nauch so Seitenhieber gemacht, wo sie gesagt haben, wir denken nicht,\ndass ein Screen vor den Augen die Zukunft ist, sondern eher das andere.\nAber es ist wirklich eine große Menge Apple-Leute, die im Design fertig waren,\ndie nicht an diese Idee von Vision Pro geglaubt haben.\nNur so als interessante Landschaft.","Also ich glaube, wir haben über diesen AI-Pin gar nicht gesprochen,\nsondern wir haben über dieses andere Ding gesprochen, Roddy.\nDu hast das aufgebraucht.","Den Rabbit. Genau.","Was so eine ähnliche Idee ist, glaube ich.","Doch, ich glaube, wir haben den auch mal erwähnt, den AI-Pin irgendwann.","Aber der stand nicht so im Mittelpunkt.","Nee, nee. Ja, das andere Ding ja auch nicht. Ich fand das nur interessant.","Ja, ich meine, es ist natürlich ein ...","Und als Linkshänder musst du dir natürlich sofort meckern, dass es ein Rechtshänder-Gerät\nist. Aber das nur am Rande.","Oh, das habe ich ja letztens jetzt auch gemerkt, weil Nachwuchs ist Linkshänder.\nUnd Carcasson kann man recht als Linkshänder blöd bedienen in einem großen Screen auf dem iPad.\nUnd wir haben es nicht eingebaut, dass man es wechselt. Ich fand es ganz schön arschig von uns.","Linkshänder finden bei Apple sowieso nicht statt. Also du hast als Linkshänder\nhast du bei iOS einfach verloren.\nIch meine Accessibility gibt es für alles, aber Linkshänder finden nicht statt.","Weil auf dem Mac mit der Maus und so gibt es es ja schon. Und in der Vision\nauch. Kommen wir später auch noch dazu.","Nein, mein Lieblings-Nörgelpunkt ist da immer,\nes gibt diese Geste, um in einem Navigation-Stack zurück zu navigieren,\nindem man mit dem Daumen von der linken Seite rüber zieht und dann navigiert man zurück.\nDas funktioniert, wenn man es auf der rechten Hand hat, relativ zuverlässig,\nweil man muss weit rübergreifen.\nWenn man das iPhone in der linken Hand hat, ist der Daumen aber standardmäßig\nda, wo man die Geste auslöst und man kann sämtliches horizontales Swipen nicht\nbenutzen, ohne dass man zurück navigiert.\nEs geht einfach nicht und man kann es verdammt nochmal nicht ausschalten.\nMan kann diese verdammte Navigation-Stack-Geste nicht ausschalten.\nDas ist, gut, beschwere ich mich schon seit Jahren nicht mehr,\nweil es keinen Sinn hat, aber wie gesagt, also Linkshändertum findet bei Apple nicht statt.\nWeiß ich nicht, was das für eine Art ist.","Der am meisten verbreitete Bedienungsunterschied ist so bei Menschen eigentlich.\nEs gibt mehr Linkshänder als Blinde oder so.","Aber es gibt ja so viele Sachen, Autoschlüssel, die ausklappen,\nfunktionieren nur in der rechten Hand oder solche Sachen.\nOder versuch mal mit der linken Hand einen Korkenzieher in eine Beinflasche\nzu drehen, das kannst du komplett knicken.\nUnd solche Sachen. Also das sind halt irgendwie, naja, aber es ist halt ein Rechtshänder-Welt.\nOkay.","Kleiner Side-Track.","Okay, gut. Zurück zur Vision Pro.","Müssen wir jetzt eigentlich Apple Vision\nPro sagen? Wir haben alle keine Verbindungen, oder? Das ist mir egal.","Wir werden irgendwelche Schimpfworte noch dafür...","Meine heißt Schiebruin.","Schiebbrühen?","Schiebbrühen heißt der, ja. Man muss ja einen Namen vergeben.","Vielleicht erstmal die ersten Gedanken komplett ablegen. Also ich war offen\njetzt für alles, denke ich.\nUnd ich war halt sehr gespannt, ob ich irgendwas entdecken werde.\nUnd ich sage, geil, das brauche ich.\nWas es ein bisschen schwierig gemacht hat, das kann ich auch gleich vorweg nehmen.\nIch hatte jetzt die Brille ohne irgendwelche Korrekturlinsen.\nUnd obwohl ich im Großen und Ganzen kein Problem hatte, irgendwas zu erkennen\nund das alles zu bedienen, gab es so im Grenzbereich für mich schon Probleme mit der Schärfe.\nAlso wenn ich ein Fenster weit von mir weg hatte,\ndann war es ein bisschen unscharf für mich und ich bin mir nicht hundertprozentig\nsicher, aber es kann sehr gut sein, dass wenn ich vielleicht eine von diesen\nLesebrillen einsetzen.\nDie man ja so hätte dazukaufen können, da braucht man kein Rezept für oder keine\nBestätigung von irgendeinem amerikanischen Augenarzt, also jetzt so eine ganz\nnormale 1,0 Lesebrille Korrektur,\nkann sein, dass das für mich vielleicht etwas verbessert hätte,\nweil ich halt mittlerweile auf so eine Lesebrille meistens angewiesen bin,\nwenn ich was lesen will. Also auf nahe Distanz.\nAber mit dieser ganzen Distanz ist das halt ohnehin so eine Sache.\nIch meine, auf der einen Seite hängt das alles einen Zentimeter vor deinem Auge,\nauf der anderen Seite arbeitet dein Hirn und deine Augen die ganze Zeit mit\nirgendwie einer gefühlten Distanz, die halt sehr viel größer ist.\nUnd das ist für mich auch sehr schwierig zu prozessieren, was da jetzt eigentlich\ndas richtige Setup wäre.\nAlso das wird auch nochmal interessant sein dann zu sehen, wenn das hier in\nDeutschland auftaucht und man in so einen Apple Store latscht und die einem\ndann irgendwie die Augen vermessen oder was weiß ich, was für eine Beratung,\nwas für Tests sie dann machen,\nob dann sozusagen das Ergebnis wäre mit, ja hier nimm nochmal die 1,0 Lesebrille\neinsetze und dann ist es besser.","Aber Lesebrille, das wundert mich jetzt ein bisschen, weil ich würde ja erwarten,\ndass die Brille von der Optik so ist, dass sie sich auf unendlich scharf stellt.\nSprich, wenn du da reinguckst, ist es wie als würdest du ganz nach hinten gucken,\ndamit das Auge sowieso entspannt ist, während du die Brille benutzt und dann\nbrauchst du auch keine Lesebrille, dann ist es sowieso scharf.","Ich glaube, das ist das ganze Ding darum. Es ist sehr persönlich,\nwie man das wahrnimmt mit der Brille, wie diese Optik wirklich funktioniert.\nIch habe viele Theorien und viele Kommentare dazu gehört, also auch bei ATP\nphilosophieren sie viel drumherum und haben unterschiedliche Haltungen,\nwie scharf es ist oder nicht oder wie gut es ist.\nUnd ich habe so ein bisschen das Gefühl, das ist so ein Device,\ndas so vor der Nase, also so persönlich ist an der Stelle.\nJa, also diese Aussagen, diese gefühlten Wahrheiten, die man selber da erlebt.\nJa, es ist unscharf vielleicht, weil ich eine Lese... Es hätte anders sein können mit... Who knows?\nAlso ich glaube nicht, dass wir... Also wir sind da alle nicht optisch firm\ngenug, aber diese Unschärfe, die gibt es.\nAlso es gibt diverse Ecken und ja.","Ja, also Zylinder sehe ich halt ein. Also wenn du eine Brille mit Zylinderschliff\nbrauchst, dann brauchst du auch eine entsprechende Anpassungslinse,\nsonst hast du da Probleme. Das ist irgendwie klar.","Zylinderschliff heißt was?","Zylinderschliff heißt, also wenn du eine normale Lupe hast, dann kannst du die\ndrehen, wie du willst, dann ändert sich das Bild nicht, weil in der Horizontalen\nwie in der Vertikalen der Brechungsindex gleich groß ist.\nSo, jetzt kannst du aber eine Linse so schleifen, dass in eine Richtung der\nBrechungsindex ist, anders als in die andere Richtung.\nUnd wenn du eine gewisse Art von Fehlsichtigkeit hast, dann ist deine Linse im Auge so.\nAlso dann musst du, wenn du eine Brille hast,\ndie gegenteilige Anpassung haben, dann ist die Linse halt in eine Richtung stärker\ngekrümmt als in die andere, um diesen Zylindereffekt wieder auszugleichen.\nUnd das kriegst du aber halt auch nicht mit Scharfstellen oder so hin,\nsondern dann brauchst du halt eine entsprechende Zylinderlinse und die muss\nnatürlich auch im Winkel passen.","Ja, genau.","Also es gibt ja zum Beispiel, wenn du so einen Zylinderfehler hast im Auge und\nhast Kontaktlinsen, dann wird an den Kontaktlinsen unten ein Gewicht angebracht,\nsodass die sich im Auge automatisch hindrehen, dass der Winkel von dem Zylinder passt.","Really? Ja.","Und wenn du den Kopf schief hältst, ist es dann leicht off-center dann?","Ich weiß nicht, wie lange die Linse braucht, um sich zu drehen,\naber das kann natürlich passieren, dass wenn du dann im Bett liegst mit dem\nKopf auf der Seite, dass sich die Linse langsam dreht und du dann irgendwann\ngar nichts mehr siehst. Das kann, weiß ich nicht.\nAlso da bin ich jetzt auf der Nummer 1.","In diesem ganzen Kontext habe ich auch wieder noch ein bisschen Infos irgendwo\nauf irgendeinem Kanal reingespült bekommen, wie denn die Augenmuskeln funktionieren.\nUnd ein Teil der Augenmuskeln ist eben auch ein Dreh des Auges,\ndamit du praktisch so ein bisschen den Horizont gerade hältst,\nwährend dein Kopf schief ist. Also das Auge selber macht nicht nur links,\nrechts, oben, unten, sondern auch in der Rotation sehr unbewusst sehr viel.\nAlso es ist einfach, diese ganze Thematik hat eine gewisse Komplexität.\nUnd das ist ganz spannend. Wusste ich nicht, dass es einen Muskel gibt,\nder für die Drehung vom Auge zuständig ist.","Okay, das wusste ich auch nicht.","Naja, ich wollte ja auch nur sagen ich habe bestimmte in bestimmten Momenten den Eindruck gehabt,\ndass es nicht total scharf war und das hat natürlich jetzt meine Bewertung auch\nbeeinflusst, aber es kann sehr gut sein,\ndass das so just me ist und dass das eben durch eine entsprechende,\nLinsenkorrektur, ob es die Lesebrille ist oder was auch immer also weiß nicht,\nklang für mich jetzt auch nicht logisch, dass das weitet dann auf einmal bei\neiner Lesebrille und so weiter beeinflusst ist, aber es ist einfach,\nhier geht es auch um so Nuancen in gewisser Hinsicht in diesem ganzen Spiel,\ndass ich da mich überhaupt nicht befugt finde, zum aktuellen Zeitpunkt,\nirgendeine Prediction zu geben, was da jetzt sozusagen die richtige Korrektur wäre oder,\nworan das liegt oder ob das jetzt noch eine Frage der Software ist,\ndie vielleicht noch angepasst werden muss, kann alles sein.","Aber dann lass uns doch nochmal so zurück zu den Warte mal.","An der Stelle interessiert mich jetzt natürlich schon noch die Frage,\nkann man unter dem Ding eine Brille tragen oder ist das völlig aussichtslos?","Ich glaube das geht nicht, weil die sind so, da ist der Platz nicht dafür.\nAlso das Insert, also da wo deine Augen reinkommen, das ist schon so rund,\ndas ist so eine Höhle, wo du deine Augen reinsteckst.\nAlso sie arbeiten schon daran, dass der Bildschirm wirklich möglichst nah an\ndir dran ist und diese Inserts dürften dann auch entsprechend gekrümmt sein.\nAber ich hatte jetzt keine im Zugriff.","Weil ich habe da nicht viel Erfahrung mit, aber von anderen Brillen kenne ich\ndas so, man lässt die Brille auf und dann passt es schon irgendwie.","Also vielleicht sollte man nochmal am Anfang jetzt erstmal erklären,\nokay was ist denn jetzt eigentlich die Hardware tatsächlich, was kommt da?\nMan macht irgendwie die Box auf und dann liegt das Teil halt da so vor einem,\ndie Fotos davon werdet ihr ja alle gesehen haben.\nUnd es gibt dann eben diese hübsche Befestigungsschlaufe da hinten zum Festdrehen,\ndie man aber eigentlich nicht nimmt, weil die sieht zwar gut aus auf Fotos,\naber du hast dann halt oben nichts und dann ist das doch signifikante Gewicht\nvon dieser Brille zieht dann doch sehr nach unten.\nUnd,\ndie Brille besteht halt aus diesem vorderen Teil, links und rechts sind diese\nStege reingeklippt, die kann\nman ja auch rausnehmen, da sind diese Lautsprecher drin, die Lautsprecher,\nwerden also nicht ins Ohr gesteckt, sondern die liegen wirklich nur da drüber\nund sind also wirklich im eigentlichen Sinne Lautsprecher,\nund die Verbindung zwischen Zwischen der Brille und dem Gesicht ist dann halt\nnochmal begleitet mit so zwei Einsätzen.\nDas eine ist halt ein, wie heißt das eine, wie heißt das andere?\nEs gibt das Light Shield.","Light Shield, genau. Light Shield ist so ein magnetisches Stoffdings.","Genau, was sozusagen da dran klippt.","Das so ein bisschen Abstand macht und von der Form her ein bisschen interessant\nist. Das gibt es in diversen Ausführungen. Da macht man vorher einen Face.\nEinen ID-kamerafähigen Scan, damit man das richtige Modell bekommt. Die haben,\nzwei Zahlen und einen Buchstaben. Ich habe die 2-2-W und inzwischen ist irgendwie\nauch rausgekommen, was was bedeutet ungefähr.\nEs ist nicht nur einfach eine Größe, sondern es ist wirklich so eine gewisse\nMenge an Gesichtsformen. Es gibt da eine irre Kombination davor.\nUnd da drauf gibt es dann wiederum zwei verschiedene Polster und zwar ein bisschen\ndickeres und ein bisschen dünneres, so einfach einfach um den Abstand ein bisschen\ngrößer oder kleiner zu machen.\nUnd mit dem größeren Abstand könntest du theoretisch, glaube ich,\nversuchen, die Brille aufzusetzen, aber ich glaube nicht, dass sie groß reinpasst.\nAlso eine Geschichte, die ich interessant finde, ist,\nDass der untere Teil, da ist so eine Nasenklappe dran irgendwie an diesem dickeren\nEinsatz, also an dem allgemeinen Einsatz, den man als erstes drauf macht, der so angepasst ist.\nUnd ich habe die als erstes auch so angezogen, dass das andersrum über die Nase\nwar und dann geht da Licht rein und das ist blöd. Und der Zweck des Ganzen ist ganz spannend.\nDieses ganze Ding ist ja relativ trotzdem ein bisschen durchsichtig.\nUnd es ist vor allem luftdurchlässig. Und das ist der große Vorteil.\nDas Ding hat so eine Ventilation und Belüftung, dass die Linsen nicht beschlagen.\nEs ist das erste dieser Geräte, das ich aufgehabt habe, das mir noch nie die\nLinse beschlagen hat. Und ich bin so ein Schwitzer.\nUnd das ist die Hölle gewesen. Das war für mich immer so ein totaler Abturner.\nBei all den Quests oder was auch immer ich aufhatte.\nErstmal, also ich habe die nur mit Föhn benutzt. Also ich habe wirklich,\nich habe einen Föhn nebenbei gelegt und den habe ich da von unten reingepustet\nimmer wieder, um dieses Ding wegzumachen und irgendwann nach einer Viertelstunde\nist das Zeug auf Temperatur und dann beschlägt es nicht mehr.\nAber bis dahin musste ich immer föhnen, ob das jetzt die Playstation VR war\noder die Quest oder was auch immer.\nUnd das Gerät habe ich auf und ich sehe. Super.\nNaja, die Packung. Diese verschiedenen Einsätze gibt es, aber ich glaube der\nKorpus ist immer der gleiche. Also es gibt dieses eine Hardware-Gerät,\ndas der Tim gerade beschrieben hat und dann nur die Aufsätze sind unterschiedlich.\nDas Hardware-Gerät selber ist nicht unterschiedlich.","Also das, wo das Glas dran ist.","Genau.","Das Alu-Teil.","Aber ein kleiner Nebeneffekt von dieser magnetischen Befestigung dieser Sichtsperre,\neben das Blick, die ich mache,\nist, das geht locker ab und man will es dann hochheben an dem Ding und man kann\nes nicht und es fällt einem was runter und das ist bei der Preisklasse auch\nein sehr großer Schockmoment.\nIst mir mindestens zwei, dreimal\npassiert, bis ich das Gerät praktisch an der Brille angefasst habe.\nDas große Problem ist, das Ding ist natürlich Apple-Style, vorne Glas alles,\nweil da sind Sensoren drin und eben auch noch ein Display.\nDas kann man auch noch zuschauen. Also das, was vorne drauf ist,\nwas bei der Skibrille so das Visier vorne wäre.\nDann gibt es außenrum so einen Alurahmen, den kann man grundsätzlich anfassen,\nwill man aber auch irgendwie nicht, weil auf der einen Seite sind Lüfter,\nauf der anderen Seite sind auch Lüfter und dann sind unten auch noch zwei Kameras,\ndie will man nicht, also die einzige Art und Weise, das Ding sauber anzufassen,\nist irgendwie so mit so einem Mittel-Pinch-Griff mit Daumen und Zeigefinger.\nAber das macht man eigentlich nicht an der Seite oder halt an den Henkeln,\ndie Henkel gehen auch ganz gut, da wo die Lautsprecher dran sind.\nGenau, aber es ist so ein bisschen dadurch, dass es so schwer ist,\nman hat immer Angst, es fällt einem runter und dann ist es halt einfach mal,\nweiß ich nicht, 4000 Euro sind im Arsch, das ist ja so die Größenordnung,\nvon der wir im Moment sprechen, wenn man das importiert, dass man echt unter\n4000 Euro kommt kommt man da nicht ran. Und ja, genau.","Okay, dann zählen wir vielleicht nochmal auf, was es so zur Bedienung da noch gibt.\nAlso es gibt ja eigentlich, abgesehen jetzt von den ganzen Kameras und natürlich\nMikrofonen und so, gibt es eigentlich nur zwei Controls, wenn ich das richtig sehe.\nAlso klar, bei dem einen Band hast du nochmal so einen Drehknopf,\num das Band festzumachen, aber jetzt für die Elektronik, für die Software gibt\nes halt so eine Crown, so wie an der Apple Watch, rechts vorne,\ndie man eben auch drücken kann und drehen kann und links oben gibt es quasi\nso einen Action-Button, sagen wir es mal so, nochmal so ein Button.","Der heißt Capture-Button und ist auch ziemlich monothematisch besetzt.","Die Crown ist das, womit man die Durchsichtigkeit der Immersion regelt,\nne? Richtig, genau. Ah ja, okay.","Genau, das ist so die Primärfunktion, also die Primärfunktion von diesen Dingern,\nalso der Button, wie Dom schon gesagt hat, ist halt primär so Capturing,\ndas heißt du drückst da drauf, dann kommst du sofort in Foto machen oder Video machen.\nAlso wenn du das Ding sozusagen als Aufnahmegerät nutzen möchtest,\nschon mal ganz interessant, dass sie das so positionieren und tatsächlich finde\nich, das ist auch eine der interessanteren Funktionen von dem Teil.\nUnd die Crown, wenn du sie drückst, die ist quasi dein Homebutton.\nAlso damit kriegst du dann immer wieder dieses Default-App-Menü,\nwas wir jetzt in tausend Fotos wahrscheinlich schon gesehen haben,\nwo dann eben so die Primär-Apps kommen und wo man dann durch mehrere Seiten\ndurchflicken kann und dann alle Apps, die installiert sind, finden kann.\nAlso die kannst du dir sozusagen darüber immer einblenden.\nWenn du den Button etwas länger gedrückt hältst, dann nordest du quasi deine Sicht neu ein.\nAlso es ist ja immer die Frage, wo ist vorne? Und wenn du dich,\nsagen wir mal, du setzt dich so leicht schräg aufs Sofa,\nsetzt dir das Ding auf, guckst du nach rechts, aber dann nach einer Weile merkst\ndu so, ich will mich hier nochmal richtig hinsetzen und guckst aus,\ndann schaust du ja quasi für die Kamera so ein bisschen nach links und dann\nwürdest du dein Home-Menü sozusagen immer rechts von dir finden.\nAlso diese, wo ist die Zentrale, wo ist die Mitte für dich, wo alles erstmal\nbei Default erscheinen soll.\nDas kannst du dadurch dann machen, dass du diese Crown etwas länger gedrückt\nhältst und dann zack hast du die Mitte neu definiert.\nDas kann man also jederzeit dadurch nachpassen. Das ist auch so eine Funktion,\nwo man wahrscheinlich vorher gar nicht draufkommt, dass man sowas braucht.\nAber das ist eigentlich das, was so diese Buttons und Dinger primär leisten.\nUnd das war's dann glaube ich im Wesentlichen auch schon, was so an Hardwareknöpfen\nund Schräubchen so sich anbietet, oder? Habe ich noch was?","Genau, also der linke Knopf ist wirklich so Kamera anmachen,\nKamera ausmachen, Aufnahme machen.\nDie Crown selber ist Homebutton, und Escape vor allem auch, ja,\nDoppelklick auf die Crown haut dich aus jeder Immersion sofort raus und du hast\nDurchblick, ich meine, das ist die andere Eigenschaft, das Ding hat Durchsicht im Sinne von,\nich habe viele Kameras außenrum und ich versuche dir den Eindruck zu geben,\nals hättest du keine Brille auf,\nso, kann man gleich später noch darüber reden, wie gut es wirklich glückt oder\nnicht, also das ist ja auch was, viel gehypt wurde im Vorfeld,\naber grundsätzlich ist das ein Kernfeature also meistens schaut man durch nur selten oder,\nLässt man sich komplett mit Content beschallen. Auch von der Positionierung her von Apple.\nOder auch das, was es ein bisschen anders spannend macht.","Eine Frage hätte ich jetzt noch zur Hardware. Die Lautsprecher,\nwie brauchbar sind die denn?","Super.","Also das ist wirklich beeindruckend gut. Ja? Ja.","Die machen echt Spaß.","Da gibt es nichts dran zu meckern.","Okay.","Zur Fairness halber muss man sagen, die sind interessanterweise bei den Quest-Dingern\nauch schon nicht schlecht. Vielleicht, aber so die Apple, also ich habe eigentlich\nnur Kopfhörer, AirPods drin, weil ich nicht will, dass jemand anders mithören kann.\nNicht, weil ich mir denke, die Tonqualität wird jetzt besser.\nSo, das ist die Größenordnung.","Aber mithören kann man an sich schon?","Wenn du daneben sitzt, hörst du, was da rauskommt. Aber es ist nicht sehr laut.","Es ist nicht sehr laut, aber es ist halt, wenn du irgendwie die Türen ganz offen\nhast und so weiter, so ein bisschen so ein Radiogesäusel für die anderen.","Und hat auch ordentlich Wumms untenrum im Bass?","Ich habe jetzt nicht so viel Musik gehört, zumindest nicht so basslastige Musik,\naber ich hatte irgendwie nicht so den Eindruck gehabt, dass da einem irgendwas fehlt.\nAlso es war okay und wie Dom schon meinte, am Ende kannst du halt auch einfach\ndeine AirPods noch dazu packen, das ist eine ideale Ergänzung und dann ist ja eh alles super.","Dann will ich aber, dass die Immersion mit dem Drehrad von den Airpods genauso mitgesteuert wird.","Da hast du recht, das ist so.","Ja, das ist so.","Du kannst sie gar nicht mehr einzeln steuern. Hast du sofort den Apple-Faktor\nerkannt an der Geschichte?","Das habe ich jetzt nicht verstanden. Was ist, wenn man Airpods reinmacht? Was geht da nicht mehr?","Es gibt nicht die manuelle Einstellung wie sonst mit Noise Cancellation,\nAdaptive und so weiter, sondern die funktionieren einfach als Extension von\nder Apple Vision Pro. Fertig.","Genau, einschließlich dieses ganzen Spazialen.","Genau, das heißt, wenn du mehr reindrehst, kommt auch mehr Noise Cancellation\nund so weiter an den Start.\nUnd das kommt ja auch dazu, wenn du so drehst.\nWas passiert, wenn man dieses Drehrad dreht? Und dann kriegt man,\nsein Blickfeld ist ja eigentlich,\ndie Gegend zeigt oder da, wo man gerade steht, weil man nur Durchsicht zeigt,\nwird dann von vorne in so einem Radius langsam um einen rum,\nso langsam bis zu vollständig ausgefüllt von einem Environment.\nUnd das ist, Environment ist ein Ding.","Jetzt greifen wir aber ein bisschen vor. Also lass uns vielleicht mal darauf\ngleich kommen, weil das finde ich ist nochmal so ein wichtiger Punkt.\nWir halten einfach mal fest, so das ist so die Hardware, Lautsprecher sind super.\nSuper, wenn man die jetzt aufsetzt, die Vision Pro,\nalso jetzt sozusagen die echte Unboxing-Experience mit, das Ding ist noch komplett\nleer, also so hast du es ja gemacht, so ist es mir auch übergeben worden,\ndass ich das also mit meiner eigenen Apple-ID dann auch pairen konnte.\nLeute, dann gehst du halt in so einen Setup-Prozess und ich muss zugeben,\nich habe mir jetzt diesen Setup-Prozess in der Reihenfolge nicht notiert.\nKann sein, dass ich das jetzt ein bisschen durcheinander bringe oder was vergesse.\nAber das war natürlich ganz interessant. Also du schaltest das,\ndu setzt das Teil auf, dann,\nhast du ja dieses Stromkabel, was du da so reinklippst und in dem Moment,\nwo du das reingeklippt hast, ist das Ding im Prinzip, bootet das.\nAlso du musst jetzt nicht nochmal irgendwas drücken oder so.\nUnd Booten heißt, du setzt es auf und das Ding ist für einen kurzen Moment schwarz.\nDann kommt ein Apple-Logo, richtig?","Es kommt erst so ein Gewaber. Es kommt so ein leichtes Helligkeitsgewaber innen im Licht.\nAußen kommt ein Apple-Logo, das sieht relativ low-res aus. Und innen drin kommt\ndann auch als erstes kurz in der Mitte des Screens ein schwebendes Apple-Logo.","Genau, so wie beim Mac, der bootet. Und dann geht die Kamera an.\nAlso das ist dann sozusagen das erste Ding, also wenn das irgendwie halbwegs\nbetriebsbereit ist und sozusagen sagt so, hallo, ich bin's, deine Kernfunktion.\nUnd die Kernfunktion heißt, du kannst hier durchgucken.\nUnd dann hast du auf einmal auch wieder diese Verankerung mit dem Raum was schon\nmal, also bevor irgendwas aufgesetzt ist, siehst du erstmal deine Umgebung,\ndas ist schon mal ganz gut das fand ich sehr assuring,\nund dann genau, weiß nicht, hast du das noch so im Kopf ich hab die Reihenfolge\nnicht mehr so ganz drauf also das iPhone erkennt dann erstmal natürlich.","Die Durchsicht getestet an der Stelle und bin rumgelaufen, weil ich wollte erstmal\nsehen, wie gut ist die Durchsicht und hab mich gar nicht an das,\nwas er mich leiten wollte erinnert, weil ich wollte sehen, wie ist die denn so.\nJa, und da ist mir aufgefallen, nach all dem Hype war sie mir zu schlecht,\nweil sie einen extrem viel Motion Blur hatte.\nAlso man muss sagen, ich habe das, der Bekannte von mir ist erst abends angekommen,\nalso der ist mittags mit dem Flieger angekommen, brauchte ein bisschen Erholung\nund wir haben das abends getestet, es sind schlechte Lichtverhältnisse.\nLichtverhältnisse machen einen riesen Unterschied für das Gerät.\nUnd dann muss ich feststellen solange man den Kopf gerade hält ist der Durchblick super,\nAber wenn man dann den Kopf bewegt, dann hat man einen sehr absurden Motion\nBlur, der einem diesen Durchschnittseffekt ziemlich kaputt macht, finde ich.\nAlso da muss man sich lange dran gewöhnen, dass es kurzzeitig unscharf ist und dann ist es in Ordnung.\nAber es ist nicht so, also alle haben gesagt, ja das ist genau so,\nals hätte man auf und ab und so, als hätte man nichts an und das ist mitnichten so.\nAlso der Blickwinkel und so ist super, die Auflösung ist auch adäquat,\naber die Kameras sind sowohl von der Lichtempfindlichkeit als auch von der Schärfe,\ndie können noch ein paar Generationen besser werden.","Und das ist jetzt aber nur der Fall, dass das Licht schlecht ist?","Es ist besonders schlimm, wenn das Licht schlecht ist, aber es ist auch nicht\nperfekt, wenn das Licht da ist.\nAlso wenn das Licht da ist, dann ist es ungefähr so, auf so einer Handdistanz\nist halt was, ich meine, es ist verhältnismäßig schon cool, du kannst dein Telefon\nbedienen, ohne dass du die Brille absetzt.\nSo, die Auflösung hast du, du kannst es lesen und so weiter.","Mit Einschränkung. Also man kann dann nicht mehr alles so gut lesen.\nAlso es ist nicht so, dass es dann wirklich noch genauso aussieht,\nsondern es ist schon etwas vager alles.","Genau, aber man kann es überhaupt. Also das ist schon auch so eine technische\nGeschichte, die durchaus eine Errungenschaft ist.\nAber bei all dem Hype dachte ich halt so, hey, das ist so aufgelöst,\nwie ich sehen kann. Und das ist es halt nicht.","Ja, zu dem Motion Blur nochmal, also man muss sich das jetzt nicht so vorstellen,\ndass wenn man nach links guckt schnell, dass dann so alles auf einmal in so Streifen übergeht.\nEs ist nur so, du guckst woanders hin und das Eye-Tracking braucht einen Moment,\nbis es sozusagen das dann auch umsetzt und umsetzen heißt, dass an der anderen\nStelle, wo ich hinschaue, dann nochmal nachgeschärft wird.\nIch weiß nicht, ob das generell diese Funktion ist, die für dieses Rendering auch zuständig ist.\nDom, ich weiß nicht, wie du das siehst, also was der Grund dafür ist,\ndas ist mir nicht so ganz klar, aber der Effekt ist auf jeden Fall der,\ndu schaust irgendwo hin und dann ist es für so einen ganz kurzen Moment,\nerst ist es nicht so richtig scharf und dann ist es scharf.","Also der Grund ist mir nicht so hundertprozentig klar.\nEs hat glaube ich was damit zu tun, dass, so wie ich es verstehe,\num dieses 3D-Bild, das die Kameras außen aufnehmen, auf die Augen zu mappen,\nwas ein bisschen höher ist, ein bisschen anders die Geometrie zu machen,\nmüssen sie ein bisschen mehr Informationen haben von allen Sensoren und sind\ndeshalb ein bisschen langsamer.\nWeil, wenn du in 2D guckst oder eine Aufnahme machst, dann hast du diesen Blur nicht.\nDen Blur hast du, wenn du die Brille auf hast, auf den beiden Augen.\nAlso das ist glaube ich wirklich so eine,\nGeometrie, Anpassung und es\nmuss genau sein und irgendeiner von den Sensoren ist noch zu leggy dafür.\nDas ist, glaube ich, mein Eindruck. Aber who knows. Es sieht halt kurzzeitig\nso aus, als wären zwei Bilder praktisch noch übereinander gelegt.","Den Blur sieht man aber auch in Screen Captures.","Aber nicht so sehr, wie du es drauf hast. Also wenn du es drauf hast,\nist eine ganz andere Größenordnung.","Okay, ja, aber so in User Interface Elementen und so weiter sieht man dann schon,\nwo derjenige, der die Screen Capture gemacht hat, wo der hingeguckt hat,\nweil alles andere ist halt doch ein bisschen blurry.","Das ist ja was anderes, genau, aber das ist Foveated Rendering und das ist was\nanderes, weil das fällt dir innen nicht auf.\nWeil das ist einfach nur eine Optimierung, die passiert. Die können wir mal\nkurz beschreiben, weil so schwierig ist die nicht.\nDas Ding hat Augensensoren, das heißt, es weiß, wo du hinguckst und um Performance\nzu sparen, ist nur der Teil scharf.\nWenn du jetzt Screen Capture machst, dann fällt dir das auf,\nweil du dann genau siehst, wo die Person hingesehen hat und der Rest komplett unscharf ist.\nDiese Unschärfe hast du, wenn du es aufsitzt, nicht.\nWeil sobald du, also das ist schneller scharf, was du hingucken kannst.\nAlso das ist technisch geil gelöst.\nUnd das ist eben eine ganz andere Unschärfe. Weil die ist ja eher nur einfach\ndie Auflösung runtergerät.\nDas ist wie es wäre mit Mapping, aber halt am Augen Mittelpunkt, da wo du hinguckst.","Es ist jetzt aber auch kein Effekt, wo man sagen muss, das ist jetzt schon der totale Dealbreaker.\nAlso das ist schon was, woran man sich gewöhnen kann. Und ich glaube,\nes ist auch nochmal ganz wertvoll, nochmal zu wiederholen, was du gerade gesagt\nhast, Dom, das ist mir nämlich auch erst danach klar geworden.\nMan schaut ja in die Welt.\nDie Kamera versucht deinen Blick zu simulieren und dir ein entsprechendes Bild\nso zu liefern, als würdest du da selber gerade hinschauen, was du ja nicht tust.\nAber da, wo deine Augen sind, sind gar keine Kameras,\nsondern die Kameras befinden sich etwas weiter oben und etwas weiter unten und\ndas heißt, sie müssen diesen Blick, die Blickrichtung oder den Winkel korrigieren in Software. wäre.\nUnd das ist also nicht so ein einfaches Durchschalten eines Videosignals,\nwo man sich denkt, wieso gibt es da irgendwie noch überhaupt irgendeine Verzögerung,\nsondern das ist halt auch ein digital,\nbegleiteter Vorgang, der in irgendeiner Form ein Berechnungsrendering ist und\ndas unter Umständen hier schon wirklich auf der.\nMaximalen Geschwindigkeit arbeitet, die diese Elektronik gerade liefern kann.\nMit anderen Worten, das ist ein steigerungsfähiger Aspekt.\nEs kann sehr gut sein, dass das in der nächsten oder übernächsten Generation\nweg ist und dann auch gar kein Thema mehr ist und dann weißt du noch damals,\nals es diesen Motion Blur gab und so weiter.\nAlso das ist vielleicht nicht so wichtig, wenn es darum geht einzuschätzen,\nwas hat das Ding für ein Potenzial, sondern es ist mehr so eine Feststellung\nmit so ist jetzt dieses konkrete Gerät.","Und das finde ich insgesamt, das ist so ein bisschen ein Thema auch,\ndas sich zumindest in meiner Bewertung durchziehen wird. Es gibt Es gibt viel Potenzial von...\nDas technisch in der Zukunft viel besser gelöst wird. Also da,\nwo wir jetzt beim iPhone und beim iPad ziemlich am Ende der Fahnenstange sind,\nsind wir halt bei der Vision Pro am Anfang.\nDas ist praktisch das Minimal Viable Product, das gut genug ist,\num diese Art von Computing zu machen.\nUnd was ich nochmal dazu sagen will, ist, ich habe die Durchsicht auch von der\nQuest 3 im Vergleich gesehen,\nalso selber benutzt und diese geometrische Verzerrung, die dadurch stattfindet,\ndass die das nicht macht,\ndie ist sehr deutlich sichtbar.\nAlso wenn man die Quest 3 aufhat, ist die grundsätzliche Auflösung nicht so\nviel schlechter, als man jetzt denkt, aber der Blickwinkel und die Sicht aus\ndeinen Augen ist halt einfach nicht korrekt, die ist einfach schief und es wirkt\nalles wie ein interessantes Videospiel.\nHat später nochmal, erinnert mich mal an das nochmal, es hat Auswirkungen auf\nandere Aspekte, auch die ein bisschen störend sind, also bei der Vision Pro.\nAber so grundsätzlich ist es schon eindeutig besser, wenn dein Blickfeld genauso\naussieht, wie es dein Hirn erwartet.\nAlso auch von der Art und Weise, wie es einem selber jetzt geht,\nwenn man das Ding auf hat, weil es gibt ja so viele physiologische Effekte,\ndie passieren, wenn man zwei Bildschirme vor den Augen hat über einen längeren\nZeitraum, da kann einem schlecht werden,\nda kann man desorientiert sein, da kann blöde Sachen passieren und grundsätzlich\nist meine Erfahrung mit der Vision Pro da sehr gut gewesen.","Ein Aspekt noch in Bezug auf diese Durchsicht ist natürlich,\nwie viel sieht man eigentlich?\nUnd ich weiß jetzt nicht ganz genau, was das in Grad ist. Ich habe irgendwas\nüber 100 Grad gelesen. Stimmt das? Was ist dein Eindruck?","Es gibt keine offizielle Angabe. Leider ist es auf alle Fälle im Vergleich nicht\ndie größte der Blickwinkel, die man so haben kann.\nAlso sowohl Quest 3 als auch Quest Pro haben einen weiteren Also.","Es ist definitiv nicht 180 Grad. Es ist sehr viel weniger.\nVon daher hast du schon so ein bisschen, also es ist jetzt nicht so wie durch\nein Fernglas gucken, auf gar keinen Fall.\nAlso dass du so richtig in so ein Rohr reinschaust oder so, das ist es nicht.\nAber es ist auch sofort klar, dass das nicht dein normaler Blickwinkel ist.\nAlso Blickwinkel ist nicht der richtige Begriff.","Du, ich bin Brillenträger seit Jahren. Ich kenne das Problem und den Effekt.\nAlso das schockt mich jetzt überhaupt.","Also die interessante Sache ist ja, als Brillenträger ist man sowas ja gewohnt\nund man kann sich wohl ganz gut darauf einstellen, wenn das Blickfeld ein bisschen eingeschränkt ist.\nAls Nicht-Brillenträger ist es durchaus ein größerer Nachteil,\nweil man kann eben nicht einfach mit dem Auge nach links gucken und dann sieht\nman das so weit, wie man halt am Gesicht vorbei sieht, sondern dann sieht man\nhalt mit dem linken Auge noch ein bisschen was und mit dem rechten Auge siehst du halt schwarz.\nSo, insofern man muss schon ein bisschen mit diesem Tunnelblick auch arbeiten,\nist aber bei den meisten Headsets so, bei anderen ist es halt ein bisschen besser\nund das kann man natürlich auch,\nweil das ist auch sowas in Zukunft wird es auch besser werden noch da gibt es\nkeine technischen Gründe dafür warum man das nicht besser machen würde,\naußer halt Auflösung im Verhältnis zu,\nzu Blickweite und im Moment, Apple wollte halt mehr Auflösung haben,\nUnd ist auch wichtig Weil Ich finde gar nicht so, dass die Durchsicht von der\nAuflösung her So wichtig ist, sondern das, was man ansonsten Da rein macht in\ndiese Durchsicht Das muss natürlich gestochen scharf sein Und das ist es.","Kann sogar sein, dass der Begriff Gesichtsfeld ist Den wir jetzt versuchen zu\nbeschreiben Gesichtsfeld.","Echt?","Ja, da gibt es nochmal Unterschiede Optik ist wirklich, das ist auch echt nochmal\nso ein Rattenloch Da will ich jetzt gar nicht rein Auch Disclaimer.","Wir haben keine Ahnung Ja genau.","Aber sagen wir mal so, man hätte gerne mehr, also ich hätte gerne mehr,\naber es ist auch nicht so, dass man jetzt das gar nicht genießen kann.\nAlso ich habe nicht das Gefühl gehabt, jetzt in so eine Kammer eingesperrt worden zu sein, aber es ist…,\nIch würde sagen, das ist so ein Bereich, da kann ich mir sehr gut vorstellen,\ndass wir in zukünftigen Generationen Verbesserungen sehen werden.\nAlso es sollte ein Ziel sein, noch ein breiteres Gesichtsfeld anbieten zu können,\naber so wie es ist, ist es brauchbar und bietet schon eine Menge.","Ich muss da jetzt einfach auch mal sagen, ich meine, ich hatte das erste iPhone\nund ich hatte auch das erste iPad und ich hatte auch die erste Apple Watch und\ndiese erste Generation Geräte von Apple, die sind zwar irgendwie ganz geil, was sie machen,\nwas vorher keiner gemacht hat, aber gerade von der ersten Generation zur zweiten\nGeneration war immer ein deutlicher Sprung und das würde ich jetzt bei der Vision auch erwarten.","Ist klar, aber wir beschreiben das ja auch nur deshalb jetzt so akribisch,\ndamit jetzt alle, die uns zuhören, auch mal ein Gefühl dafür bekommen,\nwie ist es denn jetzt sozusagen, was sind denn jetzt die realen Constraints der Hardware,\nin dem sich das dann alles abspielt, worauf wir jetzt eigentlich ein bisschen hinaus wollen.","Ja, das sehe ich auch so. Ich würde auf was eingehen wollen,\nwas du sagst, aber halt erst später, weil das ist so der Ausblick,\ndas ist so eine, lass uns mal erst durch das Produkt, wie es ist,\ndurchgehen, aber dann haben wir relativ viel Meinung, glaube ich, noch.","Jetzt, wenn man es mal im Feld anguckt, zu all den anderen Brillen,\ndie du erwähnt hast, ist es schon ein Schritt nach vorne, oder?","Also es ist für den Zweck, den es erfüllt, ein Schritt nach vorne.\nEs ist für manche Sachen ein Schritt zur Seite.","Ich denke, Apple geht den Schritt in eine andere Richtung als die anderen.\nDann machen wir es mal so.\nKommen wir mal vielleicht kurz zum Setup. Also jetzt haben wir die erste Wahrnehmung\ngehabt, man setzt sich das Ding auf und bevor irgendwas eingerichtet ist,\nkann man halt durchschauen.\nUnd das eben in diesen Constraints, die wir jetzt so genannt haben.\nDann kommt das Setup. Also ich meine, es fängt damit an, dass so wie wenn man\nsich ein HomePod kauft, das Ding erscheint dann sozusagen sofort auf deinem iPhone.\nOh, eine Apple Vision Pro, möchtest du Setup machen? Ja,\nzack, bumm, möchte ich gerne machen und dann fangen halt Vision Pro und dein iPhone an,\nsich über alles mögliche zu unterhalten und dann fängt das Ding irgendwann an\nso zu booten und dann kennst du halt dein WLAN und deine Apple ID und das ist\nhalt irgendwie alles aufgesetzt und so.\nDann musst du dir eine PIN geben, wie für das iPhone, dann hast du das erste\nMal so eine Eingabe und ich glaube, ist das vor dieser Sicht,\nerst kommt diese Sichttest-Geschichte.","Erst muss der Sichttest, glaube ich, dann passieren. Aber ich glaube,\nder Account kam auch vor dem Sichttest, deswegen, da hast du schon recht.","Das weiß ich nicht mehr so ganz genau.","Doch, da ist eine interessante Frage, glaube ich. Hat es bei dir geklappt?\nAlso, mach mal dein iPhone in die Nähe und dann wird alles transferiert und alles super.","Also das ganze Setup war mühelos.","Ich hatte gleich wieder ein Flop-Setup, aber ich hatte natürlich auch eine ältere\nVishnu-S-Version, während ich installiert war.\nAlso du hast ja zwei Updates schon drauf gehabt auf deiner. Bei mir war dann\nso ein richtig, also es waren interessante Flops.\nAlso das eine war, ich hatte keine Uhr dran und deshalb war mein Telefon nicht\nanlockt und mein Telefon hat natürlich mich mit der Brille auf nicht erkannt.\nAlso musste ich dann erstmal mein Telefon anlocken, durch die Brille zum Durchgucken\nmit dem Passcode was ist so ein bisschen, also das ist so ein,\ndas war so ein bisschen, aber das ist auch noch ein ongoing complaint,\nweil man könnte natürlich auch wie mit der Uhr das anlocken und dann bei mir\nging da leider dieser komplette Setup-Prozess so ein bisschen schief, ich war da so ein,\nJa, so ein klassischer Beta-Tester, dass es nicht so dolle geklappt hat und\ndass ich dann auch nicht wusste, soll ich vom Backup einspielen?\nIch habe doch gar kein Backup gerade.\nIch will aber meine Daten drauf haben. Was soll ich tun?\nAlso ich war so ein bisschen underwhelmed von dem, was ich eigentlich erwartet\nhabe von Apple, wie der Ablauf läuft, weil ich ein paar Fragen als erfahrene\nApple-Nutzer nicht beantworten konnte, ohne mir einzuscheißen,\ndass ich vielleicht das Falsche ausgewählt habe.\nAber nichtsdestotrotz, danach hat es auch geklappt und ist alles draufgesungen.\nDauert aber halt eine ganz schöne Weile.","Also ich weiß jetzt, wie gesagt, nicht, ob ich jetzt genau die Reihenfolge hinbekomme,\naber was auf jeden Fall dann relativ früh kommt, ist eine Kalibrierung deiner Augen.\nAlso ich glaube, das allererste ist, du sollst einfach nach vorne gucken.\nDas ist, wenn diese beiden Augengrünen Dinger da zusammenschieben.\nAlso du guckst erst mal rein und dann messen sie sie und vermessen erstmal das\nAuge. Damit geht's dann los.\nUnd dann musst du an bestimmte Punkte gucken und das bestätigen.\nDa kommen wir dann jetzt auch schon zu der ersten Interaktion.\nHalt das mit den Fingern, das Ding.\nErkennt deine, ah ne genau, die Hände. Die Hände kommen als erstes.","Die Hände auch, ne.","Das war das erste.","Also ne, als allererstes ist wirklich der Augenabstand. Und der wird eingestellt,\nindem er praktisch eingeblendet kriegt, so eine Brille in beiden Seiten.\nAlso man sieht praktisch so einen Brillenumriss in beiden Seiten und dann sagt\nder Text, drücke die Crown so lange gedrückt, bis das stimmt.\nUnd dann fährt er praktisch den Augenabstand, der ist flexibel und der wird\npraktisch eingestellt auf dich, so lange bis es scharf wird und das macht aber\nalles automatisch. Man drückt nur ganz lange die Crown.","Das war bei mir nicht mehr so.","Was?","Ich musste nicht draufdrücken.","Doch, doch. Nee. Alle müssen da draufdrücken. Selbst ich muss das jetzt zwischendurch\nnochmal machen, wenn er sich verwirrt ist.\nDu musst einmal die Crown drücken, damit er den Augenabstand einstellt.\nDas hast du auch gemacht.","Einmal drücken oder so lange drücken, bis es richtig ist?","Gedrückt halten, bis es richtig ist.\nUnd er braucht halt einfach eine Zeit. Und da musst du mit Doppel-Tap nochmal\nbestätigen. Doch, das hast du vergessen. Das ist so.","Okay, das ging schnell, das zu vergessen.","Es ist halt das Erste und du bist interessiert an allem anderen.","Ja, ja, es ist schwierig, sich das alles zu merken. Naja, auf jeden Fall,\negal wie die Reihenfolge ist, verschiedene Dinge.\nDu musst deine Hände vor die Kamera halten, da schaut er dann drauf,\ndamit er irgendwie weiß, wie lang sind deine Finger, wie ist deine Hand etc.\nDann drehst du die Hände einmal um, dann guckt er sich sozusagen die Innenseiten\nder Hände an, dann ist das Thema Hände auch schon wieder beendet.\nDann kann er die Hand gut erkennen und man kann diese Klickgeste sozusagen machen,\nalso Daumen und Zeigefinger zusammen,\ndas ist sozusagen der Klick und dann erscheinen Punkte auf dem Bildschirm, die man angucken muss,\nalso man fokussiert sozusagen diesen Punkt in so einem Kreis,\nso fünf, sechs Punkte, guckst dir einzeln an und du merkst schon so,\noh, das Eye-Tracking funktioniert.\nAlso du schaust es an und dann ist da so ein kleiner Punkt, der so klein wird,\ndann weißt du so, ich hab da jetzt hingeguckt und dann machst du Snap mit deinem\nFinger und dann geht das zum nächsten und klick, klick, klick, klick, klick.\nUnd das ist schon irgendwie ganz geil, muss ich sagen.\nAlso dieses, dass du so auf einmal so eine bionische Verbindung hast mit diesem\nGerät, dass also wirklich deine Augen jetzt dein Pointer sind.\nDas ist schon irre, vor allem weil viele Dinge, wo man sich denkt,\nso Tastatureingabe und so, wir wissen ja alle, was das immer für ein Heckmeck\nist, mit dem Finger dann auf solchen Tastaturen die einzelnen Buchstaben zu machen.\nDu bist halt mit dem Auge und deiner Snap-Bewegung viel schneller als mit den\nFingern. Das ist wirklich irre.\nMan muss sich so ein bisschen dran gewöhnen, dass man nicht schon auf den nächsten\nPunkt schaut und so ein bisschen schon mal einen Schritt weiter ist,\naber wenn man sich dran gewöhnt hat, dann geht es sehr schnell.","Die Augenkalibrierung, muss ich auch sagen, hat mir relativ gut gefallen vom Design her.\nMan guckt erstmal in die Mitte und das ist eben dieser Punkt,\nder so ein bisschen kleiner wird und gleichzeitig so einen Soundeffekt noch hat.\nSie benutzen auch sehr gut den räumlichen Soundeffekt. Das heißt,\ndu guckst in eine der sechs Punkte, die außenrum sind.\nOder sind es sechs oder neun? Weiß ich nicht genau. Und dann guckst du da hin\nund dann macht der praktisch auch vom Geräusch her, das Geräusch ist auch rechts\noben, wenn du nach rechts oben guckst.\nUnd du kriegst ein visuelles Feedback, dass du du das anguckst,\naber eigentlich ist es ja, dass du mit deinem Klick ihm sagst,\nja, jetzt gucke ich das an.\nAlso diese Feedback- Mechanismus, dass du ja eigentlich das Ding kalibrierst,\naber er währenddessen schon so tut, als wüsste er schon, was du machst, so ungefähr.\nDas haben sie sehr gut hinbekommen. Und man muss es ein bisschen lange machen.\nDas sind so drei verschiedene Varianten davon, weil, ich glaube,\nwegen der Pupille, weil einmal in dunkel, einmal in mittel, einmal in hell,\nje nachdem, wie groß die Pupille ist dann, das Auge dann, Aber dann ist es auch gegessen.\nDann wird dein Blick erkannt und dann kannst du Dinge angucken und mit dem Finger,\nwenn du linke oder rechte Hand, Daumen und Zeigefinger zusammen tippst,\ndann machst du einen Klick oder auch einen Longpress, wenn du es zusammendrückst.\nDie nennen es glaube ich Pinch im Englischen.\nDas sei vielleicht auch nochmal dazu gesagt, das Ding ist im Moment nur auf\nEnglisch und funktioniert auch nur mit einem amerikanischen Account eigentlich,\nwas Tim wahrscheinlich viel Spaß gemacht hat beim Testen.\nUnd wird aber natürlich später irgendwann mal komplett international sein,\naber das ist im Moment so der Fall.\nUnd dieses Pinschen kann man mit links und mit rechts machen und das sind damit\nauch mehr oder weniger zwei, so wie zwei verschiedene Touches,\ndie man damit machen kann.\nIch weiß nicht, wollen wir weiter auf diese grundsätzliche Bedienung eingehen\noder wie erklärt man das jetzt am besten, dass man genug Fleisch hat,\num irgendwie, wenn wir drüber sprechen, sich was vorstellen zu können,\nwenn man es noch nicht aufhatte.","Ja, also das Setup haben wir dann eigentlich soweit durch.\nAlso es besteht im Wesentlichen im Kalibrieren von Händen und Augen und wenn\ndas Gerät der Meinung ist,\ndas wäre jetzt verstanden, dann geht es eigentlich los und ich glaube da passiert\ndann auch nicht mehr sehr viel und dann hat man den Homescreen vor der Nase und dann geht es los.","Man kriegt ein, zwei Bedienungseinführungen so mit, jetzt unten an diesem Fenster\nist so ein Balken und den kannst du angucken und verschieben.\nIch glaube schon, dass du grundsätzlich noch so eine Sequenz,\nwie du ein Fenster im Raum verschieben kannst und vergrößern,\ndie kannst du entweder mitmachen oder abbrechen, aber das wäre so noch die Einführung, die man bekommt.","Genau, und dann…,\nDann bist du eigentlich an diesem Punkt so und dann kann man jetzt vielleicht\nmal darauf eingehen, was sich jetzt sozusagen nach dem Setup für Möglichkeiten ergibt.\nAlso was macht man jetzt eigentlich mit dem Ding? Du sitzt jetzt auf dem Sofa, hast das Teil auf,\ndu siehst deinen Raum und du hast dann diesen Homescreen vor dir mit hier Safari\nund Musik und was da halt alles noch so dabei ist.","Interessanterweise nicht alle Apps, die man so kennt, aber ein paar davon.","Ja, und dann kannst du halt irgendwas angucken und wenn du was anguckst,\ndann zuckt das irgendwie so.\nDann kriegt das so einen kleinen dreidimensionalen Schritt nach vorn Effekt.","So ähnlich wie beim Apple TV?","Genau, genau so diese Apple-TV-Effekte ist es so im Wesentlichen.\nEin bisschen subtiler sogar, so absichtlich, weil es halt viel passiert,\nweil man guckt ja viel an und das ist eh Ablenkung.\nManchen ist das auch zu subtil, aber es ist so, du erkennst,\nwenn was angeguckt wird, durch leichte Lichtverhältnisveränderungen und leichtes Highlighting.\nBei den Apps, die springen dich ein bisschen an, die sind fast genauso wie die\nApple-TV-Geschichten, wenn du da mit dem Finger so rumswipest so ein bisschen mit den Icons.\nUnd alle anderen Elemente haben mehr so einen Schimmer, so ein bisschen heller\noder ein bisschen dunkler oder ein bisschen weniger vibrant,\nwie das ja so heißt bei diesen ganzen Geschichten.\nAber du weißt es meistens schon recht gut, was du anguckst in dem Moment.\nUnd dann kannst du, wenn du siehst, kannst du es eben drücken,\nindem du entweder einen Finger kurz tippst oder lang tippst.\nUnd wenn du lang tippst, dann ist die interessante Geschichte,\nalso wenn es nicht nur ein Klick ist, die weitere Bewegung, die du dann auslösen\nwillst, zum Beispiel, um im Homescreen von Apps zu Apps zu kommen,\npraktisch die App-Screens zu swipen, mehr oder weniger, die funktioniert dann mit dem Handgelenk.\nDu hast praktisch, du guckst was an, dann machst du deine Finger zusammen und\nab diesem Zeitpunkt ist dein Handgelenk und deine Hand die Bedienung, nicht mehr das Auge.\nDas Auge ist schon wieder woanders und fertig, solange du deine Finger zusammen hast.\nUnd dann kannst du praktisch so nach links scrollen und loslassen zum Werfen,\ndann hast du so eine physikbasierte Scrollerei, wie du im iPhone und iPad auch hast.\nOder du kannst es halt in Ruhe loslassen.\nUnd das ist ein ganz interessanter Moment, weil du kannst halt wirklich relativ\ngenau mit dem Tracking von deinem Handgelenk dann steuern. Also das fand ich sehr gelungen in Summe.\nEs ist ab und zu, es gibt schon Fehlbedienungen, so ist es nicht,\naber es ist erstaunlich, wie fein du es machen kannst und auch wie du deinen\nganzen Körper dafür einsetzen kannst. Du kannst damit sehr genau steuern,\nwenn du willst. Also das Auge selber ist relativ grob.\nDas braucht relativ große Hit-Targets, wo du mal startest.\nAber wenn du da was in der Hand hast, dann kannst du wirklich,\nwirklich sehr exakt was machen, wenn du willst. bist.\nZur Not kannst du deinen ganzen Körper ein bisschen vor und zurück im Raum bewegen\nund deine Hand festlassen.\nUnd diese ganze Bedienerfahrung ist einfach so ein bisschen,\nda war ich sofort so Minority Report oder whatever.\nIt's the future, you got me.\nFür mich war das in der größten Ordnung von Bedienfreude, wie es jetzt wirklich,\nTouch-Bedienung war am Anfang auch, finde ich.\nUnd das ist auch nach wie vor, wenn ich das Ding aufhabe und mal eben mein Fenster\nirgendwo hin und sonst, das klappt einfach grundsätzlich. Das ist so smooth\nund so nett und so wenig Belastung für die Hände.\nDas stimmt.","Ich würde sagen, bei den Sachen, die so potenziell hätten schief gehen können,\nist das bei mir so Platz zwei Top-Liste, was so richtig, richtig gut funktioniert hat.\nDas ganze Handtracking funktioniert irre gut.\nUnd wenn es mal nicht funktioniert, dann hat es meistens was damit zu tun,\ndass du die Hände dann doch irgendwo hinter deinen Klamotten versteckst oder\ngerade deinen Kopf so hältst, dass die Kamera einfach die Hände nicht sehen kann.\nMan gewöhnt sich so sehr daran, dass es funktioniert, dass du dann,\nwas weiß ich, die Arme nach hinten hinter deinen Kopf legst und denkst,\ndu könntest jetzt irgendwie weiter klippen und pinchen und zoomen und so weiter,\nwas natürlich dann nicht geht.\nAlso du bist schon gezwungen, deine Hände vorne zu halten. irgendwo zumindest.\nDas ist dann fast schon ein bisschen enttäuschend. Da würde ich mir fast schon\nnoch so Kameras nach hinten wünschen. Ich will immer getrackt werden.","Ich will eigentlich zwei Uhren dran und dann sollten die einfach alles weiter\ntracken. Vor allem das Pinschen auch.\nDieser Unterschied, wenn du mit deinen Händen aus dem Blickfeld dann verschwindest,\ndas relativ groß ist und auch dadurch, dass die Kamera ziemlich weit nach unten\nzeigt, auch wirklich breit.\nAber dann ist halt der Weiser nicht mehr dass du die Hände noch zusammen machst. Kann er auch nicht.\nUnd dann wird es wirklich blöd, weil dann hast du halt so einen Touch,\nder hängen bleibt und so und das, ich weiß nicht, mir passiert das sehr viel,\nweil ich bin halt auch jemand, der,\nDinge immer extrem bedient so und mit dem Arm rudert und so und auch der halt\ngerne auf der Couch so lümmeln würde und dann die Hände sind hier so oben über\ndem Kopf hinten und kraulen und würden gerne tippen.\nUnd das geht natürlich dann nicht. Also müssen sie ein bisschen nach vorne sein,\naber die andere Hand, die vorne liegt, also man kann schon auf dem Schoß die\nHand liegen haben und dann tippen. Das geht.\nAlso man muss Man kann das sehr entspannt machen, was glaube ich auf Dauer für\ndiese Bedienung, für diese ganzen körperlichen Gebrechen, die mit Computerbedienung\neinhergehen, super wichtig sind, weil wenn man verkrampft sowas bedienen würde\noder ständig nur direkt touchen kann,\ndann würde es nicht gut funktionieren.","Das moderne Äquivalent, die Maus hat das Trackpad verlassen.\nDamals, als die Mäuse noch Kugeln hatten.","Also was auch interessant ist, so für einfache Bedienungen geht auch direkt Untouchen.\nAlso man kann praktisch den Tipp auch machen, meistens indem man auch tippt.\nAlso man kann praktisch auch näher an die Apps rangehen und dann die App antippen,\ndie man starten will. Das funktioniert.\nUnd man kann auch auf dem Zahlenfeld, wenn man jetzt den Pin eingeben muss, kann man den tippen.\nMan muss den nicht angucken und pinchen. was natürlich,\nSecurity-technisch eher schlecht ist, weil die Leute sehen dann, was du tippst.\nAber ich mache es schon ab und zu, muss ich sagen. Mir ist es ab und zu lieber.","Aber.","Das mit der direkten Interaktion ist definitiv ein bisschen mehr awkward,\nweil es schlechter funktioniert.\nSo im Verhältnis. Es hat so eine gewisse Latenz, eine gewisse Fadigkeit.","So, jetzt müssen wir natürlich auf die andere Sache noch eingehen.\nDas ist halt das mit diesen Fenstern.\nAlso alles, was du machst mit den Programmen, mit den Apps, was halt irgendwie\nInteraktionen sind, geschieht halt in Fenstern, die du dir irgendwie in den Raum legst.","Was ist denn ein Fenster überhaupt in dem Kontext?\nIst das eine Fläche? Ist das eine Kurve?\nDa musst du ja jetzt eigentlich schon beschreiben, was ist denn ein Fenster im Raum?","Ja, das versuche ich ja auch gerade zu beschreiben.","Das ist eine Fläche, oder?","Die ist eben. Abgesehen von diesem Home-Menü, was sozusagen überall schwebt,\nso im Raum, vor dir einfach nur die Icons in der Luft,\nhat alles andere schon so eine Fensterartige Verankerung.\nUnd wenn du halt jetzt, was weiß ich, Safari auswählst, dann geht halt ein Browser-Fenster\nauf Und das schwebt dann irgendwo gefühlt einen Meter vor dir.","Als hätte jemand ein Brett in der Luft gehängt.","Genau. Und es hat halt dieses transluzente Ding. Und das ist jetzt aber auch wirklich...\nMein absoluter Platz 1 an, oh mein Gott, was bin ich unfassbar beeindruckt davon,\nwie gut sie das hinbekommen haben,\ndas ist halt einfach, das Ding steht halt im Raum und damit meine ich, es steht im Raum.\nUnd wenn du halt mit deinem Kopf wackelst und wenn du irgendwie deinen Körper\nbewegst und deine Kamera hin und her wabbert und niemand sitzt still,\ndu hast immer Bewegung, immer schaust du irgendwo anders hin,\ndieses Fenster bleibt einfach immer an der Stelle und da wackelt nix.\nKein Jitter, kein Blitzen, kein Pixelflashen, kein irgendwie ja im Wesentlichen ist es schon da,\naber nicht immer, sondern das ist da einfach wie reingemeißelt in deinen Raum\nund das ist wirklich unfassbar.\nAlso das haben sie so gut hinbekommen.\nIch glaube, dass es auch, wenn sie das nicht hinbekommen hätten,\ndann hätten sie das Ding nicht geschippt, aber das ist wirklich genug.\nAlso ich war mehrfach erstaunt, wie gut das funktioniert und das ist halt die Basis.\nDas heißt, dann ist diese Illusion perfekt, dass du etwas in den Raum stellst,\ndass es halt da schwebt einfach so vor dir mit Schattenwurf und dann kannst\ndu es halt irgendwo hinlegen.\nUnd wenn du dann unten an dieses Fenster deinen Blick wendest und auch nochmal\ntappst, das ist halt auch das Ding.\nAlso du hast zwar immer dieses Eye-Tracking und man denkt sich so,\nnaja, ich muss immer alles nur angucken und dann tut es das.\nDas würde aber dann bedeuten, dass wenn du so hin und her schaust,\njedes nur irgendwie erdenkliche Interaktionselement immer auch sofort aufleuchtet,\nwenn du da mit deinen Augen drüber gehst und das würde natürlich stören und\ndeswegen ist es manchmal wichtig, dass du das auch erstmal aktivierst.\nWeißt du, hast du deinen Musikplayer, der zeigt dir dann so ein Cover an,\naber du siehst nicht automatisch, wenn du drauf schaust, einen Interface-Control\nfür Vor-Zurück-Spulen oder Pause oder so, sondern du musst es dann anschauen,\neinmal so ein Tab machen und dann erscheint erst dieses User-Interface-Element.\nWeil sonst würden ja permanent irgendwelche User-Interface-Elemente um dich\nherum aufpoppen und gleich wieder verschwinden und das würde dich wahnsinnig machen. machen.\nUnd genauso ist es, glaube ich, mit diesen Controls unten, oder die muss man\nauch manchmal aktivieren.","Ja, genau, man muss die Fenster ab, also gerade wenn man so einen Film guckt\noder so, da blenden sie sich manchmal aus, da muss man erstmal einmal tippen\nund die dann unten aktivieren, das verwirrt die Leute teilweise auch,\nweil schau halt stärker dahin, ist schon so ein Impuls, den man hat.\nAber es ist und manche, es ist auch noch ein 1.0 Produkt, das heißt,\nab und zu ist es auch so, dass die UI gar nicht erscheint Also wenn man es länger\nin Benutzung hat, ist es schon auch noch klar, das hat Kinderkrankheiten, aber das sind halt Bugs.\nWenn man von denen absieht, ist es aber so, okay, man muss das Fenster,\nwenn man es bedienen will und es hat kein Element zum Verändern oder zum Schließen,\ndann muss man wahrscheinlich einmal reintippen. Und die Elemente zum Verschieben\nund Bedienen sind relativ schlicht gehalten.\nAlso Fenster nochmal sind wirklich Flächen im Raum, die stehen irgendwie dreidimensional\nim Raum zu dir im Verhältnis und halt wirklich fest verankert im Raum in gewisser Größe,\nhaben abgerundete Ecken alle und haben, wie Tim schon gesagt hat,\nauch wenn du nicht die Immersion anhast, dann wirklich in dem Raum selber werfen\ndie einen Schatten am Boden.\nDu hast am Boden wirklich dann einen Schatten oder am Tisch oder wo auch immer die sind.\nWenn die geometrisch so im Raum stehen, dass sie den Schatten werfen können, dann tun sie den auch.\nDu kannst sie aber auch einfach durch die Wand irgendwie durchsetzen und dann\nhast du ein Loch in der Wand, das eigentlich für dich optisch keinen Sinn macht, aber ist okay. okay.\nAlso so eine Kinoleinwand kannst du auch hinter die Wand setzen und dann siehst\ndu dann eine ausgeschnittene Kinoleinwand. Das ist schon okay.\nUnd dieses Bedienelement unten ist relativ schlicht gehalten.\nDas heißt, man hat einen Strich, der\nso ein bisschen aussieht wie dieser Home-Button-Indikator auf dem iPhone.\nDieser Home-Button-Strich.\nUnd den kann man angucken und eben mit einem Pinch nehmen und dann kann man\ndas Fenster dreidimensional im Raum verschieben und positionieren,\nwo man es denn gerne hätte. und links daneben ist so einfach nur ein runder\nPunkt, der ist auch super schlicht.\nUnd wenn man den anguckt, dann wird es ein bisschen größer und wird ein X und\ndamit schließt man Fenster. Und das ist bei allen Elementen so.\nDas heißt, bis auf, also es gibt später auch noch andere Sachen als Fenster,\naber die haben eigentlich diesen Strich und diesen Punkt. Das ist so die.\nSo die Design-Sprache. Und dann gibt es eben noch eine andere Sache,\nwenn man in die Ecke guckt, rechts oder links unten, werden wir unten schon\ndiese Elemente sieht und das Fenster resizable ist,\nvergrößerbar ist, dann gibt es da praktisch so Anfasser an den Ecken,\ndie auch nur ein gebogener Strich sind.\nUnd diesen gebogenen Strich kann man angucken, nehmen und dann kann man halt\nresizen und dann hängt es wieder von der App ab, ob man das jetzt irgendwie\nso machen kann, dass es beliebig die Seitenverhältnisse ändert oder nicht,\naber es ist im Endeffekt so, in der Mitte ist das Ding\nfestgepinnt, da wo es im Raum ist und dann kann man es größer und kleiner ziehen in gewissen Ausmaßen.\nUnd was ich sagen muss, die Art und Weise wie, wenn man das Fenster unten am\nFensterrand verschiebt, die Art und Weise, wie sie das gelöst haben,\nist erstaunlich intuitiv und exakt.\nDas macht so richtig Spaß, diese Fenster im Raum zu platzieren und man hat überhaupt\nkeine Frage, was denn so Sache ist. Also die.\nReichweite, die man so auswählen kann, ist super. Also die hat praktisch so\nAlso die hat einfach, macht wahnsinnig viel Sinn und wenn es über die Grenzen\nhinaus geht, indem man es verschieben kann, dann kann man sich ja im Raum bewegen dann noch.\nDas heißt, wenn ich es dann noch weiter im Raum haben will, dann muss ich halt\ndann gehen ab einem gewissen Zeitpunkt.\nAber sie haben echt eine super Range ausgewählt, wie man die verschiebt und\nauch einen super Blickwinkel. Also die sind immer relativ senkrecht zur eigenen Sicht.\nAlso es sind Flächen, es ist nicht so wie bei der Quest 3 oder so,\ndass es gebogene Dinger sind.\nEs sind gerade Flächen, es sind brechen gerade, was bei größeren Fenstern auch\nein bisschen schwierig ist.\nAber ich glaube, es ist auch ganz ästhetisch sinnvoll, weil es einfach diese\nräumliche Interaktion viel klarer macht.\nUnd es ist so ein bisschen wie wenn man diese, es gibt ja so,\nwas waren diese 3D-Bilder mit den zwei Augen, die man so nach vorne und nach\nhinten schieben kann. So Stereoskopbilder, genau, die man dann so ein bisschen\nvor die Nase hält und vorneweg, so kann man sich das so ein bisschen vorstellen.\nUnd so verschiebt man da eben so virtuelle Dinger, aber da ist halt Inhalte drin.\nDa sind Spiele drin, da sind Personen drin, da sind Webseiten drin und da kann\nman sich so den Raumvolk leisten.","Ja, also das ist wirklich gut gelöst.\nIch kann ja auch nur zustimmen, diese Positionierung, diese Vor-Zurück-Bewegung,\num die Tiefe zu bestimmen,\naber dann eben auch so diese zweidimensionale Platzierung um einen herum und\ndu kannst sie halt auch überall platzieren, du kannst sie auch direkt über dir platzieren.\nKannst dich ins Bett legen und kannst irgendwie einen Film an der Decke schauen, wenn dir danach ist.\nUnd von daher hat man auf einmal einen unglaublichen Platz, wo man so Fenster hinlegen kann.\nWobei man auch sagen muss, diese Perspektiven, die sich daraus ergeben,\ndas ist dann halt auch nicht so, dass man sagt, jetzt habe ich so viel Platz,\njetzt kann ich hier 30 8K Fenster hinlegen.\nDeswegen, also abgesehen davon, dass jetzt die Auflösung der Kameras das natürlich\nso nicht hergeben oder der, nicht der Kameras, der Displays,\nder inneren Displays das überhaupt gar nicht hergeben würde,\nmacht es auch keinen Sinn, weil wenn die Dinge weiter weg sind,\ndann müssen sie auch irgendwie größer sein. Also das ist dann halt wie im richtigen Leben.\nÜberhaupt ist so die Menge an Content, die so in diesen Fenstern sind, ist so überschaubar.\nTrotzdem waren manche Sachen für mich fast auf der Vision Pro konsumierbarer als auf dem Computer.\nIch habe zum Beispiel großen Spaß daran gehabt, Webseiten zu lesen.\nAlso ich fand das Lesen von Webseiten, von so Artikeln,\nIrgendwie, weiß ich nicht, irgendwie angenehmer.","Spannend.","Also das habe.","Ich noch kaum gemacht bisher. Ich habe Safari so gemieden wie die Pest.","Gibt es da Tabs? Ja.","Wie meinst du das?","Naja, hat das Fenster Tabs. Achso, Tabs.","Willst du wissen, wie die optisch aussehen?","Nö, einfach nur, ob es sie gibt. Also ich meine...","Also es gibt den Mechanismus, der Tabs heißt ist und es sind frei schwebende\noben drüber ein paar und darüber hinaus sind es einfach dann mehrere Fenster\nim Raum, die du anders platzieren kannst.","Ja klar, dass du mehrere Fenster machen kannst, davon war ich jetzt ausgegangen.","Aber Oder du hast halt diese Tab-Galerie wie auf dem iPad dann auch irgendwie,\nwo du eher durch das Grid durchscrollst, anstatt dass du das andere machst.\nAber du hast auch oben so, glaube ich, drei oder vier maximal,\nweil du hast schon so eine gewisse, in der Grundauflösung kannst du dir vorstellen,\nhast du eher ein iPhone als ein iPad.\nVon dem, wie es von der Größe her auf dich wirkt.\nAlso das kann man nochmal jetzt vielleicht eingehen auch darauf,\nes gibt ja viele Systemeinstellungen und eins davon ist auch,\nwie groß deine Default-Fontgröße und deine Default-Fenster sind.\nUnd da gibt es halt ein paar Größen, aber es ist schon eher größer gedacht wegen\nder Bedienung, glaube ich, wegen angucken können und machen.\nDeshalb ist es eher so, Dinge sind ein bisschen größer.\nUnd deswegen brauchen sie auch mehr Platz und deshalb...\nSind sie weniger dicht. Also du hast jetzt nicht einen Mac-Interface normalerweise,\nsondern eher einen iPad und ich würde sogar sagen, sogar einen iPhone-Interface von der Grundidee her.","Ich habe jetzt gerade nochmal darüber nachgedacht, warum ich das eigentlich\nso angenehm gefunden habe.\nIch weiß, ich mache das auch, also ich habe ja hier einen sehr großen,\nbin jetzt auf so einen 40 Zoll Widescreen Monitor gegangen.\nEin großer Freund generell von Desktop und großen Bildschirmen und wenn ich\nan meinem 40 Zoller Webseiten lese,\ndann habe ich die auch meistens, die Schrift sehr groß,\ndamit ich also auch wirklich in so einem Meter Abstand von diesem Bildschirm\nweg sein kann und genieße das, dass einfach viel Fläche bereitsteht,\num den Text groß anzuzeigen.\nUnd es ist gar nicht so sehr dieses, dass ich das jetzt brauche wegen Brille\noder Sehschwäche oder so, sondern es ist einfach,\nich finde, dass ich weniger Aufwand leisten muss, den Text zu erfassen,\nwenn er groß und klar ist.\nDass ich weniger Fehlerkorrektur betreiben muss, als wenn ich das jetzt in so\neinem kleinen Font auf so einem sehr überschaubaren Bereich auf dem Bildschirm betrachten muss.\nUnd insofern ist diese Vision Pro dann eigentlich die perfekte Perspektive,\nweil du sitzt da gemütlich im Sofa,\nschaust so leicht nach oben und dann prangt einfach diese riesige Webseite vor\ndir wie so eine riesige Leinwand, wie so ein Beamer quasi.\nAlso du schaust auf einen Beamer, der bloß sehr scharf ist und ja,\ndas war dann irgendwie angenehm. Also ich habe das definitiv nicht als unangenehm\nempfunden, wenn man dann halt...\nSich ein Macintosh quasi als Fenster holt, da können wir ja vielleicht mal drauf\neingehen, jetzt dieser Aspekt, also es gibt ja diese Funktion,\ndu hast dann so dein Laptop vor dir, ich hatte so mein R und dann habe ich so\ndrauf geschaut und irgendwie haben sie halt so eine AI-Erkennung,\ndass sie A wissen über Handoff,\nokay da ist jetzt auch ein Mac mit derselben Apple-ID und so weiter da,\nda, aber sie erkennen halt den Laptop als solchen.\nAlso sie haben halt irgendwie eine, oder?\nGibt es da noch einen anderen Trick? Ich glaube, sie erkennen einfach Tastatur.","Oberkante Bildschirm ist schon ordentlich.","Die wissen einfach, da steht jetzt ein Laptop und sie wissen auch genau, in welcher,\nPositionierung und über dem Bildschirm erscheint dann halt so,\nmöchtest du dich damit verbinden und dann guckst du drauf, machst Tap und dann\ngeht der Bildschirm aus auf deinem Laptop, der ist dann schwarz und dann erscheint\nhalt da drüber irgendwie,\neben so so als Fenster im Raum,\neine 4K-Monitor-Simulation für deinen Computer.\nAlso da ist dann sozusagen auch mehr Platz.\nDa ist ein größerer Bildschirm als der, der jetzt auf dem Laptop ist.\nUnd die Fenster arrangieren sich halt entsprechend und das hast du dann vor der Nase.\nDas war dann der Moment, wo bei mir diese, das ist nicht der richtige Wort,\naber diese Tiefenschärfe, also die Schärfe, wenn es ein bisschen weiter weg\nist, ein bisschen nachgelassen hat,\nhabe ich es näher an mich rangezogen war es für mich besser zu erkennen aber\nwie gesagt, das mag einfach nur meine Optik sein,\naber dann habe ich halt versucht mit den Mac-Apps zu arbeiten und in irgendeiner\nForm zu interagieren und dann hast du natürlich auch wieder so einen kleinen\nMedienbruch, also auf einmal musst du dann deine Tastatur und deine Maus wieder benutzen,\nweil es ist ja ein Mac irgendwie so, dann ertappst du dich so ein bisschen dabei,\nso wie man Man anfängt auf dem Mac rumzutippen, wenn du die ganze Zeit ein iPad benutzt hast.\nMöchtest du dann die ganze Zeit deine Programme anstarren und wunderst dich,\nwarum die jetzt sozusagen nicht auf deinen Blick reagieren.\nAlso Eye-Tracking auf dem Laptop, hm.\nAlso das wäre auch so ein Feature, das könnte ich auch im Laptop gebrauchen,\nweißt du, dass man einfach so Eye-Tracking hat und dann mit den Fingern irgendwie,\nalso das fällt mir jetzt gerade erst ein, das wäre eigentlich ganz geil.","Leider nicht. Leider nicht. Also deshalb wollte ich es auch sehen,\nweil Apple was released mit Eye-Tracking, was funktioniert.\nIch habe den Luxus gehabt in diversen, ich glaube zwei, drei von guten Prototypen\nvon Eye-Tracking-Steuerung für Laptops.\nZu fummelig, zu kleinteilig, zu unangenehm. Also was Apple da gemacht hat, ist schon sehr gut.\nUnd du triffst nicht so genau. Also ein normaler Laptop-Screen hat einfach nicht nicht die Fidelity.\nDas wäre wie wenn du, stell dir vor, iOS hätte Mac-Auflösungen eigentlich und\nvon der bedienenden Größe her. So ungefähr ist das.\nAlso die Idee ist nicht schlecht, aber ich habe das in schlecht gesehen.\nDeshalb war ich ja so heiß drauf, es in gut zu sehen.\nUnd wie gesagt, die PC-Varianten waren alle schlecht bisher, die ich gesehen habe.","Ja, okay. Also ich habe ja nur gesagt, man hat dann wieder dieses Problem,\ndass so ein anderes User-Interaktionsmodell in dem anderen hast Und dann musst\ndu irgendwie da hinterher kommen. Kann man damit arbeiten?\nJa, schon, wenn es konsequent scharf gewesen wäre für mich, weil ich wollte\nden Bildschirm dann nicht so nah an mich ranholen.\nDas ist auch merkwürdig, was man als angenehm findet oder so.\nAlso wenn ich den so nah ranziehe, das Fenster, dass er quasi über meinem Laptop\ntatsächlich ist, also wenn ich es auf einen Meter Distanz mache,\ndann ist es mir zu nah, es ist mir zu aufdringlich.\nUnd dann habe ich es halt weiter nach hinten geschoben, dass es so ein,\nzwei Meter Abstand hat, wie so vor so einem Beamer.\nDann war es mir halt ein bisschen zu unscharf. Wäre das scharf gewesen, wäre es scharf gewesen.\nDann wäre es, ich weiß nicht, ist das bei dir so, wenn du so ein,\nzwei Meter gefühlten Abstand hast, siehst du das dann scharf?","Also es gibt für mich eine Distanz, wo es nicht mehr scharf genug ist auch.\nAlso ich muss den nah genug halten.\nIch habe den jetzt eher so als Standing Desk benutzt mit meinem Air meistens.\nUnd wenn ich die Default-Auflösung habe, dann kann ich ungefähr so zwei,\ndrei Tastaturbreiten kann ich es in die Tiefe setzen, aber dann wird es schon knapp.\nUnd wenn ich es näher ranhole an mich, dann ist das Problem,\ndann mache ich es meistens auch kleiner, weil ich will den Winkel nicht haben.\nUnd ehrlicherweise muss ich feststellen, für das Air unterwegs würde ich es\nwahrscheinlich benutzen wollen.\nUnd natürlich ist es geil, wenn du für die Vision Pro was entwickelst.\nDann macht das wirklich Spaß. Klar.\nAber wenn du jetzt einfach es nur als Monitor Ersatz haben willst,\ndann ist ein Monitor mir lieber.\nAber es ist eine notwendige Maßnahme für,\ndafür, dass man da sinnvoll arbeiten kann und für entwickeln auch.\nJa, also es ist spannend, es ist mit der Schärfe,\nich bin hin und her gerissen, Weil ich habe jetzt diverse Meinungen dazu gehört\nund ich finde grundsätzlich, man kann es als Display benutzen und es ist in\nseiner vollen Auflösung scharf, sobald man es nicht weit genug wegstellt von einem.\nWas ein bisschen, was immer funktioniert ist, wenn man die Auflösung runterdreht,\nalso wenn man die Auflösung einfach auf ein, zweiter unten dreht,\ndie ist super scharf, deshalb hat man von der Platzmenge jetzt nicht die Größe,\ndann hast du nicht so viel Gewinn, aber das geht gut.\nMan kann es auch, wenn man wirklich viel Platz braucht, auf riesengroß machen. Das geht auch.\nUnd dann ist halt so ein bisschen diese Unschärfe deutlicher erkennbar.\nIch finde es spannend. Ich habe am Anfang ja gemeint, der Anwendungsfall alleine wäre es schon.\nUnd das ist es für mich eher nicht. Ja, es ist ein Feature, das das System braucht,\naber es ist jetzt nicht was, es ist eher was, was es braucht,\nweil wenn der Durchblick nicht scharf genug ist, wenn der Durchblick scharf\ngenug wäre, dass das Display auch volle Schärfe hat beim Durchblicken,\nbräuchte ich nicht unbedingt.","Ralf fragt gerade im Chat eine interessante Frage und ich glaube,\nda müssen wir nochmal so ein bisschen klären, wie sich diese Fenster generell verhalten.\nDie Frage ist, kann man es nicht weiter nach hinten schieben,\naber dafür den Screen viel größer ziehen?","Grundsätzlich kann man.","Also es ist nicht so, dass es seine Größe beibehält in dem Sinne,\ndass es dann kleiner wird, weil es hinten ist.\nSondern wenn du etwas nach hinten schiebst, wird es automatisch größer.\nDas Fenster nimmt sozusagen immer denselben Bereich deines Gesichtsfeldes ein,\ndu hast immer denselben Winkel, ist es automatisch größer.\nHat aber auch denselben Content skaliert, aber es wird einfach aufgebläht.\nAlso das ist so ein bisschen wie bei Jim Knopf sozusagen, nur andersrum.","Der Scheinriese.","Der Scheinriese, genau. Wenn der in der Ferne ist, wirkt er total riesig und\ndann kommt er immer näher und dann ist er klein. Das ist genauso wie bei Jim Knopf.\nEin Scheinriesenfenster. Ein Scheinriesenfenster.","Und das Spannende ist, dass es trotzdem einen Unterschied macht.\nAlso dass das selbe Fenster, dass das selbe Platz in deinem,\nGesichtsfeld, Blickwinkel, was auch immer wir da jetzt genannt haben,\neinnimmt, wirkt anders, je nachdem, welche Distanz es hat. Ich weiß nicht genau\nund ich kann dir nicht genau sagen, woran es wie liegt.\nAber es ist trotzdem so. Ich justiere da immer wieder ein bisschen weiter weg,\nauch beim Kinofilm gucken und so weiter.\nIch positioniere das ist da, wo es angenehm ist und das ist immer ein bisschen anders.\nAlso es ist so, es macht alles einen Unterschied und es ist aber super spannend\nauch, weil wenn man zum Beispiel so einen Film direkt vor die Nase klatscht, hat auch was.\nEs ist nicht so nervig wie im Kino, aber es ist halt trotzdem Zunahme,\nhat so ein bisschen so das Gefühl, es ist einem zu nah und dann ein bisschen\nweiter weg, aber im selben Blickfeld, aber trotzdem zu flach. Es ist ganz anders.","Ralf fragt jetzt, sagt, bei der Quest 3 kann man das frei und unabhängig einstellen.\nAlso du kannst natürlich das\nFenster auch, wenn du es weiter nach hinten schiebst, noch größer machen.\nWobei Programme auch immer so mit Constraints daherkommen. Also es gibt immer\nso ein bestimmtes Maximum. Ich weiß nicht, ob das für alle Programme gleich\nist oder ob das Programm das definiert. Das habe ich nicht so ganz verstanden.","Alles, und da drehen sie auch noch drum herum. Updates haben das schon verändert\nauch, die Verhältnisse, wie das denn so geht.\nUnd du musst halt teilweise ein bisschen tricksen. Also du musst teilweise ein\nbisschen im Raum rumlaufen.\nAlso wenn du was größer haben willst, als jetzt gerade geht,\ndann geht das, indem du praktisch weiter weg gehst und es dann von dir weiter\nweg schiebst und dann wieder näher rangehst und so.\nAber das finde ich eigentlich einen ganz netten Modus, wie man damit umgeht,\nweil, wie gesagt, dieses Verändern im Raum ist so intuitiv, das macht einfach\nSpaß, das haben sie gut gemacht, das ist einfach eine geile Interaktion,\ndie sie da geschaffen haben.","Es ist irre, wie schwierig das ist, diese Effekte zu beschreiben,\naber Aber warum ist das Fenster gleich groß?\nAlso es ist halt wirklich dieser Jim-Knopf-Scheinriesen-Effekt tatsächlich und\nes macht einen riesigen Unterschied.\nWie weit es weg ist, auch wenn es irgendwie immer denselben Platz einnimmt. Das ist crazy.\nFenster können ja auch hintereinander sein. Also es gibt dann auch so Stacking-Tiefe.\nEs ist nicht so, dass ein Fenster dann exklusiv diesen Bereich hat.\nAlso es ist kein Tiling oder so, sondern du kannst da alle Fenster an dieselben\nStelle kloppen. Dann siehst du bestenfalls, was vorne ist.\nUnd es wird dann auch schwierig, die unterschiedlich zu managen und anzufassen\nund rauszusuchen. Also es ist dann genauso wie auf dem richtigen Schreibtisch,\nwenn die Zettel alle erstmal übereinander liegen, dann kommst du nicht mehr so ohne weiteres ran.\nAlso man braucht schon so eine gewisse Platzierungshygiene, aber das macht man\nauch irgendwie intuitiv nicht und du hast auch nicht so viel offen immer, glaube ich.","Ich frage mich, wie dann die ersten Fenster-Tiling-Hilfs-Apps aussehen.","Mit Big Privacy wird es die einfach nicht geben so insgesamt.\nDas ist halt so die andere Ecke, wenn man jetzt wirklich von der Entwicklerseite\nher möglichst freien Expressionismus haben will, was man denn alles machen kann,\ndann ist man auf anderen Plattformen besser aufgehoben, weil sie haben schon\nalles von den Entwicklern weggesperrt, was in irgendeiner Form Aufschluss geben würde,\nauf was man anguckt oder wie man das Ding bedient.\nAlso du hast ganz konkret wirklich, als App kriegst du nicht mit,\nwas angeguckt wird, sondern du sagst praktisch, okay, das ist ein Element,\nda kann der Benutzer drauf gucken und wenn der da drauf guckt, dann wird es geheiligt.\nDu kriegst aber nicht mit, dass es gehighlighted wird jetzt in dem Moment.\nDu kriegst auch keine Chance, dir das praktisch so zu merken.\nDu kannst praktisch in keinster Weise den Blick abgreifen, was aber eben auch\nEinschränkungen hat dafür, wie man Dinge dann gestaltet.\nUnd deswegen so Fenster-Teiling-Apps wird es nicht geben, weil das wird keine\nAPI vergeben. Da ist man auf der Apple-Seite so.\nEinige von diesen Dingen, die man gerne hätte, wird es da einfach nicht geben.\nGleichzeitig ist aber auch für mich das eines der größten Unterschiede,\nweil es ist ein in sich stimmiges.\nKonsistentes Bedienkonzept durch alle Apps, durch alles hindurch.\nWas für mich immer der größte Hinderungsgrund bei den ganzen VR-Brillen bisher\nwar, weil jedes Spiel funktioniert ein bisschen anders, jede Bediengesichte\nfunktioniert ein bisschen anders.\nBei der Quest gibt es einfach, klar kannst du auch Handtracking und so weiter\nhaben, aber es ist halt immer ein bisschen anders und du musst erst die App\nlernen, bevor du dann wieder was machen kannst.\nUnd das ist für mich so die Stärke von Apple und ich glaube,\ndas haben sie weit genug geschafft jetzt in diesem ersten Wurf, dass es spannend wird.\nAber das ist ja schon wieder viel zu weit.","Kommen wir mal so ein bisschen auf,\neinen anderen Aspekt, nämlich die Sache mit dem drei Dimensionen und dem Inhalt.\nAlso Content oder Oder wir müssen mal über Video und Filme und so weiter reden,\nweil das ist natürlich etwas, was sie auch pushen, zu Recht,\nwie ich finde, als ein mögliches Anwendungsszenario.\nDas ist ja immer die Frage, wofür taugt denn das Ding eigentlich?\nUnd man kann, glaube ich, getrost sagen, man kann da ganz gut Filme gucken.\nIch habe jetzt nicht viel Zeit mit Filme gucken verbracht, muss ich sagen,\naber ich habe das auch ausprobiert.\nEs gibt ja auch so einen speziellen Kinomodus da in dieser Geschichte.","Der ist super übrigens.","Ja. Achso.","Den braucht man dann auch.","Entschuldigung, wir müssen...","Die Environments hast du mir erwähnt.","Ja, wir müssen... Entschuldigung, genau. Es ist schwierig.\nEs ist wirklich schwierig hier die Linien zu machen, aber es passt im Prinzip auch noch mit rein.\nAlso generell hat man nämlich auf diesem Top-Level-User-Interface- Element nochmal\nso eine Dreier-Unterteilung.\nDas ist ja immer mal links von diesem Hauptmenü noch, oder wo war das mit diesen\nApps und den People und Environments, das ist doch so links so ein Steuerelement, ne?","Genau, das ist eins dieser Standard-Elemente, man kann praktisch an Fenster\nlinks, unten und rechts und oben so Zeug dran hängen, so andere Optionen und\nes ist mehr oder weniger wie so eine Tab-View links,\ndas ist ein Element von drei verschiedenen Tabs, mehr oder weniger von dem Homescreen\nund das erste ist Apps, das mittlere ist Leute und das untere ist Environments.","Genau, und das ist ist es schon mal sehr interessant, dass es sozusagen nochmal\nso eine Top-Level- Organisation gibt.\nDas entdeckt man auch erst nach einer Weile. Ich habe auch immer nach der FaceTime-App\ngesucht, um irgendwie jemanden anzurufen.\nAber das ist sozusagen so weit ins Betriebssystem aufgenommen worden,\ndass quasi diese Interaktionsmodelle ganz klar getrennt werden. Also einerseits,\nArbeitest du oder wählst du Apps aus? Du kriegst diese Oberfläche mit, hier sind deine Apps.\nDer zweite Tab auf diesem Level ist Personen und wenn du das auswählst,\ndann kommen halt Personen, mit denen du interagierst sozusagen und dann kannst\ndu die anrufen und kannst dann FaceTime damit machen. Da erzählen wir gleich nochmal drüber.\nUnd das dritte, das passt halt jetzt nochmal in dieses ganze Thema mit,\nwie ist denn hier eigentlich die Optik und so.\nDas sind diese Environments. Also das ist jetzt auch nicht irgend so ein Programmfeature\noder eine App, die man dann irgendwie noch installieren muss,\nsondern das ist sozusagen ein genereller Begleiter.\nUnd wenn man das halt anwählt, diesen Tab, dann kriegt man eine Auswahl von\nzwei verschiedenen Arten von Environments.\nDie einen sind so diese softe Variante mit, da kannst du nur so deine Lichtgestaltung mit beeinflussen.\nDu kannst sagen, ich möchte jetzt gerne morgen Licht haben, Abenddämmerung oder\nso und dann nimmt das sozusagen Einfluss auf das,\nwie alles gerendert wird und welchen Lichteindruck du hast, so ein bisschen\nso Nightshift-mäßig, mehr so Modifikator.\nAber das dicke Teil sind natürlich diese richtigen Orte, wo du,\nwenn du die dann auswählst, du halt in Teilen, je nachdem wie sehr du das mit\ndieser Crown reindrehst,\nkriegst du halt einen kleinen Ausschnitt oder eben alles um dich herum wird\nersetzt durch diesen virtuellen Ort.\nUnd dann sitzt du halt irgendwo am Rande von so einem See und blickst auf so\neinen Berg und du kannst dich umdrehen und nach hinten gucken und nach oben\ngucken und so weiter und überall, du bist halt auch einmal irgendwo anders.","Wie viele gibt es davon?","Nicht so viele, drei, vier, vier sind es.","Ne?","Eins ist Coming Soon.","Eins, zwei, drei, vier, fünf. Fünf.","Sag nochmal, das ist dieser Berg.","Es gibt den Berg. Dieser Joshua-Tree. Dann gibt es den Joshua-Tree, dann gibt es Yosemite.\nGibt es nicht auch noch den Mond? Genau, den Mond gibt es. Und dann gibt es Mount Hood.","Genau, Mount Hood.","Und dann gibt es noch...\nNe, White Sands gibt es auch noch, aber White Sands war so langweilig,\nda bin ich nicht geblieben.","Das ist alles eigentlich eher langweilig. Das ist alles so menschenfreie Gegenden,\nwo nicht viel, das ist jetzt nicht so New York oder so, sondern es ist Mond.","Aber es ist halt maximale Immersion. Das heißt wirklich, das ist eine Umgebung,\nda kannst du um dich rumgucken, die ist 3D, die hat eine Geräuschkulisse,\ndie hat eine Farbstimmung.\nUnd selbst wenn du gar nichts an hast und nur, ich gehe jetzt mal zum Beispiel\nin Yosemite rein und drehe mir den hier mal auf,\ndann bin ich halt jetzt so in so einer Nacht in der Wüste und das fühlt sich,\ndas wirkt schon sehr so, als wäre ich da.\nDas ist schon nicht schlecht. Und das ist halt gedacht einerseits,\num halt so einen Kontext zu haben und alles andere auszublenden,\nfür für eine Sache oder halt einfach wirklich nur so mal drin zu sein,\num sich ein bisschen zu entspannen, wenn man will.","Also, du hast jetzt gerade diese Kamera auf und unser Headset.\nMehr Cyber geht eigentlich gerade gar nicht.","Ich habe jetzt mal versucht, das über das Headset anzuziehen, das geht ganz gut.","Er müsste jetzt noch einen Datenelch reiten.","Aber ansonsten.","Aber er kennt euch nicht als Menschen, deshalb sieht man Eis halt nicht,\ndas Feature haben wir auch noch nicht erwähnt.","Ja richtig, oh Gott Aber jetzt immer.","Also diese Environments gibt's und es gibt beim Videogucken Warte mal kurz.","Zu dieser Immersion das muss man auch nochmal klar machen, du hast es schon\nangedeutet, also mit der Crown kann man sagen wir mal,\nreindrehen wie sehr bin ich jetzt in diesem Raum und das ist halt auf der einen Seite optisch,\naber es ist auch akustisch einerseits, dass wenn du die volle Immersion hast\nhast, dass du dann so einen Hintergrund-Sound bekommst von diesem Ort,\nder erst, glaube ich, so auf den letzten,\nDreh kommt.","Nee, der kommt schon relativ früh langsam rein und es ist sogar Hall, der also sogar die,\nakustisch.","Beeinflusst ist alles, was du tust. Das heißt, das, was du hörst, hörst du dann anders.\nAlso wenn ich jetzt mit mit Dom FaceTime machen würde Oder mit der Vision Pro.\nSo. Und ich bin in meinem Raum. Und ich höre ihn. Dann höre ich ihn wie in einem Raum.\nDrehe ich die Immersion rein, umso mehr ich in irgendeiner Wüste lande,\numso mehr verschwinden auch akustisch die Räume, also die Wände,\ndie dann keinen Schall mehr liefern und du hörst es sozusagen reflektionsfrei,\ndein Audio auf einmal.","Also auf gut Deutsch, die Brille macht eine Raumsimulation auch im Schall. Richtig.","Genau. Genau. Und auch von der Art und Weise, wie der Schall von den Apps,\ndie Apps haben ja auch ihren Schall praktisch so ein bisschen spatial im Raum platziert.\nDas heißt, wenn du was hast, was ein Video ist, dann hast du dieselbe spatiale\nOrientierung von diesem Video, wie du es auch mit dem iPad auch hast, wenn du das anmachst.\nUnd da wollte ich eben noch mal am Anfang hin, wenn du die Airpods Pro im Ohr\nhast, dann hast du halt den\nAutomatismus, dass es ist jetzt so spatial gerendert, wie es die Vision Pro\nvorhat und wenn du den Environment reindrehen, dann ist halt Noise Cancellation mit an auch und sowas.\nAlso du hast das nicht mehr so explizit, sondern du hast das schön integriert.","Das ist schon ziemlich awesome.","Wie klingt denn der Mond?","Wenig. Wenig.","Ja, du verlierst halt das Echo sozusagen.","Aber der Joshua Tree ist halt, also,\nder Wald und so, also ich hab mich schon mal, ich war irritiert von den Geräuschen\nab und zu, wo ich mich mal reingedreht hab, so Grillen zirpen und so.","Also wie geht's dir denn, wenn du in diesen Environments rumsitzt? Gibt dir das was? Ja.","Für mich ist es sinnvoll, wenn ich den Raum vergrößern will.\nIch mache die praktisch so ein bisschen halb oder so ein Drittel an,\ndamit mein komplettes vorderes Blickfeld auf meine Arbeitsfläche so ein bisschen\nausgeblendet ist, aber ich den Rest von meiner Umgebung sehe.\nDas finde ich dann ganz angenehm, weil dann habe ich praktisch nicht so diesen\nSuspension of Disbelief, wenn ich Fenster in die Wand stelle,\nweil da ist jetzt keine Wand mehr, da ist jetzt freie Gegend.\nFür sowas finde ich es wichtig. Und wenn man einen Kinofilm guckt,\nist es interessanterweise an der Stelle super wichtig.\nAlso der Apple-Kinosaal, der bei Apple TV kommt, der sonst gar nichts hat,\nalso auch wegen der Lichthelligkeit außenrum und so weiter und der Ablenkung,\nist der einfach wichtig.\nJa, also das Environment, das halt praktisch möglichst wenig ist,\naber trotzdem ein gewisses Raumgefühl hat, damit diese Wand,\ndie da in der Luft hängt, irgendwo verankert ist.\nAlso ich habe da 3D-Filme geguckt, Gravity, den ich auch im Kino gesehen habe\nund das ist halt so, da habe ich mir das Environment Kinosaale angemacht auch. auch.\nIch dachte immer, bei den anderen, also bei dem, was ich bei der Quest gemacht\nhabe, war das immer irgendwie ein bisschen albern und ein bisschen fad und so,\naber da hat es irgendwie gepasst.\nDas war so richtig schön, weil der Kinosaal ist schön schwarz,\nhat auch ganz wenig Ablenkungen dann und dann hast du halt so eine Kinofläche\nund du willst halt wegen dem Blickwinkel schon auch nur so einen gewissen Größe haben.\nDu willst ihn nicht viel größer machen, sodass du diese erste Reihe Erfahrung\nhast im Kino, weil da musst du deinen Kopf immer so bewegen und du willst halt\ngenauso weit weg haben, dass du mit dem linken und mit dem rechten Auge beide\ndie volle Fläche siehst noch.\nUnd dann brauchst du halt Environment außenrum. So geht es mir.","Ja, kann ich sehr gut nachvollziehen. Ich fand es auch praktisch,\nwenn man diese Immersion so bei 80 Prozent belässt.\nDas hat dann so den Vorteil, dass wenn man sich nach links und rechts dreht\nund so ein bisschen nach unten guckt, dann sieht man noch so,\nwo man sitzt und dann kann man noch so seine Sachen greifen und so weiter.\nAlso das reicht dann dann sozusagen komplett in der Immersion zu verschwinden,\nheißt auch so ein bisschen, den Kontakt zur Außenwelt zu verlieren,\nim wahrsten Sinne des Wortes.\nUnd das ist dann nicht unbedingt immer das, was man braucht.\nAber dadurch, dass man das eben durch das einfache Drehen dieser Crown jederzeit\nauch ändern kann und dass das so ein unmittelbares,\nkontextunabhängige Geschichte ist. Das ist schon eine sehr gute Entscheidung\ngewesen und das macht dann diese Environments einerseits noch nützlicher und\nandererseits erhalten sie dadurch meiner Auffassung nach auch erst die Legitimation\nso hoch auf Systemebene angesiedelt zu sein.\nSie sind einfach so ein ganz grundsätzliches Ding, was so dabei ist und du kannst\nes immer steuern und kannst es immer beeinflussen und kannst es immer dazuholen\noder wegmachen, wenn du es brauchst.\nOhne irgendwelche App- oder Menü-gestützten Klimmzüge zu machen.\nUnd dadurch wird es eigentlich erst so richtig nützlich.","Was ich persönlich ein bisschen strange finde, ist, dass es halt diese systemweiten Environments gibt.\nUnd Apps können auch Environments haben. Zumindest die Disney-Plus-Apps.\nIch weiß nicht, wie viele andere Third-Party-Apps auch.\nUnd ich hätte halt gerne die auch zur Verfügung für was anderes ab und zu.\nWeil das ist halt schon, also bei Disney-Plus gibt es halt so den Avengers-Tower, von dem man rausguckt.\nSuper geile Immersion an der Stelle. Also auch mit kleinen Details und Geräuschen\noder du bist halt in Star Wars in so einem Gleiter und bist halt auf einem Wüstenplanet so ein bisschen.","Ich hoffe, dass es für Third-Party die Möglichkeit geben wird,\ndiese Environments bereitzustellen.","Ah, Klingeltöne.","Ja, ja, das ist, also da zahlt man dann vielleicht dann wirklich gerne Geld für.\nAber ich glaube, das wird Apple erstmal nicht machen. Aber Apple wird mit Sicherheit\nnoch mehr liefern. Also das ist definitiv.","Steht da nicht sogar coming soon irgendwo? Ja, ja.\nJa, die sind halt nicht fertig geworden überall, aber es ist fertig genug,\ndass es ein sinnvolles Release ist, so ungefähr.","Obwohl ich mir das absolut vorstellen kann, dass ein Emergency-Bereich im App Store gut laufen würde.","Emergency?","Immersion.","Im Immersion-Bereich.","Emergency.","Emergency.","This is fine.\nJa.","Okay, aber kommen wir mal auf die Filme. Das ist schon interessant.\nAlso erstmal mal ganz normale 2D-Filme anschauen, ist super.\nAlso da gibt es, glaube ich, wenig dran zu meckern.\nIch habe auch heute gelesen, es ist sogar so, wenn du dir Filme anschaust,\ndie in Panavision aufgenommen wurden, dann hast du auch wirklich den Original-Kino-Aspekt-Ratio.\nAlso diese 70 Millimeter.","Das Fenster im Raum ändert sich Aspekt-Ratio auch noch in alle Richtungen.","Das heißt, du hast da keinerlei Clipping, keine schwarzen Balken,\ndas ist alles nicht mehr der Fall, sondern alles kommt sozusagen in seine,\nnatürlichen Aspektratio und damit kannst du dir einfach bestimmte Filme,\nalso viel weiß ich, Panavision war mal so ein großer Trend, ich glaube heute\nwird nicht mehr so viel damit gemacht.","Cinema Scope war doch auch so ein Ding.","Ja, das weiß ich aber nicht ganz genau, wie die sich zueinander verhalten tatsächlich.","Naja gut, ist im Detail jetzt vielleicht auch nicht wichtig.","Vielleicht nicht wichtig, aber doch ganz interessant.\nCinemascope, anamorphotisches Verfahren der Breitbildaufzeichnung.\n2,55 zu 1, später 2,35 zu 1. Mhm.\nOkay. Und Panavision ist dann nochmal anders.\nAlso auf jeden Fall sehr breit gestretchte Filme, sagen wir es mal so.\nAlso die schon fast so Panorama-Charakter haben. Das geht auf jeden Fall.\nUnd ohne jetzt sehr viele Filme geguckt zu haben, aber das ist irgendwie für\nmich klar wo ich schon total skeptisch werde aber das hat gar nichts mit der Vision Pro zu tun,\ndas sind halt die sogenannten 3D Filme und davon gibt es ja bei Apple TV und auch bei,\nDisney Plus so einiges die konnte ich mir allerdings nicht anschauen ich konnte mir das nur in einem,\ngehackten Filmchen anschauen das hatte damit mit zu tun, dass ich mit meinem\ndeutschen Apple-ID in so einer,\namerikanisch verankerten Vision Pro hing und dann bekam ich von diesen Apps\nnicht die richtige Regionszuteilung und dann haben sie mir immer gesagt,\ndas wäre jetzt nicht anschaubar.\nAlso ich konnte mir sozusagen im Disney, in der Disney-App und in der Apple-TV-App\nkeine Filme anschauen und deswegen auch die 3D-Filme nicht ausprobieren,\nsondern ich musste dann sozusagen auf,\nanderes Material geben, wo ich dann mit AirDrop ob ich tatsächlich einen Film\nauf die Kamera gelegt habe und mit so einem Partyplayer abgespielt habe.\nIch mag 3D-Filme, wie sie heute im Kino gezeigt werden, überhaupt nicht.\nIch finde es total überflüssig und vollkommen deplatziert. Mir gibt es gar nichts.\nDas ist halt auch kein 3D, sondern das ist ja nur ein 2D-Film,\nder dann manuell so Pepper-Cut-Aus-mäßig irgendwie an bestimmten Stellen nach vorne gezogen wird.\nMehr ist es ja nicht. Es ist nicht wirklich 3D-Messal.","Kommt immer ein bisschen drauf an, wie Sie ihn aufnehmen.\nBeziehungsweise, wenn Sie sowieso mit CGI die Effekte machen,\ndann können Sie die auch gleich in 3D machen.","Ja, könnten Sie, machen Sie aber nicht. Also generell sind die Effekte so.\nDu hast auch keine Stereoskopie wirklich da drin.","Ich hatte immer das Problem, dass über der normalen Brille auch noch die 3D-Brille\nzu haben halt irgendwie dann mal so richtig schlechtes Bild ist hinterher. Ja, aber gut.","Du hast ja Zugang zu dem Apple-TV-Kram und so weiter, also sag doch mal was zu den 3D-Filmen.","Naja, also sie wirken auf alle Fälle gut im Sinne von, wenn du die im Kino magst,\nmagst du die in der Brille auch oder noch viel mehr in der Brille.\nAlso Gravity zum Beispiel ist halt schon auch ein prädestinierter Film für diesen\n3D-Effekt, weil dann bist du halt im Weltraum zwischen der ISS und dem anderen\nund drehst dich und das ist alles sowieso keine Orientierung,\naber 3D und da bist du halt voll drin und das ist toll.\nAber ansonsten ist es für mich eher ein Gimmick so, ja, es ist halt ein bisschen\neine Tiefe da drin ist es es wirklich wert?\nNee will ich es lieber haben, wenn ich mir mit der Vision Pro einen Film angucke und es gibt ihn in 3D?\nSchon, aber so aber es ist nicht wirklich wichtig also so, eigentlich hat es\nflach auch was smootheres, weil gerade so diese aus diese verschiedenen Ebenen\nund wie diese 3D-Sachen so gestaltet sind, sind auch ein bisschen ablenkend nur und machen es jetzt,\nwie gesagt, bei Gravity sehr gut, für manche ist es ich glaube,\nAvatar wird auch Sinn machen, weil es halt für 3D gedacht ist und so das Medium\ndementsprechend benutzt würde, aber es sind halt wenige, also ich würde jetzt\nnicht ich würde mir selbst Mario nicht in 3D gucken.","Ich sag dir mal, warum ich es nicht mag und warum ich das bei diesen Doku-Sachen sinnvoller finde.\nAlso, das Problem ist, dass dass sie ja nicht wirklich dieses 3D verwenden,\num es wirklich dreidimensional aussehen zu lassen.\nSondern sie verwenden ja 3D eigentlich, um Aufmerksamkeit auf bestimmte Szenen zu lenken.\nAlso klar, das ist dann schon das, was im Vordergrund ist. Aber es ist halt ...\nEs wird einem das, was näher ist, viel zu sehr aufgedrängt, sodass wenn du dich\nauf etwas im Hintergrund mal konzentrieren möchtest, also deinen Blick schweifen\nlassen willst, du die ganze Zeit an diesen vorne, hinten Stufen lang polterst.\nIch empfinde das einfach als unangenehm. Das mag anderen Leuten anders gehen,\nich kann dem überhaupt nichts abgewinnen.\nAber ich hab dann, Entschuldigung, ich hab dann, oder willst du darauf kurz?","Ja und zwar ist es ja so, dass die Physiognomie des Menschen so ist,\ndass die Augen ja nur einen geringen Abstand haben und eigentlich ist es so,\ndass du durch die echte Stereo-Sicht der beiden Augen einen 3D-Effekt nur so weit hast,\nwie du mit der Hand noch anfassen kannst.\nAlles was darüber hinaus ist, der 3D-Effekt ergibt sich nur noch durch Größen\nund weil das Hirn da so ein mentales Modell zusammenbaut, aber du siehst,\nwas weiter weg ist in der echten Welt ja nicht mehr als echt 3D.\nDeswegen frage ich mich auch immer, was wollen denn die Filme von mir?\nWollen die mir irgendwie, keine Ahnung, irgendwie Dinge direkt vor das Gesicht halten oder so?\nDas will ich ja nicht. Also ich habe irgendeinen Star Wars Film in 3D gesehen,\nda rennen die um das eine Raumschiff rum und plötzlich hast du irgendwie da\ndiese Ecke von dem Flügel irgendwie in der Fresse und denkst dir so,\nLeute, das hat jetzt nicht gebraucht.\nIrgendwie, weißt du so ich finde es so fürchterlich unsinnig, weil ne, also ein Spiel,\nwas vor dir auf dem Tisch steht, was dann auch wirklich 3D wäre wie,\nweiß ich nicht eine Lego-Burg oder irgendwas das ergibt für mich viel mehr Sinn als so ein Film.","Also ganz ehrlich Sehr guter Punkt und ich bin dann auf anderen Content umgestiegen,\nden konnte ich mir dann anschauen und wieso konnte ich mir den eigentlich anschauen und den anderen nicht?\nJetzt weiß ich es gerade gar nicht mehr. Diese Dokus konnte ich mir anschauen.","Welche Dokus?","Na, Apple hat so zwei, drei, das muss bei Apple TV gewesen sein.","Du hast dann eigentlich im Gastmodus die noch angeguckt oder so.","Ach so, ja, richtig. Auf dem eigenen Ding wahrscheinlich. Genau,\ndeswegen. Ich habe dann die Brille im Gastmodus noch mal betrieben.\nDa hatte ich dann sozusagen Zugriff, aber da war dann nicht mehr Zeit für große\nepische Filme anschauen.\nAber dann habe ich mir so ein paar kurze Dokus angeschaut, die Apple produziert\nhat, eben mit dieser stereoskopischen Kamera, mit der sie jetzt auch so Sport\nund so weiter aufnehmen, da müssen wir auf jeden Fall auch nochmal drüber reden.\nUnd ich weiß nicht mehr ganz genau, also die eine, die mir jetzt auf jeden Fall\nsofort in Erinnerung ist, ist dieses Highline. Das hast du gesehen?","Das habe ich gesehen.","Also das ist sozusagen...","Das muss man schon abkönnen.","Ja, also das also erst mal, die Frau ist irre, also das ist so ein Mädel,\ndie macht so Highlining, also die läuft über eine.\nWie nennt man denn das? Einfach über ein Seil, über eine Schlucht.\nUnd die Schlucht ist sozusagen zwei Vorsprünge, bildet sich durch zwei Vorsprünge\nan so einem norwegischen Fjord, wo es dann so einen Kilometer runter geht gefühlt.\nUnd während sie also über dieses Seil balanciert, also nur einmal so gesichert,\nwenn sie runterfällt, dann hängt sie halt an so einem Seil, aber jetzt hat nichts\nin der Hand oder irgendwie so, kein Ballonstängel oder sowas.\nSondern macht das einfach so und das ist eine kurze Doku, 10 Minuten vielleicht,\n20 Minuten vielleicht auch, sehr intensiv, schön gedreht und da gelingt es,\ndiese Tiefe, die unter ihr ist, diese Schlucht auf eine Art und Weise einzufangen,\nwo ich schon sagen musste, okay,\nnow you have a point.\nAlso das war wirklich anders, als es jetzt in so einer normalen zweidimensionalen\nDarreichung gewesen wäre.\nDas ist natürlich schon so speziell auch und man muss sehr großen Aufwand treiben, okay,\naber dieses wirkliche, echte Welt dreidimensional aufnehmen und dann eben nicht\nso ein gefaktes Ding wie beim Film, sondern eben wie es eben wirklich ist.\nDas kommt wirklich geil rüber.\nEs gibt dann noch dieses andere Ding mit dieser Alicia Keys.\nDie in ihrem Studioraum mit anderen Musikern ist und da so eine Aufnahme macht.\nDas geht auch so zehn Minuten.\nDa haben sie tatsächlich drei oder vier Kameras im Raum platziert mit der Zeit,\nwann hast du mal von der einen Stelle zur anderen Stelle. Also nicht jetzt flüssiger\nÜbergang, sondern schneidet dann einfach auf eine andere Kamera um.\nUnd dann kannst du dir halt das\nGeschehen so anschauen, als wärst du halt dabei, könnte man jetzt sagen.\nWobei ich irgendwie nie so richtig das Gefühl los gewesen,\nnie das Gefühl los geworden bin, dass für mich wirkte das alles so ein bisschen\nwie ein Aufenthalt im Wachsfigurenkabinett.","Wo sich aber alle bewegen. bewegen. Das ist so ganz interessant.\nBei dem Alicia Keys Ding hat man so ein bisschen so einen Effekt bei der Slack\nHighline nicht, fand ich, weil das war halt eine Doku, die so gemacht war dafür.\nDu bist jetzt einfach nur in der Situation, war es ein bisschen künstlicher\nund vor allem deswegen, weil du bist ja in der Perspektive gefangen.\nDu kannst dich ja zwar drehen, aber du kannst sie nicht bewegen und du willst\nja gerne mal nach vorne oder nach hinten und dann fährt die Kamera halt so ganz komisch mit.\nDas ist totaler Brainfuck, wenn man das macht. Also man muss relativ ruhig sitzen\noder sich halt irgendwann darauf eingelassen haben, dass sich die Perspektive\nnicht ändert, wenn man sich seine Chips greift. Ähm,\nDas ist so ein bisschen schräg. Deswegen funktioniert für mich auch die Extra-Doku\nviel besser als die Alicia Keys Nummer. Und es gibt noch eine dritte Tier-Doku.\nDie funktioniert für mich auch nicht so gut, weil sie ein bisschen es übertreibt.","Mit diesen Rhino-Zurosten und so.","Genau, die sind mir ein bisschen, da ist mir das 3D wieder zu stark.\nAlso das Problem bei diesem gefilmten 3D, dem real gefilmten,\nist so, passt dieses 3D zu meiner Vorstellung von 3D?\nIst es so oder nicht? Und das ist bei dem Rhino-Zurosten immer nicht so sehr, bei der Slackline ja.\nUnd da finde ich es auch wirklich cool. Und bei der Alicia Keys ist es,\nich mag das Format, ich würde mir wahrscheinlich auch, wenn ich von Künstlern,\ndie ich auch noch mag, würde ich mir das auch angucken, weil es halt ein Erlebnis\nist. aber es hat so seine Grenzen. Es ist schon ein Gimmick.\nDas ist für einen Zweck und das ist auch besser, wenn es nur eine Viertelstunde\nist als eine ganze Stunde. Also ich will das auch nicht abendfüllend.\nIch will das in kleinen Happen.","Genau, und da sieht man jetzt, das ist schon mal sehr interessant, diese,\nunterschiedlichen Darreichungsformen mal sehr genau zu unterscheiden.\nAlso wir haben natürlich den 2D-Film, der ist wie immer.\nDann haben wir diese Schein-3D-Filme, da sind wir uns einig,\ndas ist es irgendwie nicht.\nDann haben wir diese, Man nimmt reale Szenen auf,\naber immer aus festen Perspektiven und das bedeutet, du kannst halt nur exakt\ngenau die Position nachvollziehen, die eben die Kamera in dem Moment gehabt hat.\nKlar, du kannst, willst aber irgendwie auch immer, weißt du,\ndu stehst da und denkst dir so, ah, jetzt steht sie aber so ein bisschen verdeckt,\njetzt gucke ich mal ein bisschen nach links und dann ändert sich da irgendwie\nnichts und das ist irgendwie doof.\nUnd das ist dann sozusagen eigentlich der nächste Schritt, also die vollständige\ndreidimensionale Immersion von so einem Content, der ja eigentlich dann nur\nin Echtzeit gerendert werden kann, wie das eben bei diesen Games ist,\ndie aber dann sozusagen vielleicht,\neine richtige Handlung haben. Also dass aus Computerspielen ein Film wird,\nder dir komplett gerendert wird und zwar immer aus der Perspektive,\ndie du gerade einnehmen möchtest.","Und das gibt es ja auch, aber halt nur stilisiert. Da gibt es zum Beispiel von\nArte einen Comicfilm, der auch als App verfügbar ist, so wie früher beim iPad\nauch die Bücher als einzelne Apps verfügbar waren.\nDas ist so ein Ich-bin-für-den-immersive-space designter Film im Comicstil mehr\noder weniger Und ich finde da Stadt in groß, in klein und so weiter.\nHabe ich mir den ersten Teil nur angeguckt, weil ich finde es ein bisschen anstrengend.\nDas ist halt so eine Kunstform, die kann man so schon machen.\nJa, und da kannst du auch wenigstens frei rumgucken.\nAber du bist halt auch trotzdem den Künstlern ausgesetzt, was die damit machen.\nAlso mir persönlich macht es am meisten Spaß, glaube ich, so ein kurzer,\nimmersiver, so wie bei der Slackline, wo du noch zumindest nicht drehen kannst,\naber du weißt, was du machen kannst oder nicht.\nOder eben auch so Kino-3D-Filme, die dafür gedacht sind, was ich hier im Text\nauch gelesen habe, die Pina zum Beispiel, die Pina Bausch-Doku.\nDa sind es auch geile Perspektiven, die gewählt wurden, um diese Tanzauftritte\nzu filmen und da hilft 3D auch, weil du hast halt so eine Tanzbewegung, die halt einfach davon,\ndie gewinnt dadurch, dass du ganz nah an der Bühne bist oder an dem Geschehen dran.\nAlso wiederum Dokus über Kunst, wo du das mitbekommst, finde ich ganz gut.","Naja, sagen wir mal so, manche Spiele haben ja Cutscenes, die so lang sind und\nin denen man sich auch bewegen kann.\nDie kommen deiner Idee dann schon relativ nahe. Man müsste sie halt dann in 3D machen.","Jetzt ist natürlich die Frage, was wird da noch, also was man noch dazu sagen\nmuss, diese Dokus sind mit 180 Grad Kameras gedreht.\nAlso du hast halt auf der einen Seite, das muss man immer unterscheiden,\nalso auf der einen Seite haben wir diesen stereoskopischen Effekt und den gilt\nes für sich zu bewerten. und das andere ist die Tatsache, dass du auch 180 Grad Aufnahmewinkel hast.\nDas heißt, du schaust dir diese Doku an und kannst halt auch nach links und nach rechts schauen.\nUnd oben und unten. Und oben und unten, also du kannst woanders hingucken in dieser Halbkugel.\nDu kannst nur deine Position nicht ändern, aber das ist schon mal ganz gut.\nTrotzdem frage ich mich halt, warum sind es nur 180 Grad,\nWeil man dreht dann schon so mal den Kopf ganz nach links und wenn du halt so\nnormal sitzend deinen Kopf drehst und schaust, dann hast du halt mehr als 180 Grad.\nDas heißt, du siehst dann eben auch the end of the video.\nDa ist dann halt irgendwie schwarz, diese Übergänge sind dann immer so blurred.\nDas ist generell eigentlich ganz gut gemacht. Das ist dann auch später,\nwenn man selber Filme aufnimmt und so weiter, die werden auch alle mit so einem\ngeblurrten Rand gemacht.\nDas hat nicht so klare Kanten, sondern es ist immer alles so reingeghostet.","Naja, willst du denn den Typen, der die Kamera hält, willst du den dann tatsächlich\nsehen, wenn du dich umdrehst?","Naja, nee, aber 210 Grad wäre geiler so. Also so in dem Bereich ein bisschen mehr.\nDiese ganze Frage ist natürlich jetzt auch, was könnten jetzt sozusagen interessante\nvideografische Angebote werden?\nUnd was natürlich auf dem Tisch liegt und was Apple ja auch schon macht,\nalso wo man jetzt schon weiß, dass sie das tun, ist Sport.\nSport interessiert die Leute. Sport findet auf großen Flächen statt.\nSport hat geschehen an vielen Stellen.\nWenn man nur mal schaut, was beim Fußball mittlerweile für einen Aufwand getrieben wird.\nWird und im Falle von Apple ist es so, dass sie jetzt wohl auch bei Basketball\nEvents mitfilmen, auf diese Art und Weise,\nund sie haben auch jetzt diesen Ticketpass, den sie ja schon längere Zeit verkaufen für die amerikanische,\nFußballliga, also die Soccer, nicht American Football, sondern die MLS, die,\nMajor League Soccer heißt das, aber ich sage halt Soccer dazu.\nUnd jetzt kann ich dann nur darüber spekulieren, was sie da tun.\nAber sie werden vermutlich dort auch ein Videoangebot machen bei dieser Major League Soccer.\nAlso sie werden das mit Sicherheit mit ihren stereoskopischen Kameras,\nso wie sie diese Dokus machen, werden sie jetzt auch diese Sportevents machen.\nUnd das Ganze hat nochmal eine andere interessante Dimension,\nweil beim Fußball, also in Spanien ist es zum Beispiel so, da werden ja heute\nschon die Spiele oder zumindest manche Spiele, die großen Vereine.\nIn der ersten Liga, in der La Liga, werden ja mit sehr viel Kameras aufgenommen\nund damit meine ich nicht so acht oder zehn, sondern um das ganze Spielfeld\nherum eine ganze Batterie von Kameras oder zumindest um die Tore herum.\nIch weiß nicht ganz genau, wie das an den Längsachsen aussieht.\nUnd es gibt ja mittlerweile schon so Replay-Mechanismen, wo du dann quasi so\neinen Matrix-Bullet-Time-Effekt hast.\nDas heißt, du hast eine Torszene, Flanke kommt rein, Stürmer steigt hoch,\nköpft den Ball ins Tor. Das wird aber dann aufgenommen von 20 oder 30 Kameras,\ndie natürlich alle Zeit synchronisiert sind.\nDann kannst du das in der Wiedergabe so machen, dass du halt erstmal die Person\nfokussierst, die halt diese Flanke gibt.\nDann geht die Flanke rein und während sozusagen diese Flanke zu dem Stürmer fliegt,\nwechselst du deine Betrachtungsposition zu hinter dem Tor und siehst dann quasi\nden Stürmer in dem Moment schon den Ball direkt in deine Richtung köpfen.\nUnd das sozusagen alles als flüssiger Übergang, weil dann eben die Software\ndann auch diese Zwischenbilder entsprechend noch gerendert bekommt aus diesem\nganzen Ding, was halt zu so einem kompletten 3D-Modell umgebaut wird.\nKeine Ahnung, wie viel Processing-Aufwand das hat. Was ich damit nur sagen will ist,\nder Aufwand, der für den Sport getrieben wird, ist heute schon sehr hoch,\num solche scheinimmersiven Effekte zu erzeugen und wenn man das Ganze jetzt\nauch noch mit stereoskopischen Kameras kombiniert, wird es natürlich noch irrer,\nweil du dann eben dieses ganze Geschehen auch wirklich dreidimensionaler wahrnehmen kannst.\nUnd im Falle von Fußball würde ich fast sagen, könnte das sogar richtig was\nbringen, weil dieses Problem.\nDass man bei langen Bällen nicht genau sieht, fliegt der Ball jetzt gerade in\nder Kerze einmal nach oben oder nach unten oder fliegt der gerade 80 Meter in\nderselben Achse nach hinten. Du kriegst diese Tiefe irgendwie nicht hin.\nIch weiß nicht, ob das dann mit einer Vision Pro auf einmal besser gelingt,\naber das wird auf jeden Fall ein sehr interessanter Bereich sein,\nden es hier noch zu erforschen gibt, wie man das so bringen kann.\nJa,\nfällt dir noch was ein zu Thema Video und Filme?\nSonst könnten wir auch noch mal kurz über Fotos reden.","Ja, Fotos und die eigenen Geschichten halt, finde ich interessant.","Genau, aber erstmal hat man ja seine Fotobibliothek, die kann man sich natürlich\nanschauen, das ist jetzt nicht weiter spannend mit der Ausnahme von Panoramas. Findest du?","Du findest es nicht weiter spannend Ich finde die Fotos so groß,\nso scharf sehen zu können, macht schon Spaß Ich hab selten mehr Spaß gehabt\nmeine Fotolibrary durchzugucken einfach nur so,\nDie sind halt lebensgroß, du stehst halt vor den Fotos und du hast halt relativ\ngute Fotos von den Leuten, also sind die Auflösungen gut genug Und das ist schon\neine andere Größenordnung,\nob ein Porträt jetzt vor dir steht oder ob das klein auf dem Monitor ist Also\nich hab damit mehr Spaß gehabt und auch zum ersten Mal habe ich mir Memories dann auch angeguckt.\nWeil die Memories in groß finde ich schön.","Okay, ja, guter Punkt. Na, ich war jetzt besonders von den Panoramabildern beeindruckt,\nweil die wiederum auf dem iPhone anzugucken ist halt so, ja,\nscroll, scroll, scroll, ganz nett irgendwie.\nVielleicht gibt es irgendwann mal eine schönere Methode, sich das anzuschauen\nund das ist halt hier gegeben, Weil dann klickst du halt auf diesen Panorama-Button\nda oben und auf einmal wrappt sich sozusagen dieses Bild um dich herum und du\nkannst dann in der Mitte drin stehen.\nUnd ich hatte jetzt gerade auch noch so ein paar Panorama-Bilder jüngst bei\nmeinen letzten Reisen aufgenommen.\nSo Italien, Blick aufs Wasser, Neapel irgendwie über die Stadt und so.\nUnd das war dann schon sehr genau so, wie ich das dann in dem Moment auch abgespeichert hatte.","Das fand ich auch. Also Panoramas waren schon mal so eine Größenordnung und\nich hatte auch, so bevor ich nach Amerika ausgewandert bin,\nUnd damals nochmal eine Bekannte auf Teneriffa besucht, die ist da aufgewachsen\nund die hat mich da ein bisschen rumgeführt und da habe ich ein paar geile Panoramas gemacht.\nUnd dadurch, dass es ein eigenes Panorama war auch noch, war es halt wirklich\nauch so diese Kombination von ich bin wieder dort.\nUnd zwar wirklich so, ich stehe jetzt an diesem Aussichtspunkt von dem Vulkan\nauf Teneriffa und ich bin sofort da.\nUnd dass es nicht 3D ist, war mir gänzlich wurscht, ehrlich gesagt.\nAlso wenn ich eins machen werde in Zukunft dann von Positionen,\naus denen sich Panoramas ergeben, optisch sinnvoll, werde ich welche aufnehmen,\nweil das ist wirklich toll.\nUnd das hat damit zu tun, dass man selber auch an der Stelle war,\nweil ich habe auch wirklich geile, hochauflösende Panoramas von sonst irgendwo\nruntergeladen, um sie mir anzugucken, weil ich die so gut fand.\nDas wirkt einfach nicht so sehr. Oder auch, was schön ist schon auch,\nmeine Schwester war im Urlaub gerade und hat ein paar Panoramas geschossen und mir geschickt.\nMan hat schon einen Eindruck davon, aber die eigenen Erlebnisse so wahrzunehmen ist es schon nochmal.\nUnd es ist also Panoramas angucken, also zum ersten Mal so, dass ich denke,\nPanoramas sind geil anzugucken auch, weil halt Panoramas ansonsten immer nur\nzu viele schwarze Balken oben und unten haben, egal mit was man es irgendwie anguckt.","Jaja, man bereut sofort nicht schon sehr viel mehr Panoramas gemacht zu haben in seinem Leben.\nAlso das macht wirklich einen riesigen Unterschied. Und das.","Ich habe hier 230 Panoramen auf dem Phone.","Viel Spaß.","Allerdings sind da auch Fotos dabei, die halt einfach von der Aspect Ratio so\nsind, dass das Phone dann meint, das muss jetzt ein Panorama sein,\nobwohl es ganz offensichtlich nur Text ist. Ja.","Ja, hat sein Für und Wider. ich finde es ganz gut, dass du praktisch nicht so\nbesondere Metadaten brauchst, damit es in der Kategorie landet,\nweil dann verpasst du auch keine und brauchst nicht Magic,\nweil zum Beispiel bei den Immersive-Fotos, da brauchst du wieder irgendwelche\nMagic, dass du diese 3D machen kannst in irgendeiner Form.\nZwei Fotos, die gleich heißen, kannst du nicht einfach reindonnern.\nDas wäre auch schön, dass man so, ich habe nämlich so 3D-Content und ich weiß\nnoch nicht, wie ich den reinbringe, so dass ich ihn angucken könnte,\nweil da kommen wir nämlich zu anderen Geschichten so,\nsie kann ja jetzt 3D-Fotos, die Vision Pro, aufnehmen und anzeigen. Ähm,\nUnd die Frage ist, ist es das wert bei den 3D-Fotos, weil es ist halt wie immer\nso, ich habe ja damals sogar mal eine App gemacht, die mit dem iPhone 3D-Fotos\naufgenommen hat, mit so einer Apparatur, dass du an der iPhone-Kamera, Poppy hieß das Ding,\nzwei Prismen dran machst und dann praktisch ein bisschen das aufspiegelst,\nsondern in einem Bild so eine Stereoskope Bilder hast, gemacht hast,\nda war damals die Auflösung gerade so gut genug, dass das 3D-Bild,\ndas da rauskam, Sinn machte.\nHabe ich hier auch noch die Prototypen davon und die App, die ich geschrieben habe.\nAber die kriege ich jetzt da auch nicht rein. Aber es ist halt auch so ein bisschen\nso diese 3D-Bilder, wie die Panovision.\nEs hat schon was, aber es ist halt auch immer weniger aufgelöst und es ist so ein bisschen schräg.\nIch weiß es nicht. Ich habe ein paar gemacht jetzt, aber...","Meinst du jetzt die Fotos oder die Videos?","Die Fotos. Die Fotos.","Kann die Vision Pro den Hochkant-Panoramen?","Hochkant-Panoramen? glaube ich nicht, weiß ich nicht.","Weil ich habe so ein paar, wo ich halt das Panorama von unten nach oben gemacht habe.\nWenn du vor so einem Turm stehst oder so und dann das Panorama aber von unten\nnach oben machst, sodass du den ganzen Turm drauf hast.","Keine Ahnung. Ich würde mal vermuten, nein, aber don't know.\nJa, also das mit dem Aufnehmen, also die Videos hatten hatten keine wirklich\nbeeindruckende Qualität, glaube ich.\nAlso ich bin mir da nicht so ganz so sicher, um ehrlich zu sein.\nUnd die Wiedergabe war bloß so strange, weil du nimmst nicht so einen Kasten\nauf mit so einer klaren 16 zu 9 Kante oder sowas, sondern das ist irgendwie so...\nWie soll man das beschreiben? Also du gibst das wieder und dann hat das alles so ein,\nWolkenrand.","Es hat so ein bisschen einen fassigen Rand. Es ist eigentlich ein quadratischer\nAusschnitt, sowohl bei den 3D-Fotos als auch bei den Videos, die man aufnimmt.\nZumindest wenn man sie mit der Vision Pro aufnimmt, weil man kann ja auch mit\ndem aktuellsten iPhone Videos aufnehmen, die haben ein bisschen anderes Seitenverhältnis.\nUnd die stellen es grundsätzlich in so einem Kasten da, wo du praktisch ein\nbisschen, also im Verhältnis zu deinem Fenster im Raum.\nDu guckst da praktisch ein bisschen durch und kannst deshalb ein bisschen seitlich\nalso sie haben es ein bisschen so gemacht, dass es so ein bisschen wabert,\nwenn man seitlich rumguckt, damit es auch diesen Stereoskop Effekt ein bisschen mehr hat.\nUnd du kannst auch da wieder reinzoomen, auf Immersive machen,\ndann ist es so ein auch ein bisschen seltsames Erlebnis, weil halt die Auflösung\nnicht so super dolle ist.\nGleichzeitig ist es, wenn du es selber gemacht hast, also gerade das Video,\nist es ist es schon das hat was ja.\nJa, das stimmt ich habe auch heute nochmal versucht in Vorbereitung von der\nSendung eins zu nehmen, wo ich jetzt die Treppe runter laufe und dann mal raus\ngucke und dann mal Klavier spiele um das so ein bisschen um mal so eins zu haben,\nwo man ein bisschen was ausprobiert,\nes ist aber schon mehr ein Gag als wirklich cool, glaube ich also ich hätte\nglaube ich schon gerne so Aufnahmen von meinem Kleinen,\naber gleichzeitig will ich nicht mit der Brille von meinem Kleinen so rumherfeln\nalso dem habe ich das jetzt auch noch vorenthalten weil der soll ja überhaupt\nnicht so viel mitbekommen das ist mir zu creepy,\nPapa wieder mit seinem VHS Videokamera,\nalso ich muss aber sagen da.","Wären wir jetzt auch nochmal gleich zu kommen ist ja immer die Frage,\nWozu kann man das eigentlich gebrauchen? Ist das jetzt nur so eine Technologiedemonstration,\nist das so ein Gimmick oder ist das vielleicht für irgendwas gut oder gibt es\nzumindest Leute, für die das eine besondere Bedeutung haben kann?\nUnd dieses dreidimensionale Fotografieren und dieses dreidimensionale Video\naufzeichnen, das mag zwar jetzt noch nicht perfekt sein,\naber die Möglichkeit das überhaupt machen zu können ist natürlich für bestimmte\nAnwendungen unter Umständen wirklich geil.\nAlso ich denke halt gerade so, wenn man so Veranstaltungen macht und so Location\nScouting macht oder du bist so auf Wohnungssuche und schaust dir Wohnungen an\nund dann versuchst du irgendwie zu fotografieren und irgendwie dir zu merken, wie das ist,\nweil du nur sehr wenig Zeit hast, das zu begehen.\nJa, so eine Wohnungsbegehung zum Beispiel.\nDa würde ich mir, also wie ich es jetzt sozusagen hätte, dann würde ich mir\ndieses Teil aufsetzen und da einfach 3D-Video-Capture-Button drücken und dann\nda einfach mal 10 Minuten lang durchlaufen und das komplett aufnehmen.\nWeil wenn du dir das dann auf der Brille wieder anschaust, dann kriegst du einfach\nso ein gutes Gefühl für die Weite und die Räume und was wo ist und was miteinander da ist und so.\nEs ist ein bisschen schwierig, sich zu sehr bewegte Rumlaufvideos auch anzuschauen.\nDa muss man aufpassen, dass man da nicht so ein bisschen wonky wird.\nMir ist nie schlecht geworden jetzt bei der Brille, aber es ist schon so.\nAlso da kann ich mir schon vorstellen, dass hier die Brille auch wirklich eine\nunmittelbare Anwendung hat für bestimmte Leute.\nWeil das halt einfach die optimale Quick-and-Dirty-Dokumentation von Situationen ist.","Was ist eigentlich mit 360-Grad-Kameras?\nDas, was die ausspucken, kann man die sich auch mit der Brille angucken?","Ja, da gibt es auch Certify-Apps davon.\nDa kannst du so 360-Grad-Dinger kannst du ein paar dieser Formate dann angucken.\nAlso Files funktioniert ganz ordentlich auf der Kamera und da kannst du in Files\nentweder SMB oder was auch immer anbinden und dann hast du halt da den Input\nfür deine Apps und es gibt zwei oder drei von diesen VR- und 3D-Apps.\nAlso wenn du was hast in irgendwelchen Formaten, die es geht,\nklappt es auch. Ich habe diese Daten nicht.\nUnd da YouTube noch keine eigene App hat, ging es da auch nicht.\nUnd die Side-by-Side-Videos, die ich so hatte, die braucht nochmal Pre-Processing,\nist auch nochmal nervig.\nDa bin ich noch nicht firm genug, auch in welchen Formaten man das direkt angucken kann.\nWeil man will schon, also den Content, den man herkaufen kann,\nder funktioniert sofort, als es ist.\nUnd der macht dann schon in dem Sinne Spaß.\nDass es sich selber zusammen gebastelt, ist halt so eine Sache.\nAlso es gibt eine App, die ganz gut funktioniert.\nDie hat Star Trek alle Brücken oder so von allen Enterprises.\nUnd da hast du halt so eine VR-Ansicht.\nUnd auch das ist ganz nett. Das macht schon auch Spaß.\nDa drin zu stehen.","Ja.\nSo, was haben wir denn noch?\nIch glaube, wir müssen über,\nFaceTime und diese Personas reden.","Ja, über iSight haben wir auch noch gar nichts fallen lassen,\naber das haben wir auch nicht so viel.","Das stimmt.","Das gehört da auch irgendwie ein bisschen dazu, also bei der Immersion.\nAber ich habe den Anwendungsfall noch nicht so gehabt, weil ich habe die meistens so oft gehabt.","Anwendungsfall für was jetzt?","Diese Situation, wo du die Brille aufhast, aber mit Leuten interagieren willst\noder kannst und dann dadurch, dass die sowohl die Leute durch die Immersion\ndurchgehen, also wenn du.\nAlso vielleicht nochmal kurz erklärt, wenn wir es noch nicht oft genug gesagt\nhaben an so einer Stelle, wenn man sich so ausblendet mit der Crown und dann\nso ganz einbettet in irgendeine Experience in der Apple Vision Pro,\ndann ist es so, wenn Menschen auf dich zukommen, mit dir reden wollen,\ndann machen die so ein Loch dadurch und man sieht die trotzdem.\nAlso man wird nicht komplett aus seiner Immersion rausgeworfen,\nsondern es ist so, okay, die gucken dann aus der Wolke raus.\nDa wird einfach ein bisschen aufgemacht, wenn die einen angucken und reden.\nUnd umgekehrt ist es so, dass die wiederum auf der Vision Pro Außen,\nauf der Stiebrille, so eine Andeutung von Augen sehen,\ndie deine Augen sind. Das kommt dann gleich mit der Person nochmal raus.\nAber die halt eigentlich so blurry sind und so ein bisschen,\ndass sie nur eine Andeutung sind.\nAber dadurch sehen die halt, okay, du siehst die auch. Und dadurch kannst du\ndiese Interaktion machen.\nIch habe es jetzt selber nie in so Kontexten verwendet, wo das relevant gewesen\nwäre. Ich habe mir die Augen mal im Spiegel angeguckt, weil da funktionieren die auch.\nUnd die sind so, ja, sind schon okay. okay, also ich finde die weniger kontrovers,\nals die Leute meinen, dass das nichts...\nEs ist halt, es ist ein Indikator, es ist wichtig in irgendeiner Form für diesen\nAnwendungsfall und es wird immer wichtiger, je mehr es von diesen Vision Pros\ngibt und je mehr die normal eingesetzt werden.\nAlso das werden wir in Zukunft noch sehen, glaube ich.\nJa. Aber es ist halt so ein Feature, das sehr unik ist hier.\nUnd sehr belacht wurde im Vorfeld, aber ich finde es okay.\nAlso es ist so, das ist ein okayer Weg, weil es geht halt intuitiv, ist es klar.\nWenn da Augen Rausgucken, auch wenn sie ein bisschen creepy sind Das ist halt\ndie Person Alles andere, was so indirekt wäre Mit einer Leuchte,\nsonst irgendwas Würde nicht funktionieren, weil da müsste man Jemandem was erklären erst an der Stelle.","Interessant ist ja auch, wie das Setup Dafür funktioniert, da musst du ja dann die Brille Abnehmen.","Also für die Persona jetzt.","Ja Ja, ist ja nicht nur für die Persona Sondern es ist ja auch für diese Eyesight.","Auch, genau, aber es ist ein Vorgang. Also du machst die ja nicht extra.","Genau, aber damit sozusagen deine Augen überhaupt mal reproduziert werden können,\nmuss es ja Fotomaterial geben sozusagen von dir,\nweil es gibt ja keine Kameras, die jetzt auf deine Augen gehen und sozusagen\ndie wirklich jetzt filmen, sondern sie werden ja nur simuliert und.\nDazu musst du halt vorher durch diesen Persona-Prozess gehen der dann eben auch für diese,\nja Persona heißt ja, sind diese quasi diese Avatare, die angezeigt werden wenn\ndu jetzt mit jemandem Facetime machst und du hast diese Vision Pro auf,\ndazu nimmst du die Kamera halt ab und dann musst du,\nda reingucken, den richtigen Abstand haben, du siehst dann so ein bisschen,\nsiehst so ein bisschen aus wie so ein Teletubby,\ndiese Sonnenbaby bei den Teletubbies.\nDie Sonne, wo so ein Baby in so Sonnenstrahlen drin ist, so sieht das so ein\nbisschen aus, wenn du das Ding vor dich hältst und dann,\nsiehst du erstmal quasi per Video so deinen Minikopf in der Mitte von dieser\nBrille und musst den dann sozusagen auch im richtigen Abstand halten und wenn das dann so weit ist,\ndann machst du deinen Kopf nach rechts und nach links und nach oben und nach\nunten und dann musst du einmal Einmal lächeln, einmal lächeln mit Zähne,\nAugenbrauen heben und dann Augen zumachen und das war's.\nDas sind sozusagen die Positionen, die dann erfasst werden und daraus berechnet\nsich halt auf der einen Seite das, was außen an der Brille zu sehen ist,\nwenn Leute dich anschauen und dadurch, dass sie ja dann auch noch so ein,\nwie heißt dieses Gitter, was sie da haben, dieses...\nAlso das Glas ist ja dann nochmal so angeschliffen, dass du tatsächlich in jede\nRichtung noch ein anderes Bild abgeben kannst, wie bei so Wackelbildern.\nDas heißt, wenn dich einer von links und von rechts anguckt und so weiter, dann.","Lentikular, Lentikular.","Genau, lentikulare Linse, irgendwie sowas.","Also so eine Oberfläche halt, wie bei so einem Wackelbild.","Genau.","Genau das.","Und das ist schon irgendwie auch alles wieder ziemlich beeindruckend, wie das eben so ist.\nUnd ich kann dir auch mal so ein Foto teilen irgendwie von mir mit diesem Ding drauf hier.\nEs ist nicht besonders hell, aber in manchen Situationen ist es gut zu erkennen.","Bei dir funktioniert es sogar erstaunlich gut. Also ich habe es oft so ein bisschen\nvon dem Blickwinkel her, dass es halt ein bisschen daneben ist.\nAlso das war zu hoch oder zu niedrig oder so bei Leuten gehabt.\nAber bei dem war es jetzt gut. Bei dem Foto.","Ja, muss ich wieder Kapitelmarkenbild machen. Ja, unbedingt.\nDoch, das ist doch alles Arbeit. Genau, und dann kommen wir im Prinzip auch zu diesen Personas.\nIch meine, klar, du hast halt so eine Brille auf dem Kopf, klar kannst du in\ndem Moment kein richtiges Bild liefern und deswegen rendern sie das sozusagen\nund der Aufwand, den sie hier wieder getrieben haben,\nder ist bemerkenswert, weil es glaube ich etwas mehr Aufwand ist,\nals man vielleicht denkt,\ndenn was machen sie jetzt, also ich rufe jemanden per FaceTime an,\nUnd dann erscheint quasi mein vollständiges Gesicht animiert auf Basis dieses\nFotos oder dieses Recordings, was sie vorher gemacht haben, womit sie wahrscheinlich\ndann halt dreidimensional mein Bild abgetastet haben,\nmein Gesicht abgetastet haben und eben Fotos davon gemacht haben in verschiedenen\nZuständen, sodass sie dann eben auch Mundbewegungen simulieren können.\nEinfach nur aus, du hast mal gelächelt, zweimal, irgendwie das war's.\nUnd während du halt dann jetzt mit jemandem redest, und da musst du mir jetzt\nmal weiterhelfen, Dom, was du denkst, wie sie das machen.\nAlso wie machen sie diese Mundbewegungen? Das sind ja schon die,\ndas sind die richtigen Mundbewegungen, die man in dem Moment auch wirklich macht\ndurch die Kameras nach unten, oder?","Genau, die nach unten Kamera ist sehr weitwinklig, die sieht den Mund.","Und die Augen sind nachgebildet auf Basis des Eye-Trackings.","Ja. Und die Augenbrauenbewegungen, weiß ich nicht, wie die die machen.\nDie finde ich eigentlich am interessantesten.","Stimmt, die sind ja auch noch mit dabei.","Die müssen ja irgendwie die Augenbrauen auch innen drin schon ein bisschen filmen,\nabgreifen irgendwo. Weil das ist ja nicht Eye-Tracking. Das ist ja dann irgendwie\nso die Augenbrauenpartie.","Welche Auflösung hat denn die Eye-Tracking-Kamera und vor allen Dingen welchen Blickwinkel?","Weiß ich nicht.","Keine Ahnung.","Also wahrscheinlich sind die Augenbrauen mit auf der Eye-Tracking-Kamera drauf.","Nein, nein, nein. Die Augenbrauen sind ja komplett hinter der Brille verschwunden.\nDu machst doch deine Glubschis da in diese Höhlen rein, da bleibt doch von den\nAugenbrauen nichts übrig.\nIch glaube, dass sie das einfach aus der Bewegung der Augen ableiten.\nAlso das, also wie auch immer, es ist totale Magie. Das ist das, was ich sage.","Es ist super, dass du dir das Augenbrauen...","Es ist totale Magie und klar sieht es irgendwie erstmal creepy aus,\ngar keine Frage, aber wenn du dir\nmal vorstellst, was sie da alles zusammenbringen, um das überhaupt zu tun.","Also mal ganz ehrlich, ich habe jetzt schon ganz lange und ganz viele von diesen\nVideospielen gespielt, wo man so seinen Charakter machen kann und wo alle versuchen,\nautomatisch irgendwas zu machen.\nAlso, dass Apple in der Lage ist, so eine Qualität abzuliefern auf dem ersten\nWurf, hätte ich denen nie zugetraut. Also auch von dem, wie es aussieht.\nUnd es ist auch wirklich gefühlt State of the Art gerade, was so geht für so\neinen Scan, den wir mal eben schnell aus der Hüfte schießen.\nAlso, ich habe eher das Hutabgefühl.\nInsgesamt Uncanny Valley, ganz klar, da kann man noch viel machen,\naber ich hätte nicht geglaubt, ich hätte mit Lächerlichkeit gerechnet und es\nist einfach eigentlich schon cool.\nEs ist ein bisschen uncanny, aber es ist schon cool. Und es hat halt wahnsinnig\nviel, also die Art und Weise, wie es dann eingesetzt wird in Facetime,\nda kommen wir auch gleich nochmal dazu, die macht es halt nochmal so viel runder.","Also ich finde, es sieht so ein bisschen so aus, wie ich mir das vorstelle,\nwie Evangelikale sich das vorstellen, wie sie im Himmel sind.\nAlso dieses sehr Geblörte mit dem weißen Hintergrund und so.\nEs ist schon so, lebst du noch oder weiß ich nicht, facetimest du schon?","So, aber interessant, also mehrere Sachen sind interessant an der Geschichte.\nDie eine Sache war, wir haben ja Videos aufgenommen mit der Vision Pro und,\nAber nur mit dem eigenen Capture, mit dem Knopf. Ja, weil Apps sehen den Videostream\nnicht, den du selber siehst. Die dürfen das nicht.\nDu kannst keine Bilder machen mit der Apple Vision Pro.\nThat doesn't work for you as App Developer.\nWas du kriegst, ist der einzige Videostream, der als Rückwärtskamera gilt.\nAlso ich habe ja auch diese Tageslicht-App, mit der man auf dem Apple TV was\nstreamen kann, eine seiner Kameras.\nUnd die kann man auch dafür verwenden. Und da kommt dann der Avatar.\nAlso diese Persona kommt da praktisch, also auf der Selfie-Kamera ist immer\nder Avatar und das ist das einzige Video-Input, das die Apps haben können aktuell.\nNur FaceTime selber kann auch Screensharing machen, aber das ist FaceTime selber,\nkeine Third-Party-App da auf das.\nUnd das heißt, da läuft halt dieser Avatar einfach und der funktioniert super cool im Raum.\nAlso der ist so, je nachdem wo jetzt das Gegenüber beim Facetime steht,\nman hat also für Facetime, wenn man in der Apple Vision Pro Facetime macht,\nkriegt man ein Fenster, also ein Fenster, das dann aus mehreren.\nUnterfenstern besteht, mehr oder weniger, mehreren Untervierecken,\naber das ist so eine Ebene, die man irgendwo im Raum platziert und dann hat\nman dadurch einen ganz klaren Punkt, wo man Leute angucken kann und wo man praktisch\nauch sogar mit den Leuten interagieren kann.\nAlso einerseits kommt deren Audio aus deren Richtung, das macht es nochmal räumlich und wirklich klar.\nDie Mikros von der Apple Vision Pro sind glasklar.\nDadurch, dass sie irgendwie so viele weiß ich nicht, so viele Processing-Mikros haben wollen.\nEs ist ein FaceTime-Call, mit der klarste Gesprächs-Call mit der Apple Vision\nPro, den ich den ich je gehört habe. Also das ist wirklich super angenehm.\nUnd dadurch, dass du die im Raum hast an der Stelle, kannst du halt auch mit denen interagieren.\nDas heißt, deine Hände, wenn du auf die Leute zeigst, werden eingeblendet bei\nFaceTime vor der Persona an der Stelle.\nWenn du dich wegdrehst, drehst du dich halt auch weg von der einen oder anderen.","Also sehen die anderen, wen du anguckst?","Die sehen, dass du halt wegguckst. Also dass du nicht sie anguckst,\nmehr oder weniger. Und du drehst dich immer in dieselbe Richtung weg.\nAlso wenn du in einem Dreiercall bist und weißt, wer die andere Person ist,\nhast du schon ein Gefühl dafür, wenn die andere Person, also dass es jetzt die\nandere Person ist, die angeguckt wird, ohne dass es Arbeiten ist oder Wegsein davon.\nAlso alles, alles das macht FaceTime und das macht es schon auch erstaunlich gut.\nDann mit diesen Mimiken und Abtastungen, die halt ein bisschen uncanny sind,\naber doch sehr genau, passt es schon sehr gut.","Ja, es ist schon wirklich Strangeland, aber cool.\nEs ist schon irgendwie cool.","Das Strangeland.","Und wenn man jetzt nicht so drin ist in der Geschichte, finde ich auch spannend.\nIch habe meine Eltern angerufen und die haben es erst mal nicht gemerkt.\nAlso die hatten es halt irgendwie auf dem Laptop. Die haben eh selber die schlechte\nWebcam in die andere Richtung und hatten halt irgendwie schlechtes Licht.\nDie haben, also ich habe das denen gesagt, dass das jetzt, also die haben gesagt, neue Frisur.\nSo. aber bis sie dann gecheckt haben, dass das wirklich eine Persona ist oder\nhalt ein bisschen creepier, hat es gedauert.\nUnd ich glaube, das darf man auch nicht unterschätzen.\nDas ist, glaube ich, schon sehr adäquat und das wird auch noch viel besser.\nSelbst mit dem nächsten Update wird es wieder besser und da ist noch viel drin.\nFür mich ist, die Zukunftsfragen sind sehr spannend, was dieses Gerät angeht,\nweil ich weiß nicht, wann wir da hinwollen, noch nicht, wir sind noch nicht ganz durch.","Ja, bei FaceTime gibt es ja noch so einen anderen Aspekt, weil du kannst ja\naußerdem auch noch dein View,\nden du hast, sharen, quasi Screensharing und damit anderen Leuten einen Eindruck\nvermitteln, wie das vermutlich so gerade ist, was du so siehst.\nAlso du kannst auch was weiß ich per Airplay auf dem Fernseher und dann kannst\ndu halt sich zumindest mit Leuten darüber unterhalten, was du da gerade tust,\nweil sonst kriegt ja keiner mit, was du siehst.\nWobei dann halt so PIN-Eingaben und so weiter, die erscheinen dann da nicht.\nAlso das ist halt auch wirklich interessant, da muss ich mich erstmal dran gewöhnen.\nImmer wenn man nach einem Passwort gefragt wird und man gibt sein Passwort an,\ndann steht das Passwort da im Klartext und da erschreckst du dann erstmal.\nSo, oh, der Computer zeigt das Passwort ein, während ich das eingebe. Das geht doch nicht.\nAber es sieht ja keiner. Es sieht ja auch keiner.\nAlso irgendwie habe ich das komplett verstört, dass irgendwie Passwort,\ndas sind immer diese runden Bubbles, die ich da eingebe.","Ja, man hat auch keine Vorstellung davon, wie ein Passwort ausgeschrieben aussieht.","Das soll mein Passwort sein?","Guckt man das so an, so, hä? Hä?","Das hab ich noch nie gesehen.","Eine Sache, die wir noch gar nicht erwähnt haben, ist, irgendwie ist das Ding\nja auch gesichert und das macht einen Iris-Scan und hat Optik-ID,\nalso nicht Face-ID und nicht Touch-ID, sondern deine Iris, deine Augen.\nUnd an sich funktioniert das super, finde ich. Also das braucht ein bisschen,\naber es klappt dann, also geht einfach automatisch und ist genauso wie die anderen IDs von Apple.\nGrundsätzlich ist ein bisschen das Problem, wie gesagt, wenn man das Telefon\nnicht unlocked hat und die Brille auf hat, dann kann man das jetzt nicht mit\nder Brille, mit deinem Optik-ID unlocken im Moment. Das ganze Ökosystem ist\nnoch nicht komplett rund.\nAber so grundsätzlich läuft es wie bei Face-ID.\nDas heißt, du musst noch ein, wenn du was kaufst oder so, musst du noch einen\nextra Input geben und das ist in dem Fall auf den Auslöser drücken. so.\nAlso nicht auf die Crown interessanterweise, sondern auf den Auslöser, um es zu bestätigen.\nUnd ansonsten ist es halt wie andere Biometrie-Geschichten bei Apple auch. Genau.","Ja, interessant wird es natürlich jetzt,\nAb wann wird es so eine Art 3D-Sharing geben? Weil du sharest ja nur eine 2D-Ansicht\nsozusagen von deinem View gerade.\nUnd was man eigentlich möchte, ist natürlich gemeinsame dreidimensionale Räume teilen.\nIch bin mir gar nicht so sicher, ob das so trivial ist.\nWahrscheinlich nicht, weil wenn du jetzt sozusagen, also man könnte ja sagen,\njemand anderes steigt per Immersion.\nAlso ich könnte zum Beispiel deine Ansicht jetzt bei mir als Immersion reindrehen.\nDas wäre zum Beispiel eine Vorstellung so.","So Immersions-Sharing oder was?","Naja klar, also ich wache.","Dom ruft mich an.","Ist mit mir verbunden und sagt so, hier ist mein Raum, den die Kameras jetzt\nerfassen und der ist dann bei dir aber quasi Immersion.\nAlso ich kann den sozusagen Doms Raum, auf den er gerade schaut,\nkann ich mir so einblenden, als wäre das jetzt hier Mount Hood. Gut.","Wäre an sich kein Thema. Müsste ich mich einmal im Kreis drehen,\ndann hätte er genug Informationen, um das rüber zu schicken.\nSo fertig. Wird kommen, glaube ich, in irgendeiner Form.\nEs ist halt wahrscheinlich nicht hübsch genug, deshalb mag es Apple nicht.\nAber grundsätzlich wird es gehen.","Aber das stelle ich mir cool vor. Du stehst vor dem Eiffelturm,\ndann drehst du dich einmal und rufst jemanden an. Hier, guck mal.","Das ist die andere Geschichte, die ich gerne hätte. Ich würde gerne praktisch\nin der 3D-Ansicht einfach von anderen Brille-Seiten fertig.\nGib mir halt das, was du aufnehmen würdest in deinem Immersionsvideo direkt\nals Stream. Das hätte ich gerne als Erlebnis.\nWas ja schon kurz davor ist, du hast es halt nur flach.","Ja und dann halt die Personas in 3D, aber da wird es wahrscheinlich gleich dreimal\nan, Kenny Oder sind die Personas schon an sich dreidimensional.","Das ist ja schon so Du kannst nicht nach links und rechts gehen Ich hab mal\nversucht meine Personheit zu verbessern und hab dann,\nich hab gerade lange Haare und ich hab mal,\nweil die Frisur so komisch aussah, hab ich die nach hinten gehalten und dann\nwar meine Schulter praktisch so und da war diese Schulter als 3D-Geschichte\nin dieser Persona mit drin und mein Arm hing da immer so irgendwie ab,\nwenn ich meine Hände gezeigt habe, es sah ganz creepy aus.\nAlso die haben so ein gefühltes 3D-Modell von deinem Oberkörper schon mit dem,\nwas sie erfassen, weil die Finger und Hände haben sie ja dann auch, wenn sie anzeigen.\nAlso es gibt schon von dem, was sie sehen, es könnte auch mehr sein und interpoliert\nwerden dann und da gibt es viel, aber was es halt überhaupt nicht gibt, ist,\nzusammen interagieren in irgendeiner Form, also sich gemeinsam einen Film angucken,\ngeht angeblich mit Shareplay, habe ich noch nie ausprobiert,\naber dann siehst du ja die andere Person nicht, dann schaust du nur denselben Film zur selben Zeit.\nSo, du bist jetzt nicht in so einem gemeinsamen Erlebnis, so wie es bei Facebook\nund Quest schon länger geht, auch wenn es ein bisschen gimmicky ist,\naber sowas gibt es halt im Moment gar nicht auf der Plattform.\nUnd ich weiß auch nicht, ob da bald was kommt.","Naja, bei Apple haben dann wahrscheinlich die Leute aber von Anfang an auch Beine.","Das wäre zu hoffen, ja.","So, aber das FaceTime-Erlebnis war schön so per se und Audio,\nfandst du Audio nicht auch klasse?\nAlso ich fand halt schon so die Audioqualität, die so die der so abgreift und Ich hab jetzt nicht.","Glaube ich, nicht so viel FaceTime gemacht, um da wirklich mir eine Meinung\nbilden zu können, aber audiotechnisch habe ich sowieso überhaupt nichts auszusetzen an diesem Gerät.\nAlso das war alles tippitoppi. Jetzt haben wir schon ganz lange über die Vision Pro geredet.\nWir können jetzt vielleicht nochmal so Apps, also es gibt ja abgesehen von dem\nStandardkram, gibt es ja auch noch ein paar Apps, die vielleicht schon mal so\nein bisschen zeigen, wo jetzt das frühe Interesse von Entwicklern liegt oder\nwo zumindest mit rumgespielt wird.\nUnd die eigentliche Frage, die sich natürlich damit verbindet,\nist, wofür kann man das Ding eigentlich gebrauchen und taugt es überhaupt irgendwas\nund warum sollte man sowas überhaupt haben wollen und will man sowas überhaupt haben?\nAlso ich will sowas zum Beispiel gerade noch nicht haben.\nSo beeindruckend ich das alles finde, aber das ist ja eben die Frage,\nwas ist dann sozusagen auch der Nutzen?","Also nicht für 4K. Haben wollen würde ich es schon, aber nicht für 4K.","Ich würde es haben wollen, wenn ich es benutzen will.\nAlso das ist ja immer so diese Frage, du hast ein Mac, du hast ein iPad oder\nhast ein iPhone auf dem Tisch und deine Uhr, so, und jetzt willst du irgendwas tun. Was nimmst du?\nWelches Gerät nimmst du als erstes, um irgendwas zu tun?\nOder was tust du, wenn du irgendein Gerät nimmst? Was tust du nicht,\nwenn du irgendein Gerät nimmst? Es gibt Dinge, die mache ich am liebsten auf dem iPad.\nEs gibt sehr viele Sachen, die mache ich auf dem Mac am liebsten.\nEs gibt Dinge, da ist nur das iPhone für gedacht und einen Timer stelle ich\nmir am liebsten auf der Uhr.\nUnd genauso müsste es halt irgendwas geben für diese Vision Pro,\nwo ich so diesen Urge habe, so jetzt das Ding aufsetzen, weil dann, also vor allem wo man.\nKein Problem damit hat, all diese ganzen Nachteile einzugehen mit der Entkopplung\nvon der Außenwelt, das Teil mit dem komischen Akku, den du da in der Hosentasche hast,\nden du erstmal irgendwie arrangieren musst und dieser komische Clip da und einschalten\nund booten und okay, wenn das schon läuft, dann setzt du den auf, dann Optik-ID,\ndann bist du auch sofort eingeloggt, dann kann es auch sofort losgehen.\nPasst schon alles, aber es ist halt nicht so wie eine Uhr,\ndie du immer am Arm hast und es ist auch nicht wie das iPhone,\nwas du mal eben aus der Hosentasche ziehst oder ein Laptop, der dich einfach\nauf den Tisch die ganze Zeit anlächelt und sagt, benutze mich oder das iPad.\nDie Vision Pro muss immer erst in Betrieb genommen werden.\nDu hast immer erst so diesen Aufsetzen, Arrangieren, was mit meiner Frisurbrille,\nwie habe ich das richtige Setting.\nOkay, Und dann hast du sie auf und dann geht es eigentlich erst los.\nEs ist also nicht so dieser in einer Sekunde kann ich sofort anfangen mit irgendwas,\nsondern das ist auf jeden Fall erstmal eine Prozedur. Und da muss sich natürlich was rufen.\nDa muss irgendwas da sein, was du nur da so machen kannst und was es dir dann\nnatürlich auch wert ist.\nSowohl jetzt die initiale Investition in Geld, als auch Wert in dem Moment diesen\nAufwand zu leisten und auch die potenziellen Nachteile einzugehen,\ndie du natürlich zwangsläufig hast, wenn du so ein Ding aufhast.\nUnd wenn man sich jetzt mal anschaut, was an Apps derzeit so da ist,\nmeine Apple behauptet jetzt 600 Apps, keine Ahnung, die Hälfte davon sind wahrscheinlich Clocks.\nAlso was sind sozusagen jetzt so die Anwendungen, die gerade da sind und die\nandere Frage ist natürlich, was sind die Anwendungen, die einen sofort das kaufen lassen würden.","Also was ich mir vorstellen kann ist Anwendungen, die du gut verwenden kannst,\nwenn du die Hände nicht frei hast.\nWo du dir was anzeigen lässt. Weiß ich nicht, wie es mit der Interaktion ist,\naber im Prinzip Dinge, keine Ahnung.\nKochbuch. Rezept.","Kochbuch gibt es eins und diese Google Glass Reparaturanweisungen und sowas.","Sowas in der Art.","Da hast du halt immer das Problem, das Ding ist zu balki auf deinem Kopf.\nKlar, du kannst damit kochen. Also die eine Technik hat du eh gemacht.","Vielleicht nicht die Generation, aber dann später. Also einfach Ich habe die\nHände frei und kann aber trotzdem Informationen abrufen und mich auch gleichzeitig\nbewegen und irgendwo hingehen und so.\nAlso das ist für mich ein Interaktionsmodell, was Sinn machen würde.\nUnd das zweite ist auf jeden Fall halt auch,\nwenn ich irgendwas mit 3D-Druckern mache und vielleicht auch 3D-Modelle dann\nentwerfe, dann ist so eine Brille natürlich super.\nSuper, machst das Modell, du kannst, wenn das entsprechend gut gemacht ist,\nsogar auf dem Druckerbad kannst du sehen, wie kommt das Teil da raus,\nwie sieht das dann aus, wie groß ist das und mit einem Tab kannst du dann den\nDrucker anwerfen, möglicherweise.","Ja, also ich denke alles, was so mit 3D-Modellierung, 3D-Modellerstellung,\nalso egal ob es jetzt gedruckt ist oder virtuell, das funktioniert.\nSelbstverständlich werden viele Leute, die so im Bereich Architektur,\nWohnungsvisualisierung, Einrichtungen und so weiter, das sind glaube ich,\nEarly Adopter potenzielle von dieser Kamera,\nweil ich vermute, dass dort im Application-Bereich sehr schnell was passieren\nwird, weil es halt teilweise auch Apps schon gibt, die eigentlich nur angepasst\nwerden müssen und die dann natürlich sofort davon profitieren.","Also ich könnte mir auch vorstellen, so wenn du, weiß ich, so ein CAD-Programm\nwie Shaper oder so oder Onshape, wenn du das gut machst, dass du das in der\nBrille auch gerne lieber machst, weil das hat diesen 3D, du siehst es halt wirklich.\nUnd wenn du eh parametrisch arbeitest, dann kannst du halt ein paar Zahlen eingeben\nund musst halt nur, das muss halt gut bedienbar sein.\nAber Shaper3D, was Shaper3D auf iPad gemacht hat, das auch für Vision OS,\ndann hast du gewonnen eigentlich, weil das ist schon, das willst du haben, das macht schon Spaß.","Was hat denn Shaper3D gemacht?","Ein Interface, das man gut auf dem iPad mit dem Stift bedienen kann,\ndas intuitiver ist ein bisschen als Autodesk und Shape.\nEs hat einfach wirklich eine iPad-spezifische Lösungen gemacht,\nmit einem Bedienmodell, das funktioniert.\nUnd das kannst du halt mit eigentlich mit der,\nmit dem Eye-Tracking und den Gesten kannst du es genau genug machen, wenn du es gut machst.\nWas ich ein bisschen schade finde, ist, dass Onshape hat eine Vision Pro App,\naber die macht halt gar nichts irgendwie.\nAlso die ist halt so grottenschlecht, dass ich es nicht geschafft habe,\nmeine Modelle, die ich mir so gebaut habe, in letzter der Zeit irgendwie in\nden Raum zu stellen, weil ich diese App nicht bedienen kann,\nweil da geht halt irgendwie nichts. So soll es nicht sein.\nAber das ist schon auch eine.\nSchon auch eine Zielgruppe für sowas. Es ist aber alles noch Zukunftsmusik.\nEs ist wirklich, jetzt aktuell gibt es ganz wenig Apps, wo ich sagen würde,\nhey, dafür brauchst du das.\nFür mich ist es, glaube ich, eher so eine Geschichte, das ist jetzt eine Plattform,\ndie Apple aufbaut und Apple wird den Atem haben, die zu halten.\nUnd die wird jetzt noch eine Zeit lang vor sich hin verkümmern,\nweil was Geiles zu entwickeln, kostet auch geil viel Geld und so viele Leute\nhaben jetzt dieses Ding noch nicht, dass es sich lohnt.\nUnd du kannst ja auch die App nicht für 150 oder noch mehr verkaufen.\nDas haben wir ja auch irgendwie den Leuten abgewohnt.\nApps, die ich selber ganz gut finde schon, also wirklich, wo ich jetzt,\nich habe gestern irgendwie einfach mal mindestens eine halbe Stunde auf das\nHerz geguckt und habe dann erstmal verstanden, wie so der Flow durch das Blut\nins Herz so funktioniert und durch die Lunge und wieder zurück und so.\nDas ist halt eine freie App von diesen Herz-Apps und die Modelle in der Luft\nzu haben und anzugucken, ist einfach noch eine andere Qualität als nicht.\nAlso sämtliche dieser teureren Apps, die jetzt einfach eine im Raum 3D-Visualisierung\nvon irgendwas, was du brauchst, also als Arzt, einem Menschen oder als Techniker\nirgendwie Bauteile oder sonst irgendwas.\nAlso Chick ist zum Beispiel auch wirklich geil, da kannst du dir einfach so\nein 3D-Modell in den Raum stellen, in Originalgröße und dann auseinandernehmen,\ndie Teile angucken und Texte dazu.\nAlso das ist schon ein Anwendungsfall, wo so eine Mixed Reality-Brille wirklich\nSinn Sinn macht und das Erlebnis kriegst du nicht anders.\nOder auch die Mars Rover App ist ziemlich schlecht leider, aber den Mars Rover\nso im eigenen Zimmer in Originalgröße zu haben, nochmal um zu sehen,\nach, das ist ja doch ein Auto und nicht ein Matchbox Ding, ist einfach,\nschau doch mal, es ist eine Klasse von,\neinfach eine andere Qualität, dass du diese Original-Maßstab-Geschichten hast.\nUnd für das, was Roddy gesagt hat, alles, was mit 3D-Druck zu tun hat,\nda ist Reality Kit und AR Kit so gut, wenn du dem die richtigen Maße gibst,\ndann kannst du das im Raum platzieren und es ist einfach genau das so super\ngeil. Finde ich auch schon cool.\nAber brauche ich es konkret für irgendwas anders außer Spielen? Nee.\nAlso ich schaue gern damit Filme und so und das wird auch so bleiben.\nIch finde auch ganz gut, mich da zu bewegen dabei.\nAlso dann praktisch so den Screen irgendwie zu haben und dabei aktiv irgendwie zu sein.\nDas ist okay, weil das Motion Blur beim Videogucken nicht so blöd ist.\nAlso ich gucke viel im Stehen und Gehen.\nInteressanterweise nicht so viel auf der Couch. Auf der Couch nervt ein bisschen,\ndass dass die Klickerkennung und das Chips-Essen sich nicht so gut verträgt.\nUnd da muss man sich praktisch erstmal die Bedienung ausschalten,\nbevor man da entspannt Fernsehen gucken kann.\nAlso man kann ja auch die Bedienung auf nur linke oder nur rechte Hand stellen.\nDa kann man mit der einen Hand Chips essen. Das ist nicht schlecht,\nohne dass da aus Versehen ein Klick erkannt wird.\nOder man kann, und das sind auch ganz coole Features, so die Accessibility-Features\nzum Pointer-Control heißt es dann.\nDa kann man umstellen, dass man halt nicht mit den Augen arbeitet,\nsondern entweder mit dem Handgelenk, das heißt ein Handgelenk zeigt irgendwie,\ndas andere tippt und dann hast du mehr oder weniger so einen Pointer, so ähnlich wie bei iOS,\nalso einen Kreis, den du irgendwo anzeigst, wenn du willst, kriegst du auch\nden 3D-Strahl gezeigt oder du kannst mit dem Finger zeigen irgendwo drauf oder\ndu kannst es so ganz hardcore machen, die Mitte des Bildschirms ist dein Zeiger\nund dann musst du halt den Kopf bewegen.\nDas ist für Accessibility gedacht, aber so kann man praktisch Situationen,\ndie man nur temporär, indem man temporär nicht jetzt mit den Händen so viel\nauslösen will oder machen will, überbrücken. Das geht im Moment.","Oder machen kann, ja.","Da hast du dann so ein Fadenkreuz wie bei einem Shooter oder wie ist das dann?","Ne, das ist genauso wie der Mauszeiger bei iOS.","Also das mit dem Kopf?","Mit dem Kopf ist halt in der Mitte, genau da ist nur der Mauszeiger,\niOS Mauszeiger ist so in der Mitte vom Bildschirm und du musst halt den Kopf\ndann bewegen Das geht ganz.","Gut tatsächlich also.","Ich hab das mal eingeschaltet.","Das ist okay also ich würde mit Augen ist schneller Mein Genick.","Tut mir da weh einfach nur bei der.","Vorstellung Nee, ist nicht so schlimm weil du eine sehr gute Auflösung hast\nauch bei dem Kopfbewegung, du musst da nicht so hektisch hin und her gehen,\ndas ist eine ganz Ganz einfache Kopfhörungen reichen da schon aus.\nAlso ich würde es auch nochmal so zusammenfassen, was meiner Meinung nach derzeit\nAnwendungen sein könnten und die potenziell in der,\nin der Lifetime dieser Version 1.0 vielleicht noch eine Rolle spielen können.\nAlso nochmal so im nächsten anderthalb Jahr bei Leuten einen Kaufanreiz auslösen könnten.\nUnd das ist definitiv natürlich ganz klar, das haben wir jetzt schon mehrfach\ngesagt, Visualisierung, 3D-Visualisierung, wenn man da in irgendeiner Form einen\nBedarf hat, dann ist das halt einfach ein No-Brainer.\nUnd Editing in gewisser Hinsicht auch.\nDas ist halt irgendwie Architektur, Wohnen, Kunst, also wenn ich das was weiß\nich, für Blinkenlights,\nmachst du eine Kunstinstallation im Raum, willst du irgendwo so was Großes irgendwo\nauf so einen Platz bauen, dann wäre es natürlich mega, wenn du eine Software\nhast, die sagen kann, so ja, hier zack, Alexanderplatz,\ndann das wäre natürlich der Knaller.","Ist auch eine App, die es schon gibt, also für Designer und so weiter,\nklatscht dein Design an ein reales Objekt dran und dann musst du halt die Objekte\nzahlen, also die hat auch ein Geschäftsmodell, das funktioniert so,\nalso Also Milchkarton-Design.\nDa, fertig. Dann hast du Milchkarton in der Hand mit deinem Design.","Ja, okay. Aber das sind ja immer so Objekte. Es geht mir jetzt richtig auch\num diesen ganzen Immersions-Kram.","Objekte und Gegenden auch sind es da. Also Litfaßsäulen und so Zeug auch.\nOkay, aber so in die Stadt rein.","Also wirklich so large scale. Wie auch immer. Also es wird es in allen Varianten\ngeben und ich glaube, dass das einfach das ist dann auch konkurrenzlos.\nAlso dann ist das einfach auch die die beste Möglichkeit, sich sowas anzuschauen\nund ein Gefühl dafür zu bekommen, sind unsere Entscheidungen richtig.\nDa kommt es ja manchmal auf so gefühlte Sachen an. Wie groß bauen wir das? Ist das groß genug?\nWirkt das zu wenig? Ist das zu groß? Solche Entscheidungen sind sehr schwer\nmit Visualisierung im Zweidimensionalen zu machen, wenn du auch die Bezugsgröße\ndeiner Umgebung nicht wirklich dabei hast.\nUnd das ist halt das Coole, dass du sozusagen das zusammenbringen kannst.\nDa kann ich mir das also schon vorstellen. Dann eben, was auch schon anklang, so Remote Assistance,\nalso wenn jetzt irgendwie jemand repariert was und du brauchst aber Expertise\nund dann könnte sich jemand sozusagen in deinen View einklinken,\nso Streaming, Facetime würde ja in dem Moment schon reichen und du kannst dann\nhalt auch wirklich auf Dinge vielleicht auch zeigen und markieren oder so,\ndas ist ja jetzt noch nicht möglich,\num Leuten irgendwas beizubringen.\nJa, da kannst du irgendwie in der Ukraine den Piloten da irgendwie noch Assistance\ngeben oder den Leuten, die irgendwas reparieren, Assistance geben, so eine Sachen.\nAlso mit Militär will ich jetzt gar nicht erst anfangen, aber generell die Remote\nAssistance, ob das dann im medizinischen Bereich ist oder Reparaturbereich,\nTechnik und im weiteren Sinne, was du ja auch schon erwähnt hast,\nso Training, Education.\nLernen, 3D-Modelle, interaktive Sachen, Sachen, wo du halt Dinge auseinander\nschälen kannst und dir wirklich dreidimensional anschauen kannst.\nDas ist ja bei dieser Jig-App auch so, dass du so Teile wegnehmen kannst,\nalso wirklich vorstoßen kannst in Bereiche und das ist definitiv etwas, was damit geht.\nUnd dann halt wie vorhin schon erwähnt, Sport denke ich mal,\nwird eine Rolle spielen.\nMir ist noch nicht so ganz klar, was die beste Sache ist, aber du kannst natürlich\njetzt auch so Stadionperspektiven einnehmen.\nAlso wenn es möglich ist, sozusagen eine Live-Übertragung mit 180 Grad oder\nmeinetwegen auch noch mehr.\nZu machen und dann hast du eben so diese Stadionperspektive,\nwas sozusagen den Vorteil hätte, dass du eben das ganze Spiel sehen kannst,\nwährend du heute immer nur so Kamera-Ausschnitt hast.\nOder so eine mega totale, auf der du nichts erkennen kannst.\nAber wenn du nah genug dran bist, um das Detail zu verfolgen,\naber trotzdem jederzeit nach vorne und nach hinten gucken kannst und immer irgendwie\nso das Spielfeld beobachten kannst,\nich glaube, das könnte ganz interessant werden und das ist auch definitiv ein\nBereich, wo ich vorher eher skeptisch war und wo ich jetzt mir denke, okay,\nmaybe there's something to it.\nFür mich persönlich wäre natürlich die Killer-App Google Earth.\nBeziehungsweise fände ich ja mal, jetzt wäre es ja mal Zeit für Apple da mal\nButterbeigefische zu machen, weil die haben ja im Prinzip die gleichen Daten.","Apple Earth.","Also das wäre,\ndas Beste, wobei ich dann so meine Zweifel habe, dass die Eingabemethodiken ausreichen.","Das ist eine gute Frage.","Also da hätte ich schon doch lieber gerne meine Space-Maus.","Was du ja auch machen kannst, also du kannst ja auch eine Maus und eine Tastatur,\nalso ein Trackpad und Tastatur pairen, du ziehst ja auch durch,\ndu kannst ja reale Dinge nutzen, das ist ja nicht ausgeschlossen.\nIch meine, das ist auch eine andere Geschichte, die ich noch vergessen habe,\ndie wir noch vergessen haben, wenn du den Mac pairst,\ndann hast du nicht nur auf dem, also wenn du den Mac-Bildschirm verbindest,\ndann hast du nicht nur auf dem Mac-Bildschirm deine Tastatur und Maus,\nsondern auf allen Apps, die du anguckst,\nkannst du auch mit dem Trackpad deine Maus bewegen und das ist halt die klassische\niOS-Maus-Bedienung, die du benutzen kannst und die Tastatur direkt verwenden.\nDu kannst praktisch ein Laptop auch als Eingabegerät benutzen für deine,\nVision Pro Apps.","Ja, ich habe so ein bisschen meine Zweifel, dass die Space-Maus noch zu hören\nweinkommt bei Apple, aber tatsächlich wäre...","Mir ist die letztens untergekommen, bei den 3D-Modeller-Geschichten ist die\nauch ganz happy freund und wird auch unterstützt.","Ja, natürlich, das ist ja die Zielgruppe.\nWenn es möglich wäre, eine Space-Maus in dieses Produkt noch zu integrieren,\nalso dass man sozusagen ein Ich-Kann-Mit-Meiner-Hand-in-Jede,\nin jede Richtung Beschleunigung bewirken.\nDas ist ja im Prinzip das, was die Space Mouse macht. Du kannst das Ding ziehen,\ndrücken, in jede Richtung, Rotation und so weiter.\nAlso allein als Model Interface, also eigentlich müssen sie das sogar irgendwie\nunterstützen, fällt mir dabei ein, weil diese ganzen 3D-Programme brauchen ja\ngenau das Gleiche, weil da kannst du dann nicht die ganze Zeit irgendwie in der Luft,\nrumwirbeln und mit den den Fingern irgendwie rumziehen. Wie sieht denn das aus?\nAlso, naja.","Ja, mal sehen. Aber da ist noch eine andere Geschichte, die wir jetzt noch nicht erwähnt haben.\nAlso jenseits der Bedienung, die wir jetzt beschrieben haben und der direkten\nInteraktion mit mal drauf tippen, gibt es schon auch noch Handtracking per se\nfür Apps, die in den Immersionsmodus gehen.\nDas heißt, Apps können auch das Handtracking komplett benutzen und eigene Erkennung\nmachen auf dem Handskelett über ARKit,\naber nur, wenn sie als immersive App die einzige App sind, die gerade am Start\nsind. Das ist auch so eine Privacy-Einschränkung.\nUnd ich muss sagen, dass diese Handerkennung jetzt nicht so berauschend wirkt.\nAlso die ist schon okay, aber die ist ein bisschen laggy.\nDas kann natürlich daran liegen, dass das,\ndie Art und Weise, wie ich das jetzt mal programmiert habe an der Stelle,\naber ich habe es auch bei den Spielen und bei den Apps so gesehen, es geht so.\nAlso das ist nicht so schick. Da ist jetzt die Quest jetzt auch nicht schlechter so per se, glaube ich.\nUnd vielleicht sogar besser.\nUnd es ist auf alle Fälle dieses direkte Interaktionsmodell mit dem Handskelett\nist so ein schwierigeres. Das ist ein bisschen schade. Also da hätte ich mir noch mehr erwartet.","Glaubst du, wir werden Controller sehen?","Nee, man kann Controller verwenden, aber es gibt keine extra Controller,\nwird Apple nicht machen.\nAlso du kannst ja Playstation-Controller und Game-Controller halt verwenden.","Nee, ich rede jetzt nicht von Game-Controllern in dem Sinne,\nsondern das, was bei der Quest mit dabei ist zum Beispiel.","Ja, nee. Nee. Also von Apple und der Garantie. So wie sie bei Gamecontroller\nam Anfang sich geweigert haben.\nAlso von Apple. Selbst die Unterstützten. Also andersrum.\nEs ist technisch natürlich möglich, auch die zu unterstützen, die da sind.\nUnd ich glaube, wenn sie irgendwas machen, dann, weil sie merken,\nder Spielemarkt bricht ihnen weg und wir machen so ein billiges Produkt,\nhätten gerne Spiele auch,\ndass sie den populären Game-Controller unterstützen, der halt diese Form hat\nvon Flag, also den man halt Third-Party-mäßig kaufen will, wenn es einen gibt.\nAber sie werden nichts selber machen.\nDie sind da dagegen. Definitiv.","Das glaube ich auch. auf.","Insgesamt, diese Zukunftsgeschichten ist halt schon spannend und wenn wir schon\nan der Ecke sind, da würde ich darauf eingehen wollen, von dem,\nwas du am Anfang gesagt hast, ja beim ersten iPhone und beim ersten iPad und so weiter.\nDas Problem ist, das erste iPhone und das erste iPad war im Verhältnis nicht\nso viel teurer als der Rest und die nächste Generation muss trotzdem besser werden.\nAlso die Vision Pro hat ein bisschen das Problem, dass die nächste Generation\ntechnisch definitiv noch besser werden muss als die hier.\nUnd sie muss irgendwann mal in einem Preissegment ankommen, wo es Kunden hat.\nAlso das ist im Moment so, das ist ein Luxusgut hoch 10, dass es spannend genug\nist an der Stelle, aber das muss eingedampft werden auf unter 1000.","Ja, welches Feature lassen sie los?","Es darf aber nichts losgelassen werden, wir brauchen alles.\nDie Sensoren dürfen nicht schlechter werden, das Audio darf nicht schlechter\nwerden, die Auflösung darf nicht schlechter werden, also nichts darf schlechter\nwerden. Insofern, nur die Zeit wird es retten.\nApple hat den Atem, aber ich rechne schon mit zwei bis drei Jahren, bis da eine,\nbis dann mehr Massenmarkt kommt. Also das ist so ein bisschen die seltsame Geschichte,\ndie ich damit finde, weil es ist jetzt schon ein geiles Produkt,\naber kein, nicht geil genug und es hat nicht genug Nischen so an der Stelle.\nAlso nur über den Atem kann Apple das, glaube ich, wirklich aufrollen,\nweil und ich weiß auch nicht, wie viele Entwickler dann bis dahin mitspielen.\nAlso diese Investitionen zu machen, hier ein externes Produkt für zu machen,\nfür so einen kleinen Markt, puh.","Ja, schau dir Apple TV an, gibt's ja auch nichts für im Wesentlichen.\nAlso außer halt diese ganzen Television-Apps, die gibt es halt fürs Apple TV,\naber dann so ein paar halbherzig portierte Spiele.\nAber, ne?","Jaja, bei Apple TV ist das ein anderer Grund irgendwie. Die Plattform hat halt\nden Zug da verpasst, im Sinne irgendwie spannend zu sein.\nGünstig genug wäre ein Apple TV schon, wenn es Spiele gäbe. Aber das Ding ist\nhalt nicht günstig genug.\nWenn das nicht weniger als 1000 kostet, dann haben das zu wenig Leute dafür,\ndass es sich lohnt, große Entwicklungen zu machen für kleines Geld oder in irgendeiner\nForm in diesem Apple-Modell. Also da habe ich schon ein bisschen Sorge.","Ich hätte es gerne.","Weil ich finde das Ökosystem, das sie geschaffen haben und auch die,\nalso nicht das Ökosystem, sondern das Interaktionsmodell, das sie geschaffen\nhaben, also das, was sie jetzt da hingelegt haben, ist eine Plattform.\nIch würde die Plattform gerne mit Erfolg sehen, aber ich weiß nicht,\nbis wann es dauert, bis sie das hat. So, da bin ich nicht so optimistisch.","Naja, ich kann mir vorstellen, also sie haben die erste Vision ja ganz offensichtlich\nPro genannt, weil Pro heißt bei Apple ja nicht Professional, sondern nur teuer.\nUnd dann kann ich mir vorstellen, dass sie in drei Jahren oder sagen wir zur\ndritten Generation dann die nicht Pro bringen,\nwo dann ältere Hardware verbaut ist, die halt in der dann dritten Generation\nirgendwie immer noch, wo sie immer noch rechtfertigen können,\nwarum das dann pro Modell immer noch so viel kostet.","Ja, aber was passiert denn bis dahin? Also, ich glaube nicht,\ndass es viele Apps geben wird, die da viel investieren. Die Sport, also,\nSportübertragung und so weiter. Es gibt ein paar Nischenmärkte,\ndie machen das wahrscheinlich. Apple selber macht natürlich so,\naber so puh, also ich glaube, ich würde jetzt nicht sagen, hey,\nmach mal, also ich selber würde was dafür machen, weil ich es will, weil es Spaß macht, so.\nAlso, ich empfinde immer so dieses, es gibt ja auch so eine Guitar Hero Style Piano App.\nSowas hätte ich auch gerne gemacht und die ist recht schlecht, die es gibt.\nDie auf der Quest ist übrigens relativ gut sogar inzwischen.\nDie heißt irgendwie Piano Vision.\nAber für den Consumer-Markt ist das halt nicht.\nMal schauen. Es wird spannend. Ich glaube, Apple hat den,\nhat den Atem, das durchzuhalten und die werden es machen. Aber ich glaube, es dauert länger.\nEs dauert wirklich drei, vier, fünf Jahre, bis das in irgendeiner Form dem Produkt\neinfach mal vorhanden ist.","Mit der Zeit ist es schwierig. Wir haben ja diese populären Vergleiche mit irgendwie,\nwas ist denn sozusagen das Apple-Produkt, was als es rauskam,\nso vergleichbar ist mit seinem Stand im Markt.\nUnd ich würde sagen, Die Lisa eben.","Das ist aber zu lange her, das kann man eigentlich nicht mehr vergleichen.","Ja doch, ich hätte jetzt gesagt der Original Macintosh, weil da war es im Prinzip\ngenau dieselbe Situation.\nSie haben einen unheimlichen Aufwand getrieben, sie haben ein System rausgebracht,\nwas komplett anders war als alles, was bis dahin galt.\nJa, ein Computer, den du nicht mit der Tastatur über Kommandos steuerst,\nder einen weiß-schwarzen Bildschirm hatte mit einer Maus und mit einer Floppy-Disk\nund also 3,5 Zoll. Ja, Lisa, also egal.","Wegen dem Preis und der Größe die Lisa und dann der Macintosh ist dann die Vision. Genau. So in der.","Ja genau, könnte man auch noch machen. Aber ich wollte ja darauf hinaus,\nwas hat dann letzten Endes den Macintosh zum Erfolg werden lassen?\nUnd das war halt Photoshop und später QuarkXPress.\nDesktop Publishing, das ist\ndas Segment, das ist die Tür, die sie aufgestoßen haben, das war das Neue.\nInnerhalb kürzester Zeit hattest du in Werbeagenturen und Verlagen überall Macintoshes\nstehen während der Rest der Welt von dieser Maschine keine nennenswerte,\nKenntnis genommen hat außer natürlich ein paar Die-Hard-Nerds,\ndie sich irgendwie jeden Kram kaufen mussten aber das war das Segment,\nwas sie sozusagen dadurch begründet haben und das haben sie in dem Sinne auch\nnicht geplant so wie für den Apple 2 und auch für DOS,\nSpreadsheets Visikal und Lotus 1, 2, 3 absolute Treiber waren und überhaupt\nerstmal die Legitimation der Existenz ihrer Plattform überhaupt geliefert haben.\nWeil es da einfach einen Bedarf gab und weil Leute gesagt haben,\nmir ist das scheißegal, was ein Computer kostet, wenn der Zahlen ausrechnen\nkann in so einer XY-Spalten-Geschichte, dann kann ich irgendwie,\ndann kann ich meine ganze Firma komplett anders betreiben, als ich es bisher\nhergemacht habe, ist mir egal, was der Computer kostet.","Multiplan auf dem Apple II war glaube ich das erste.","Multiplan, VisiCalc war glaube ich das erste.","Oder VisiCalc, ja kann auch sein.","Und,\nUnd genau so etwas braucht jetzt auch die Vision Pro, weil Apple hat es sozusagen\nplatziert als, wir sind zwar irgendwie so ein Headset, aber wir benutzen das Wort gar nicht.\nWir definieren hier eine Computing-Plattform und nicht irgendwie ein Gaming-Device.\nWir haben ein komplett eigenes Interaktionsmodell, wir haben ganz andere Arten\nund Weisen, wie das hier bedient wird und so wie wir die Maus erfunden haben\nund wie wir Multitouch auf den Markt gebracht haben,\nhaben wir jetzt hier irgendwie Pinch und also Stimme, Stimme,\nAuge und Finger sind auf einmal der Controller für dein System.\nUnd dann halt so alles in brauchbarer Qualität, genug Sensoren und jetzt ist\nes eigentlich so die Wette, die auf dem Tisch liegt mit,\nso liebe Entwickler, jetzt lasst\neuch mal was einfallen, wir wissen auch nicht, was die Killer ab ist.\nWir haben eine gewisse Idee und wir haben drei, vier, fünf Sachen wie bei der\nWatch auch schon rausgeguckt.\nErinnere dich, bei dieser Watch, was da am Anfang alles probiert wurde,\nhier mit irgendwie Herzschlagteilen und diese ganzen Kommunikationssachen,\ndie sich nie durchgesetzt haben.\nAber am Ende waren halt Notifications allein schon mal ganz interessant und\nirgendwie Timer und dann vor allem halt Fitness-Tracking. ging.\nDas war halt der Grund, warum sich die Leute diese Uhr gekauft haben.\nSport. Das war halt das Ding.\nUnd das hat diese Watch in den Markt geholt und dann haben sie auch zugesehen,\ndass sie da das immer weiter verbessern und dafür ist die halt auch wirklich wirklich gut.\nUnd genauso wird es jetzt bei der Vision Pro laufen. Es wird irgendwas rauskommen.\nWas diese Fähigkeiten dieser Plattform nutzt auf eine Art und Weise,\num dabei was Neues zu produzieren oder irgendetwas auf eine bestimmte Art und\nWeise viel besser zu machen, als man das bisher mit was anderem machen konnte.\nUnd dieser ganze 3D-Modellierungs- und Visualisierungsbereich ist ein heißer Kandidat dafür.\nSicherlich auch irgendwelche Kommunikations-Interaktionsmodelle im Bereich Training,\nEducation, Kommunikation. Kann ich mir sehr gut vorstellen, dass da irgendwas passiert.\nUnd vielleicht ist es auch der Sport und vielleicht ist es auch am Ende Kino\ngucken. gucken. Vielleicht funktioniert das auch schon. Das ist, sagen wir mal,\ndieses Filmgucken ist so die, ich würde nicht sagen, die niedrig hängende Frucht,\naber das ist so, dass das versteht jeder.\nAlso du musst keinem mehr erklären, warum man Filme gucken sollte.","Also die Geschichte dahingehend sei vielleicht nochmal gesagt,\nalso der Screen für Filme gucken ist schon extrem gut auch.\nAlso ich habe ja zumindest davor nochmal versucht mit der Quest 2 das mal zu\nmachen, die war noch viel zu schlecht, aber die Quest 3 macht auch weniger Spaß.\nAlso das Mehr an Pixel, das man in der Density hat, ist für Filme gucken schon auch nochmal cooler.\nAlso es ist schon auch die erste Brille, mit der ich Filme gucken will,\ndie ich aufgesetzt hatte, weil mit den anderen wollte ich immer nur eher Spiele\nspielen, weil das halt ein Novum ist.\nAber mit der will ich auch einen Film gucken, weil die Qualität gut ist, was ich da sehe.","Also ich sehe es ja eher in Interaktion mit 3D,\nob das jetzt Spiele sind oder ob das tatsächlich ich baue CAD-Modelle, ich,\nbin in der Lage, die besser im Raum zu verorten und besser zu verstehen,\nwas habe ich da eigentlich modelliert, wie sieht das aus, wenn es bei mir auf dem Tisch steht.\nDas ist für mich der heiße Kandidat.","Aber es ist natürlich kein Massenmarkt.","Ja, aber passiv 2D mit so einer Brille, ja, Ja, das mag zwar ganz nett sein\ndamit, aber da muss sie schon sehr viel billiger sein.","Filme gucken meinst du?","Ja, Filme gucken. Dafür muss sie schon sehr viel billiger sein,\ndass das ein echter Treiber für Verkäufe wird.","Und auch weniger personalisiert irgendwie. Du hast ja wieder dieses Modell,\ndass pro Person ein Gerät bitte, und das ist bei der Größenordnung vom Preis\nhalt einfach nicht okay.","Das ist bei Kommunikation genau das Gleiche. Also ich meine,\nwenn sich zwei Leute mit Vision Pro unterhalten wollen und was zusammen machen\nwollen, dann legst du erstmal 8.000 Euro auf den Tisch.\nDas ist natürlich erstmal irgendwie, ja, muss man irgendwie.","Weißt du auch, es gibt Leute, für die ist das keine nennenswerte Investition.","Ich weiß, solche Leute, aber dann reden wir aber auch nicht von Massenmarkt.","Nee, es geht ja auch nicht erstmal um den…,\nMassenmarkt, sondern es geht darum, dass so ein neues, also das mit den Filmen\nist, sagen wir mal, nur so die Reizwäsche, die einen erstmal sozusagen für diese\nPlattform, die eine gute Ausrede liefert, sich diese Plattform zuzulegen.\nDu kaufst dir diese Brille und dann kannst du Filme gucken.\nUnd wenn du irgendwie regelmäßig Business Class im Flugzeug fliegst und irgendwie\ndeine 4-5 Stunden Flüge hast, dann kostet dich das Ding so viel wie ein Ticket.\nNew York, Paris und das geht sozusagen in deine Gesamtinvestitionen komplett unter.\nDas sind halt die Leute, die dann erstmal einfach mal kaufen und die sich da\nimmer schön einreden können, okay, das reicht mir jetzt allein zum Film gucken.\nJetzt läuft die Zeit weiter und Entwickler kommen halt mit neuen Ideen und dann\nist halt eben die Frage, gibt es so einen Photoshop, VisiCalc, QuarkXPress Moment?\nGibt es irgendwie so eine App, die da halt was definiert und dann kann das eben\ndiese Kamera in die nächste Generation bringen.","Aber von den Leuten, von denen du sprichst, die haben sich auch damals die Newtons\ngekauft und da ist nie was bei rumgekommen.","Ja gut, aber der Newton war auch nicht im Ansatz so gut gemacht wie das Teil.","Also was ich mir wünschen würde an der Stelle wirklich, was diese Reise gewinnen\nwürde, wäre irgendwas, was praktisch mit diesem Interaktionsmodell im Raum einfach\nwirklich was Neues macht.\nSo wie Spaghetti Computing für Shader, sowas für andere. Also es ist wirklich\nso, du arbeitest mit einem 3D-Objekt und erzeugst damit geiles Zeug, wie auch immer.\nAlso so eine App, die es halt einfach noch nicht gibt.\nSo eine VJ-App, die aber im Raum arbeitet und es mehr Sinn macht, im Raum zu sein.\nIch finde, da hat die Vision Pro Potenzial, weil sie alle Sensoren hat und alle\nAuflösungen dafür, sowas zu machen.\nAber das gibt es halt noch nicht. Es gibt halt das Programm noch nicht.\nDas Äquivalent zu Photoshop für den 3D-Raum gibt es halt noch nicht.\nUnd das würde ich gerne sehen, das wäre mir am liebsten, weil da warte ich drauf.\nIch warte schon so lange drauf auf so eine größere, das ist jetzt mal eine geile\nSache, die jetzt mit neuer Technologie, nur mit neuer Technologie funktioniert.","Aber das Beispiel Photoshop ist insofern recht schön, du hast ein Tool,\nwas in der virtuellen Welt funktioniert.\nUnd du produzierst aber etwas damit, was in der nicht virtuellen Welt verwendet\nwird, nämlich das Druckerzeugnis.\nUnd ich glaube, dass die Vision, wenn sie sich beweisen soll,\nmuss diesen Medienbruch zwischen virtueller und echter Welt hinkriegen.\nDeswegen sage ich halt, 3D-Modeling aller Art kombiniert mit Rapid Prototyping,\n3D-Drucker aller Art, ist glaube ich ein schöner Knackpunkt.\nWenn Apple diesen Markt irgendwie auch nur halbwegs anknacken kann,\ndann haben sie einen Gewinner an der Stelle.","Ich habe so ein bisschen das Gefühl, der ist nicht groß genug,\naber es wäre natürlich auch, es wäre ganz schön.","Ja, aber wie viele Leute haben denn jetzt schon einen 3D-Drucker?\nIch meine, das kommt doch auch immer mehr in den Massenmarkt.\nUnd wenn die 3D-Drucker erstmal ordentlich im Massenmarkt sind,\ndann kommen auch die, wie komme ich denn zu dem Kram, den ich ausdrucke?\nDas muss doch auch dann irgendwie mit in den Massenmarkt tröpfeln.","3D-Drucker im Massenmarkt?","Räumst du?","Was, Marc? Du meinst, Saturn verkauft 3D-Drucker?","Würde ich mich jetzt nicht wundern, wenn du bei Saturn in einer Ecke auch 3D-Drucker findest.","Also nur mal, um dich mal in meinen Relativ zu halten, mein Kleiner hat eine\nEinladung mit einem 3D-Druck bekommen, so zu einem Geburtstag.\nUnd ich weiß nicht, wie nerdy die Familie wirklich ist. Ich muss mal nachfragen.\nWirkt er nicht so nerdy? Also es ist erstaunlich, erstaunlich Massen.\nUnd ich bin mit meinem Neukauf von meinem 3D-Drucker in eine Runde gekommen\nund dann war das, ach so, ja.","Also das kommt vielleicht mal so Copyshop-mäßig, dass da die 3D-Drucker rumstehen\nund du dann mit deinem Modell da hinkommst und das machst, aber dass das jetzt irgendwie alle machen.","Also es ist mehr Massenmarkt als die Leute, die beim Business-Flug irgendwie\neinen Film gucken wollen.","Was?","Also Leute wissen, es ist wie Copyshop früher. Ja, definitiv.\nLeute wissen das und nutzen das sowieso.\nMan macht es halt jetzt. Man druckt sich halt jetzt 3D-Zeug.","Okay, gut. Da sind wir in der falschen Generation inzwischen.","Wir sind alt.","Im Chat schreibt einer Aldi. Also wenn es 3D-Drucker bei Aldi gibt,\ndann ist es Massenmarkt.\nEs gibt kein anderes Kriterium für Massenmarkt als Aldi.","Konrad verkauft 3D-Drucker. Natürlich Konrad. Konrad verkauft auch Widerstände\nund und komplizierte Geräte als so.","Ja, Konrad ist weniger ein Kriterium.","Ja, nee, das muss schon was sein.","Aber wenn die Dinger bei Aldi stehen, dann ist es Massenmarkt.\nAlso das kann man dann nicht mehr wegdiskutieren.","So, haben wir denn noch irgendwas zu sagen eigentlich zu unserer Headset Experience?\nIch glaube, wir sind so ein bisschen an dem Punkt angekommen,\nwo sich nicht mehr sehr viel sagen lässt.\nOder es ließe sich noch viel sagen, aber nichts Neues.","Ich weiß nicht, ob wir wirklich noch was haben, was wir loswerden wollen dazu,\nalso ich find's nach wie vor, also ich find's,\nIch finde es super spannend, vielleicht, es klingt jetzt so negativ,\ndass ich den Markt nicht so sehe und was auch immer, aber es ist so,\nseit längerem wieder so das erste Produkt,\nwo ich sehe, wie geil es noch werden kann, weil alle Aspekte noch viel besser\nwerden können, so an der Stelle und auch müssen und trotzdem so die Initialzündung\nschon so viel Spaß macht, dass es für mich, also es ist so ein,\nals Hobbyding ist es irgendwie cool.","Okay, ich gebe auf. Der Chat hat gerade Aldi verkauft, 3D-Drucker.","Du hast es nicht geglaubt, oder was?","Nee.","Das war kein Chat. Also gerade die Bamboo-Geschichten und so,\ndie haben halt einfach, wenn die so ein Enclosure haben, dann muss man auch wenig können.","Dann halt 3D-Druck, meinetwegen.","Also ich sage jetzt nicht, jeder muss das jetzt machen.\nAber ich sehe das Phänomen schon in der Masse ankommen. Und warum auch nicht? Macht ja sicher Spaß.","Ja, nee, ist in Ordnung.\nAlso vielleicht mal so nochmal von oben herab.\nIst das jetzt sozusagen ein bold Move, den Sie da gemacht haben? Ja.\nIst es etwas, was ich kaufen würde gerade für mich, weil ich für mich da eine Anwendung sehe?\nNee, derzeit noch nicht. Also nichts hat mich jetzt so gereizt und als ich das\nDing, nachdem ich mich 24 Stunden damit beschäftigt habe,\nGab es jetzt nichts, wo ich mir gedacht habe, so, oh, schade,\ndass ich die jetzt nicht im Zugriff habe, jetzt würde ich aber gerne nochmal\ndas, also abgesehen von, ich beschäftige mich damit, um zu verstehen,\nwas es ist, so einfach so von der Anwendung her,\ngab es jetzt nichts, wo ich sagen würde, das brauche ich aber jetzt unbedingt\nirgendwie in meinem Leben.\nHat auch ein bisschen was damit zu tun, dass ich jetzt nicht so ein extensiver Filmgucker wäre.\nDa wäre das schon vielleicht ein bisschen anders.\nUnd natürlich hätte ich gerne etwas, was ist wie Google Earth.\nAlso ich meine, wenn Apple mal Apple Maps einfach so wie Google Earth baut für\ndie Vision Pro, dann kaufe ich mir aber eins für jeden Ort.","Wo ich wohne.","Also das ist, ja, verstehst du?","Was machst du da eigentlich immer so drin? Du schaust dir die Erde an,\nanstatt sie abzufahren.","Ich, also für mich, mir hilft es einfach sehr, die Welt zu verstehen.\nAlso ich, wenn ich so News wahrnehme, irgendwas ist irgendwo passiert, dann fliege ich da hin.","Also das fände ich insgesamt auch einen guten Content News mit,\ndu bist an dem Ort dann ein bisschen, du hast ein bisschen den Kontext im Sinne\nvon, das sind die Leute da, das sind die Orte, das sind die Gebäude, das ist so die Stimmung,\ndas ist die Farbe des Himmels oder wie auch immer so als Immersive Experience,\nnur damit du nicht nur diese komische Zahl hast oder so.\nAlso das könnte ich mir auch noch gut vorstellen als, ist ja mehr Education\ninsgesamt, aber so einfach so als, man will es dann nicht mehr nicht haben.\nWenn man mal irgendwo vor Ort gewesen sein kann, um es zu sehen,\nanstatt so ein flaches Fernsehbild, vielleicht ist das was.","Ja, aber ich meine, dass sie...\nAlso das wäre ja geradezu eine Unterlassung, dass sie jetzt mit ihrem Maps-Produkt\nnicht irgendwie diese Vision Pro erschließen.\nAlso wenn sie das nicht kombiniert bekommen, dann können sie den Markt auch\ngleich wieder verlassen.","Naja, aber das Maps-Team von Apple sind doch Jagdhunde, die man zur Jagd tragen muss.\nAlso die sind ja irgendwie immer drei Jahre hinter State of the Art gewesen.","Das ist nicht ganz richtig. Also sie sind bei vielen Sachen vielleicht später.","Wie viele Jahre haben die gebraucht, um die Anzahl der Flughäfen in Berlin richtig hinzukriegen?\nIch glaube zehn oder so?","Ja, gut.\nContent-Problematik nochmal separat, aber rein von dem visuellen und vom dreidimensionalen\nsind sie zum Beispiel deutlich besser als Google Earth. Also klassenbesser.","Ja, okay.","Das mit der Vision Pro zu verbinden. Weil dann kannst du dich halt wirklich,\ndreidimensional irgendwo hinbewegen.","Für Vision OS 2 und für Vision OS 3 braucht Apple ja auch noch ein paar Features.\nAlso jetzt sei mal nicht ungeduldig.","Das wäre sozusagen das Produkt, was ich unbedingt haben will.\nAllerdings müssen sie sich wirklich, also ich glaube, der Tag,\nwo ich so richtig steil gehe, wäre es, wenn Apple irgendwie 3D-Connection kauft. Das wäre es.\nWerden sie aber nicht machen, leider.","Ich sag mal so, zum jetzigen Preis ist es halt immer noch indiskutabel.\nAlso nicht, dass ich so ein Teil nicht haben wollen würde, aber halt nicht zu dem Preis.","Mit Google-Ads kaufe ich das auch für 5.000.","Naja, ich weiß nicht genau, wo der Cut-Off ist und ich glaube,\nich will da auch nicht genau drüber nachdenken.\nAber es muss ja auch ein Apple-Gerät geben, was ich nicht, wo ich nicht Early\nAdopter bin und das gleich kaufe.","Genau.","Also ich meine, ich hatte das erste iPhone, ich hatte das erste iPad und habe ich auch immer noch.\nIch hatte die erste Apple Watch, die habe ich nicht mehr. Ich hatte den ersten iPod.\nAlso irgendwie ähm.","Gerade den ersten iPod hatte ich nicht. Ich glaube, nur die Watch habe ich als erstes gekauft.","Ich weiß noch, dass ich damals am Überlegen war, jetzt mal so einen MP3-Player\nmit Festplatte haben zu wollen.\nUnd habe dann hin und her überlegt, die Geräte waren alle irgendwie nicht so richtig meh.\nUnd dann kam Apple mit dem iPod.\nUnd ich so, scheiße, den musst du jetzt haben. Und der war ja auch geil.","Auf jeden Fall. So, dann lass uns doch mal den Vision Pro Teil beenden.","Ja.","Wir haben jetzt,\nunsere tausend Stunden Freakshow auf jeden Fall zusammen.","Auf jeden Fall voll, ja.","Und ich war dabei.","Ein bisschen drüber, du warst dabei, genau. Wir haben uns gar nicht gemerkt,\nwie wir durch diese Schallmauer durchgebrochen sind.","Nee, und das ganz ohne Outliner.","So, aber Aber wer wollte denn von euch jetzt nochmal über 3D,\njetzt haben wir schon so viel 3D-Drucker als die Verheißung der Zukunft gesprochen?","Ich bin ein bisschen durch.","War das dein Thema?","Ich? Ja, ich habe mir den spontan irgendwie, ich habe von einem Bekannten mal\neinen alten 3D-Drucker ausgeliehen und habe so ein bisschen Lunte gerochen und\nhabe mir überlegt, ich will mal wissen, wie der aktuelle Stand der 3D-Drucktechnik so ist.\nWas kauft man denn da so und hab mir dann bei Aldi gibt es da gerade was genau,\nempfehlen lassen den Prusa MK4 der da noch mit,\nWarteliste war und dann kam der doch viel früher als gedacht und dann kam der\npraktisch zwei Wochen vor der Vision Pro daher und dann hat mich der links hinten\nüberrascht und seitdem hat der rund um die Uhr durchgedruckt dann,\nalso einen zum selber aufbauen sogar, also eher nicht so Massenmarkt mäßig Ja.","Aber mehr so Ikea oder?","Nee, also was heißt Ikea? Ja schon, von der Anleitung, die Anleitung ist sehr\ngut, aber acht bis neun Stunden baut man den so zusammen.\nOkay, willst du das machen?\nIch habe mir die genaue Dauer nicht so genau durchgelesen und ich dachte mir,\ndas ist ja doch noch so ein manuelles Produkt, wenn man es dann selber zusammengebaut\nhat, weiß man wenigstens, wo die Probleme sind, weil ich kenne 3D-Drucken ja nur mit Problemen.\nAlso wir haben damals, Martin hatte damals mal von irgendeinem Kongress den\nersten Maker-Bot oder den zweiten so gefühlt mitgebracht und den haben wir dann\nin der Cave mal aufgebaut und dann haben wir ungefähr drei Drucke hinbekommen,\nbis der irgendwie eingeschmolzen ist, weil wir waren alle nicht so aktiv,\nden zu pflegen und bis der irgendwie auf dem Druckbett dann wirklich auch gehaftet\nist und so. es war dann ganz cool, aber hatte keinen Sinn.\nUnd da habe ich mir gedacht, das ist doch jetzt anders, dann hatte ich den kleinen\nvom Bekannten und habe dann eben so ein bisschen ausprobiert und dann hatte\nich es auch schon ein altes Modell und das ist eigentlich inzwischen alles schon\nviel angenehmer, weil was der Prusa macht ist und die,\nmoderneren 3D-Drucker ist, man muss die nicht mehr so fein fiddelig justieren,\nsondern man steckt einfach was\nrein und dann startet man den Druck und man muss ein bisschen die Werte,\nin den Programmen einstellen, so dass sie passend zu dem Druckmaterial ist, was man benutzt.\nAber man muss jetzt nicht mehr das Druckbett irgendwie anheben und dann die\nTemperatur ausprobieren und den ganzen Scheiß machen.\nSo, und dann druckt man halt Dinge. Und das macht erstaunlich viel Spaß.\nUnd die Welt der CAD-Programme hat sich auch massiv verändert.\nAlso wie ich vorher schon gemeint habe, Shaper.\nOnshape ist irgendwie sogar ein Web-Tool, mit dem man parametrisch...\nCAD machen kann und geiles Zeug sofort, wenn man weiß, was man macht,\ngeht es in Nullkommanix. Die Programme sind alle besser geworden.\nEs ist ein Spaß. Es ist ein Rabbit Hole. Es ist wirklich so,\nzwei Wochen hat dieser Drucker durchgedruckt.\nUnd jetzt ist er schon langsam so ein bisschen eine Bremse drin.\nAber ich habe mir zum Beispiel so das hier gemacht für meine Vision Pro. Was ist das hier?\nDas ist so ein in die Vision Pro kommt in der Verpackung mit so einem Karton runden Dings.\nDamit die Vorderseite da wo dein Gesicht drauf ist, auch abgedeckt ist.\nWenn du die Vision Pro rausnimmst kriegst du im Umfang, wenn du nicht die teure\nTasche gekauft hast, nichts um das irgendwie zu transportieren oder,\nzu schützen, außer so ein Verhüterli, der so vorne auf der,\nGlasscheibe sitzt, genau so ein Socken, aber die Innenseite mit den Linsen ist\neinfach, die ist einfach offen,\nalso die kannst du irgendwie jetzt so nicht in die Tasche stecken oder so oder\neinfach nur rumlegen lassen und da habe ich mir so ein Inlay gedruckt,\ndas man da drauf legt damit, wenn irgendwie Dreck runterfällt oder es nicht\neinstaubt oder man halt auch das Gefühl hat, es verkratzt nicht die Linse, die sauteuer war und,\ndas konnte ich mir halt einfach zusammendrucken, indem ich das ein bisschen\nausgemessen habe und ein bisschen dann so,\nCAD gemacht habe das hat Spaß gemacht,\nund die meisten Drucke funktionieren einfach, wenn man es machen will und es hat halt diese.\nNach wie vor den Nachteil, dass man halt mit der Art und Weise des Drucks arbeiten\nmuss, das heißt Das heißt, es gibt halt die Schichten, mit denen das Zeug läuft\nund man muss halt die Stärke des Materials in die richtige Richtung machen und\ndas verschiedene Plastik.\nAber es ist halt alles jetzt ein gelöstes Problem geführt. Also wenn ich jetzt\nirgendwas machen will, kann ich es machen.\nZum Beispiel kleine Elektronikbauteile auch. Also ich habe auch noch Lust,\nda was schöne Enclosures für zu machen. Also die,\nDa wird viel passiert und das selber machen zu können hat für mich den Unterschied\ngemacht, weil jetzt habe ich es halt einfach ausprobiert.\nIch habe die zwei Wochen lang immer was gedruckt, dann habe ich es ausprobiert,\nein bisschen was gemacht, ein bisschen was selber gemacht und jetzt habe ich\nso innerhalb dieser zwei Wochen schon genug Selbstvertrauen,\ndass ich jetzt irgendwie so Reparaturzeugs machen würde.\nWürde für, da ist man, da fehlt man ein Plastikteil von irgendwas,\ndass ich das schnell nachbaue und dann einfach mal schnell drucke.\nSo. Und das ist einfach, ich kann das jetzt, ich hab das jetzt was,\nich kann da jetzt Zeug hervorheben.","Du hast da was Eigenes sozusagen.","Genau, so ein Jodel-Diplom.","Das ist jetzt.","Das 3D-Jodel-Diplom. Also,\nkeine Ahnung, ich weiß nicht, ob ihr so Spaß an dem Zeug noch habt oder nicht,\nalso auf dem Kongresso und im Umfeld sieht man ja so Zeug immer rumhängen und\nrumlaufen, aber selber nochmal zu haben.","Ich habe mich jetzt sehr lange mit Händen und Füßen gewehrt,\neinen 3D-Drucker anzuschaffen, aber ich glaube, ich komme langsam nicht mehr dran vorbei.\nWeil das ist wieder so ein Rabbit Hole. Vor allen Dingen das Schlimme ist,\nes gibt ja inzwischen auch alles,\nwas man damit macht, also so Lebensmittel echtes Filament zum Beispiel,\nwo man halt dann auch mal keine Ahnung, Sachen drucken kann,\ndie man irgendwie, weiß ich nicht,\nbeim Brauen brauchen könnte oder so.\nEs gibt kaum noch Argumente dagegen. Das ist echt ein Problem.","Ich frage mich immer, wie viele Dinge ich eigentlich wirklich so zu ersetzen und zu reparieren habe.\nAber klar, es gibt immer mal so Plastikteile, die brechen und dann ist es schwierig,\ndie zu kleben und dann so, aber wie oft ich dann auch wirklich in dem Moment\nso einen Drucker zum Einsatz bringen könnte, erfolgreich,\nda habe ich doch echt meine Zweifel.","Also ich hätte es halt auch nicht gemacht, wenn ich nicht Lust runtergeleckt\nhätte, einfach so, okay, wie ist denn die aktuelle Situation mit 3D-Druckern?\nUm einfach diese Einschätzung, okay, gibt es die bei Aldi und macht das Sinn\nfür Leute, um die einfach haben zu können und ja, also du kannst mit so einem,\nrelativ robusten Drucker und ein bisschen was aus dem Internet runterladen,\ndir sinnvolles Zeug drucken, das können die Leute jetzt, die Geräte sind gut genug und,\ndas wollte ich alleine wissen Und jetzt habe ich mich genug informiert wieder\nund jetzt werde ich mit dem so lange glücklich, wie ich ihn verwenden werde.\nKeine Ahnung. Also die Recherche ist passiert. Die sinnvollen Dinge kommen jetzt\ndann später in kleineren Dosen wieder.","Aber du hast noch nicht gesagt, warum es jetzt genau der Drucker sein musste.","Das war einfach nur so die grundsätzliche Recherche.","Aber grundsätzliche Recherche heißt ja, du musst ja auf irgendwelche Punkte\ngestoßen sein, die dann gesagt haben, das Modell muss es sein.","Also, du hast einerseits die Ecke...\nIst es jetzt eher so ein fertiges Produkt, das du dann nicht reparieren kannst,\nso wie ein Bamboo oder eher so, wie du halt so einen Drucker kaufst,\nden du dann wegwirfst, wenn er kaputt ist?\nOder ist es eher noch in dieser Makerboard und so weiter Gedankengut,\nwo auch Teile selber noch 3D gedruckt sind und du es eben noch zusammenbaust\nund reparieren kannst und ersetzen kannst und wo es sich auch mit der Zeit verbessert?\nSo, das ist so die eine Achse, an der man arbeiten kann und Prusa ist da einfach\nrelativ umtriebig, was das angeht.\nPrusa selber verwendet die massiv und hat die einfach im Einsatz,\ndas heißt, die sind einfach, die gehen nicht so schnell kaputt und die sind\nauch wirklich gepflegt und das ist jetzt nicht ein Produkt für einen Consumer\nin irgendeiner Form, sondern von einer Ecke von Leuten, die auch wollen,\ndass die Dinger lange funktionieren.\nSo, das war so, das ist ein Ding, das hält eigentlich oder kann man reparieren\noder kann man sich dann Zeug nachkaufen.\nEs ist eher noch so, diese MakerBot-Tradition selber finde ich halt auch noch\nschön, weil ich halt so ein bisschen mehr aus dieser, ich will mehr verstehen\num das Zeug drumherum Ecke komme und da gibt es da einiges.\nUnd das war es dann eigentlich schon, weil es gibt noch einige andere, aber das war halt,\ndie Ecke und die letzte, die mir noch wichtig war, war eben dieses,\nder kann einfach drauf losdrucken, nachdem er aufgebaut worden ist,\nalso der hat der muss nicht mehr eingestellt werden auf seinem Bett und das\nBett muss man gerade ausrichten so, damit irgendwie der erste Layer funktioniert,\nsondern der hat einen Mechanismus, wo er mit mit seiner Nase auf den Layer fährt und das misst.\nUnd das macht er jedes Mal und dann\nklappt es auch. Du musst nur unten die Bildplatte putzen und das war's.\nUnd es wurde bestätigt, dass das viel so ist. Und so eine Mischung aus Convenience\nund noch im alten Spirit fand ich gut.\nDeshalb ist es der geworden, genau. Es gibt noch einige mehr,\naber ich meine, das ist so ein Rabbit Hole. Ich habe mich nicht super tief reingegraben.\nDas war so an der Oberfläche.\nAber ich bin sehr zufrieden mit meiner Entscheidung. Also der flutscht.\nDas Einzige, was ich nicht unbedingt empfehlen würde, das Ding selber aufzubauen,\nweil man halt sich schon beim Aufbauen ein bisschen was kaputt machen kann und\nhabe ich natürlich auch wieder, weil irgendwie die Kugellager von den Stangen,\nwenn man die da durchdrückt, da kann man schon aus Versehen mal Kugeln rausdrücken\nund das weiß man halt nachher, dass man das falsch gemacht hat, mehr oder weniger.\nUnd auch wenn es vorher beschrieben wird, wenn man es zum ersten Mal macht,\nmacht man es halt ein bisschen nicht so dolle.\nEs war gut genug, dass er sauber noch funktioniert, Aber so ein,\nzwei Kugellager sind jetzt weniger toll, als sie sein könnten,\ndadurch, dass ich es selber gemacht habe.","Okay, verstehe ich. Wenn man, ja, machst du es ja eigentlich richtig.\nIch bin so ein bisschen Weichei, was diese ganze Tinkerei betrifft.\nDa brauchst du immer einen sehr langen Anlauf für mich, bis ich mich da wirklich\nmal reingelehnt bekomme.","Also ich hätte gerne, ich habe ein bisschen Lust, ein bisschen was mit Elektronik\nzu machen und die wird halt nur dann hübsch, wenn sie eine Enclosure bekommt.\nDa musst du dann selber drucken und designen. Also ich habe halt jetzt,\ndas Letzte, was ich gemacht habe, war so ein ein E-Paper-Display in den Bilderrahmen\ngesteckt und dann klebt es halt hinten mit,\ndoppelseitigem Klebeband und Kabelbindern dran und das kann ich nicht,\ndas kann ich nirgends woanders hinstellen als hier im Raum.\nWenn ich da aber einen Enclosure drumrum mache, dann hat es einen USB-Stecker\nund dann sieht das aus wie ein schickes Ding. Also so, weißt du?\nUnd da ist halt auch was, was ich gesehen habe, wenn du es mit genug Zeit druckst,\ndann ist halt auch das Plastik hübsch genug inzwischen.\nAlso es ist nicht mehr so, dass du diese Schichten und Rillen und alles siehst,\nsondern wenn du das mit genug Zeit drucken lässt, dann ist die eine Seite auf\ndem Druckbett super glatt, die Oberseite kannst du super glatt bekommen und\nwenn du es ein bisschen mit Geschmack designst, hast du einfach ein schönes Teil.\nDas ist nicht mehr so, das hast du ja selbst gehäkelt.","Ja, aber selbst häkeln ist ja auch schön.","Mach ich ja auch, aber ist wieder was anderes.","Nichts gegen Häkeln. Nee?\nGut Leute, wollen wir es da enden lassen heute Jetzt haben wir schon wieder\nunser 4-Stunden-Programm so gut wie durch,\nOder? Ja Wir haben.","Die 1000 Stunden.","Geknackt Das muss jetzt reichen Genau,\nAlso naja Also alle jetzt an die 3D-Drucker gibt es bei Aldi und demnächst mit\nder Vision Pro auf dem Kopf.","Ich weiß nicht, ob ich solche Produkte bei Aldi kaufen will,\naber das muss ja jeder selber wissen.","Da gebe ich auf jeden Fall sofort zu. Habe ich schon wieder einen Trend verpasst?\nIst nicht gedacht, dass das da auf dem Regal liegt.","Bresser 3D.","Keine Ahnung, ob der was taugt, aber Aldi ist meistens schon irgendwie okay.","Ja, Aldi ist vor allem seiner Zeit auch immer irgendwie voraus.\nDas muss man ihm mal lassen.\nIch kaufe da trotzdem nicht gerne ein, aber so ist das halt nun mal.\nSo, also. Dann ist jetzt die Gelegenheit, sich artig zu verabschieden.\nWir hören uns ein paar Wochen wieder.","Bei mir dauert es ein bisschen länger, aber ich höre euch weiter zu dann.","Okay, dann sagen wir Tschüss Tschüss. Bis bald."]}